{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTStephens18/AudioTranscriptor/blob/main/V8_VisionEncDec_audioProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change log:\n",
        "V8 aims to use the aspect list vs the caption in an attempt to reduce the inference stage from only predicting the most common tokens used in an English sentence such as \".\", \"the\", and \"a\"."
      ],
      "metadata": {
        "id": "a5G9UpMlHmnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation / Setup"
      ],
      "metadata": {
        "id": "BqoBQaJTH_iq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmkZlQnjPa1e",
        "outputId": "38bcfca0-8d93-4c99-f559-5e5f45b1e557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2023.11.16)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.19.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (6.0.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[audio]) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[audio]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (2023.11.17)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2023.3.post1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->datasets[audio]) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install yt-dlp\n",
        "# Install huggingface audio datasets\n",
        "! pip install datasets[audio]\n",
        "! pip install transformers evaluate jiwer\n",
        "!pip install accelerate -U\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlQ2aruLJOcz",
        "outputId": "3f0d60f5-b74c-4ff9-ce1b-80f49b909dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from datasets import load_dataset, Audio, Dataset, concatenate_datasets\n",
        "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, ASTFeatureExtractor\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import librosa\n",
        "import re\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlVjar3hKBXU",
        "outputId": "613c8b63-f31a-44d0-bafd-f64f6f42ed4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['ytid', 'start_s', 'end_s', 'audioset_positive_labels', 'aspect_list', 'caption', 'author_id', 'is_balanced_subset', 'is_audioset_eval'],\n",
              "    num_rows: 5521\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "ds = load_dataset('google/MusicCaps', split=\"train\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHy7po4X2o4j"
      },
      "outputs": [],
      "source": [
        "ds = ds.remove_columns([\"author_id\", \"is_balanced_subset\", \"is_audioset_eval\", \"audioset_positive_labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEyz2LDGzea4"
      },
      "source": [
        "# Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def process_aspect_list(example):\n",
        "  newList = []\n",
        "  aspect_list = example[\"aspect_list\"]\n",
        "  for word in word_tokenize(aspect_list):\n",
        "    cleaned_word = re.sub(r'[\\'\\[\\]\\(\\),]', ' ', word)\n",
        "    val = re.findall(r'\\w+|[^\\w\\s]', cleaned_word)\n",
        "    if(len(val) > 0):\n",
        "      newList.append(val[0])\n",
        "  example[\"aspect_list\"] = newList\n",
        "  return example\n",
        "\n",
        "\n",
        "ds = ds.map(\n",
        "    process_aspect_list,\n",
        "    num_proc=4,\n",
        "    writer_batch_size=1000,\n",
        "    keep_in_memory=False,\n",
        ")"
      ],
      "metadata": {
        "id": "6QpwkjLAKB56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0][\"aspect_list\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmBhTe6YKlQl",
        "outputId": "c0d29877-7719-41ed-8295-f9663a023e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['low',\n",
              " 'quality',\n",
              " 'sustained',\n",
              " 'strings',\n",
              " 'melody',\n",
              " 'soft',\n",
              " 'female',\n",
              " 'vocal',\n",
              " 'mellow',\n",
              " 'piano',\n",
              " 'melody',\n",
              " 'sad',\n",
              " 'soulful',\n",
              " 'ballad']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o72J0qczjNb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "# vocab_list = [\"word 1\", \"word 2\",  ..., \"word N\"]\n",
        "vocab_list = [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
        "max_len = 0\n",
        "vocab_count = {}\n",
        "maxLenItem = 0\n",
        "\n",
        "# Need to split on punctuation\n",
        "# I see some tokens such as \"funk/pop\" and singing.the - These should be separate\n",
        "\n",
        "def split_word(word):\n",
        "  # Removes brackets, commas, and single quotes from the corpus\n",
        "  word = re.sub(r'[\\'\\[\\]\\(\\),]', '', word)\n",
        "  return re.findall(r'\\w+|[^\\w\\s]', word)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(ds.num_rows):\n",
        "  aspect_list = ds[i][\"aspect_list\"]\n",
        "  if(len(aspect_list) > max_len):\n",
        "    max_len = len(aspect_list)+1\n",
        "    maxLenItem = i\n",
        "  for j in range(len(aspect_list)):\n",
        "    word = aspect_list[j].lower()\n",
        "    if(word) not in vocab_list:\n",
        "      vocab_list.append(word)\n",
        "      vocab_count[word] = 1\n",
        "    else:\n",
        "      vocab_count[word] += 1\n",
        "\n",
        "\n",
        "# for i in range(ds.num_rows):\n",
        "#   caption = ds[i][\"aspect_list\"]\n",
        "#   captionSplit = []\n",
        "#   # captionSplit = word_tokenize(ds[i][\"caption\"])\n",
        "#   for word in word_tokenize(caption):\n",
        "#     # word = word.replace(\".\", \"\")\n",
        "#     captionSplit.extend(split_word(word))\n",
        "#   if(len(captionSplit) > max_len):\n",
        "#     max_len = len(captionSplit)+1\n",
        "#   for j in range(len(captionSplit)):\n",
        "#     word = captionSplit[j].lower()\n",
        "#     if(word) not in vocab_list:\n",
        "#       vocab_list.append(word)\n",
        "#       vocab_count[word] = 1\n",
        "#     else:\n",
        "#       vocab_count[word] += 1\n",
        "\n",
        "# vocab_dict = { \"word\": index }\n",
        "vocab_dict = {}\n",
        "for i in range(len(vocab_list)):\n",
        "  vocab_dict[vocab_list[i]] = i"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sortedDict = dict(sorted(vocab_count.items(), key=lambda item: item[1]))\n",
        "print(sortedDict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub7FbnK-HAou",
        "outputId": "cedbc7e6-a6bf-40c8-ab5e-d3a9c599e14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'direct': 1, 'input': 1, 'suspended': 1, 'shuffling': 1, 'okay': 1, 'trills': 1, 'ornamentation': 1, 'thumps': 1, 'transposed': 1, 'canon': 1, 'mellody': 1, 'doorsteps': 1, 'improvement': 1, 'lip': 1, 'smack': 1, 'windpipe': 1, 'barbershop': 1, 'seconds': 1, 'zurna': 1, 'halay': 1, 'hyper': 1, 'exploring': 1, 'territory': 1, 'parts': 1, 'tireless': 1, 'antique': 1, 'knives': 1, 'hopeless': 1, 'parole': 1, 'imploring': 1, 'forgive': 1, 'enlightening': 1, 'nirvana': 1, 'endless': 1, 'catchybeat': 1, 'baraban': 1, 'distorting': 1, 'stumping': 1, 'ukrainian': 1, 'hips': 1, 'emphasisengaging': 1, 'carribean': 1, 'drumset': 1, 'hamster': 1, 'flash': 1, 'pianos': 1, 'circuit': 1, 'lightening': 1, 'electricity': 1, 'about': 1, 'olden': 1, 'squeal': 1, 'turntablism': 1, 'throat': 1, 'coordinated': 1, 'propeller': 1, 'drill': 1, 'cimbalom': 1, 'desi': 1, 'guitark': 1, 'eldery': 1, 'trimmings': 1, 'mixing': 1, 'timid': 1, 'cheerleaders': 1, 'sweeps': 1, 'provence': 1, 'repertoire': 1, 'stars': 1, 'al': 1, 'idle': 1, 'bored': 1, 'sleepdrone': 1, 'crouching': 1, 'twisted': 1, 'psychological': 1, 'satanic': 1, 'designed': 1, 'devilish': 1, 'jeepers': 1, 'malaysian': 1, 'discofunk': 1, 'rockballad': 1, 'customised': 1, 'cheerfully': 1, 'gallopy': 1, 'subtly': 1, 'reel': 1, 'alternative7rock': 1, 'gutiar': 1, 'percusion': 1, 'mameluke': 1, 'genial': 1, 'layerd': 1, 'melanchoic': 1, 'depressive': 1, 'aakar': 1, 'triad': 1, 'based': 1, 'dynamics': 1, 'halloween': 1, 'cruel': 1, 'hunting': 1, 'fascinating': 1, 'aquatic': 1, 'bandolero': 1, 'public': 1, 'comedicsong': 1, 'imitating': 1, 'mysticalm': 1, 'divas': 1, 'strikes': 1, 'better': 1, 'contact': 1, 'electromagnetic': 1, 'shatter': 1, 'fingerstile': 1, 'shamanic': 1, 'transcending': 1, 'devilishly': 1, 'kiss': 1, 'spot': 1, 'churchy': 1, 'sitarist': 1, 'ethic': 1, 'himdustani': 1, 'replacing': 1, 'patriotism': 1, 'whispers': 1, 'dutch': 1, 'nightcore': 1, 'adverticement': 1, 'jazzmusic': 1, 'safari': 1, 'luau': 1, 'spunk': 1, 'christmasmusic': 1, 'dry': 1, 'highly': 1, 'purring': 1, 'kizomba': 1, 'bedtime': 1, 'eurodance': 1, 'champeta': 1, 'mother': 1, 'earth': 1, 'rending': 1, 'genreș': 1, 'metallophone': 1, 'handicapped': 1, 'tourist': 1, 'look': 1, 'ma': 1, 'rotary': 1, 'rings': 1, 'fender': 1, 'everlasting': 1, '7th': 1, 'relief': 1, 'sedative': 1, 'tranquilizing': 1, 'release': 1, 'affirmation': 1, 'synthpad': 1, 'dotted': 1, 'sparse': 1, 'hoppy': 1, 'warming': 1, 'grove': 1, 'ecstatic': 1, 'nagpada': 1, 'vocalising': 1, 'baarat': 1, 'voracious': 1, 'uptemo': 1, 'promotion': 1, 'scratched': 1, 'tellers': 1, 'heroes': 1, 'villains': 1, 'stories': 1, 'frolic': 1, 'swimming': 1, 'pool': 1, 'cooing': 1, 'grinding': 1, 'tool': 1, 'factory': 1, 'fruitful': 1, 'victories': 1, 'splendour': 1, 'wrong': 1, 'boring': 1, 'unsteady': 1, 'drilling': 1, 'tero': 1, 'bellowing': 1, 'strumpets': 1, 'conversations': 1, 'trumpety': 1, 'relatable': 1, 'homer': 1, 'simpson': 1, 'sandhya': 1, 'raag': 1, 'gehu': 1, 'guqin': 1, 'lock': 1, 'uplifitng': 1, 'jet': 1, 'chapping': 1, 'precarious': 1, 'ambiguous': 1, 'contrast': 1, 'voclaist': 1, 'meditationmusic': 1, 'battlecry': 1, 'ackground': 1, 'overdubbing': 1, 'raking': 1, 'exploration': 1, 'curiousity': 1, 'freddie': 1, 'mercury': 1, 'hobbyist': 1, 'jig': 1, 'filipino': 1, 'refreshing': 1, 'mizwiz': 1, 'quantum': 1, 'goblet': 1, 'darl': 1, 'mooing': 1, 'goose': 1, 'eritrean': 1, 'hybrid': 1, 'midrange': 1, 'uzbek': 1, 'doira': 1, 'napoletana': 1, 'tunisian': 1, 'vietnamese': 1, 'meditating': 1, 'murmurs': 1, 'incomprehensible': 1, 'cubano': 1, 'folktronic': 1, 'tropics': 1, 'thick': 1, 'future': 1, 'clusters': 1, 'tropes': 1, 'fooling': 1, 'pamiri': 1, 'british': 1, 'xylophonist': 1, 'metalophone': 1, 'magicalvocalisation': 1, 'tehsil': 1, 'gangs': 1, 'lain': 1, 'dealing': 1, 'depression': 1, 'cameras': 1, 'ame': 1, 'splash': 1, 'basses': 1, 'guiros': 1, 'tube': 1, 'screamer': 1, 'bitter': 1, 'strokes': 1, 'americana': 1, 'gravelly': 1, 'got': 1, 'mail': 1, 'bassmarimba': 1, 'drink': 1, 'speechlow': 1, 'organic': 1, 'earthy': 1, 'kidssong': 1, 'sheriff': 1, 'lawmen': 1, 'hero': 1, 'tulna': 1, 'perseverance': 1, 'teenagers': 1, 'loudly': 1, 'pack': 1, 'boar': 1, 'attacking': 1, 'hunt': 1, 'wildlife': 1, 'prey': 1, 'food': 1, 'attack': 1, 'struggle': 1, 'calling': 1, 'girlish': 1, 'reflecting': 1, 'elanchoilic': 1, 'mufffled': 1, 'busker': 1, 'motivation': 1, 'scheming': 1, 'accents': 1, 'gamers': 1, 'projectile': 1, 'coordination': 1, 'unamplified': 1, 'motorbike': 1, 'celticmusic': 1, 'guitarlike': 1, 'timpanie': 1, 'chanter': 1, 'plonk': 1, 'complicated': 1, '70': 1, 'breakdown': 1, 'december': 1, 'slurring': 1, 'pull': 1, 'easter': 1, 'friday': 1, 'sere': 1, 'deafening': 1, 'plification': 1, 'acerbic': 1, 'shouts': 1, 'drumkit': 1, 'chuckles': 1, 'occult': 1, 'drumstep': 1, 'flying': 1, 'werewolf': 1, 'vielle': 1, 'dan': 1, 'gatherings': 1, 'togetherness': 1, 'custom': 1, 'tutari': 1, 'maharashtrian': 1, 'sringa': 1, 'buffalo': 1, 'c': 1, 'unfamiliar': 1, 'extemporaneous': 1, 'lao': 1, 'laotian': 1, 'synthesisers': 1, 'mismatch': 1, 'pantomime': 1, 'preaching': 1, 'sufimusic': 1, 'austria': 1, 'switzerland': 1, 'urba': 1, 'masterpiece': 1, 'foto': 1, 'burn': 1, 'drama': 1, 'wheels': 1, 'perfomrance': 1, 'collaboration': 1, 'mumbly': 1, 'overwhelming': 1, 'board': 1, 'pages': 1, 'kissing': 1, 'smacking': 1, 'straining': 1, 'imbalanced': 1, 'silastic': 1, 'fireworks': 1, 'chopper': 1, 'stringsound': 1, 'alpine': 1, 'venture': 1, 'mimicry': 1, 'spitting': 1, 'rolling': 1, 'tongues': 1, 'pingpong': 1, 'ambientmusic': 1, 'passages': 1, 'talented': 1, 'football': 1, 'synthesisation': 1, 'neurological': 1, 'paranoia': 1, 'rorschach': 1, 'fractal': 1, 'randomness': 1, 'buzzes': 1, 'chaos': 1, 'tonsl': 1, 'buzzz': 1, '1970': 1, 'wanderlust': 1, 'jeep': 1, 'stopping': 1, 'tarmac': 1, 'sadly': 1, 'greeting': 1, 'kumaoni': 1, 'bina': 1, 'muting': 1, 'sarod': 1, 'variety': 1, 'countdown': 1, 'buddha': 1, 'screenplay': 1, 'showdown': 1, 'cups': 1, 'issues': 1, 'left': 1, 'glitter': 1, 'spell': 1, 'letter': 1, 'way': 1, 'impressionable': 1, 'nadaswaram': 1, 'skurrile': 1, 'skate': 1, 'sakte': 1, 'hope': 1, 'warrior': 1, 'bleeding': 1, 'aisi': 1, 'cheesy': 1, 'curacao': 1, 'suite': 1, 'soundboard': 1, 'careless': 1, 'sundowner': 1, 'pealing': 1, 'tencion': 1, 'concentration': 1, 'chakras': 1, 'turnaround': 1, 'nasheed': 1, 'islamic': 1, '/': 1, 'hums': 1, 'things': 1, 'simlpe': 1, 'bedroom': 1, 'saz': 1, 'iranian': 1, 'tar': 1, 'daf': 1, 'seasonal': 1, 'warbled': 1, 'drunken': 1, 'stupor': 1, 'indistinct': 1, 'elbow': 1, 'mucus': 1, 'gadgets': 1, 'fake': 1, 'inorganic': 1, 'shoes': 1, 'settings': 1, 'resolution': 1, 'looped': 1, 'childhood': 1, 'wireless': 1, 'purity': 1, 'found': 1, 'striking': 1, 'alphabets': 1, 'lineage': 1, 'elegy': 1, 'salutation': 1, 'tag': 1, 'cumbria': 1, 'disconcerting': 1, 'superhit': 1, 'backups': 1, 'buttons': 1, 'staggered': 1, 'moroccan': 1, 'revelation': 1, 'b3': 1, 'laitin': 1, 'maxican': 1, 'folkrock': 1, 'snapshot': 1, 'indirock': 1, 'legend': 1, 'frustrated': 1, 'tin': 1, 'rotating': 1, 'platform': 1, 'elecronic': 1, 'riveting': 1, 'velcro': 1, 'metalrock': 1, 'seagull': 1, 'slang': 1, 'objectionable': 1, 'almost': 1, 'dungeon': 1, 'missed': 1, 'enterprising': 1, 'clubmusic': 1, 'resilience': 1, 'freedom': 1, 'hispanic': 1, 'awareness': 1, 'spots': 1, 'technopop': 1, 'cornets': 1, 'soundtracks': 1, 'warp': 1, 'bed': 1, 'jordanian': 1, 'rabab': 1, 'qaulity': 1, 'tarab': 1, 'andalusian': 1, 'avante': 1, 'it': 1, 'wonderful': 1, 'doomsday': 1, 'nightmarish': 1, 'hopelessness': 1, 'gregorian': 1, 'connected': 1, 'bonds': 1, 'supernatural': 1, 'virtuous': 1, 'steelpan': 1, 'torque': 1, 'phono': 1, 'output': 1, 'clubs': 1, 'buddhist': 1, 'da': 1, 'gamba': 1, 'hardware': 1, 'adult': 1, 'hurrying': 1, 'southside': 1, 'square': 1, 'temulous': 1, 'courage': 1, 'experiments': 1, 'picado': 1, 'stroke': 1, 'prrformance': 1, 'joys': 1, 'oercussions': 1, 'l': 1, 'plethora': 1, 'portugal': 1, 'synthbass': 1, 'glitchy': 1, 'jealous': 1, 'melodipiano': 1, 'emotiona': 1, 'brutal': 1, 'superhero': 1, 'districted': 1, 'seat': 1, 'medtiation': 1, 'geek': 1, 'ragga': 1, 'arp': 1, 'algerian': 1, 'rai': 1, 'washint': 1, 'prediction': 1, 'stock': 1, 'doors': 1, 'testosterone': 1, 'driven': 1, 'right': 1, 'held': 1, 'etherophone': 1, 'this': 1, 'honey': 1, 'mosquito': 1, 'bumble': 1, 'guitarș': 1, 'ghatak': 1, 'deities': 1, 'basset': 1, 'inauthentic': 1, 'throwing': 1, 'gaiety': 1, 'levity': 1, 'drummer': 1, 'entry': 1, 'business': 1, 'duty': 1, 'oman': 1, 'chase': 1, 'murderous': 1, 'huffing': 1, 'puffing': 1, 'chasing': 1, 'sou': 1, 'dsl': 1, 'banjomusic': 1, 'shadow': 1, 'unexpected': 1, 'paranormal': 1, 'baleful': 1, 'cocophony': 1, 'delightful': 1, 'commanding': 1, 'dragged': 1, 'cricket': 1, 'modulate': 1, 'grip': 1, 'raper': 1, 'uillean': 1, 'sand': 1, 'disney': 1, 'fairy': 1, 'tale': 1, 'plug': 1, 'breath': 1, 'stamp': 1, 'affecting': 1, 'plugging': 1, 'into': 1, 'rebellion': 1, 'syth': 1, 'feminism': 1, 'flirting': 1, 'innocence': 1, 'uncomplicated': 1, 'guide': 1, 'foreground': 1, 'descant': 1, 'descan': 1, 'lomba': 1, 'corresponding': 1, 'perform': 1, 'embouchure': 1, 'tick': 1, 'tock': 1, 'beginner': 1, 'diary': 1, 'nomads': 1, 'scatting': 1, 'scat': 1, 'generated': 1, 'boots': 1, 'intellectual': 1, 'swift': 1, 'chains': 1, 'pulled': 1, 'sparks': 1, 'thuds': 1, 'o': 1, 'f': 1, 'loved': 1, 'comically': 1, 'basseline': 1, 'island': 1, 'fiddler': 1, 'mome': 1, 'pujo': 1, 'picture': 1, 'clicked': 1, 'audios': 1, 'harpisichord': 1, 'gasping': 1, 'farting': 1, 'wings': 1, 'flapping': 1, 'scuttling': 1, 'psytrance': 1, 'irritated': 1, 'psy': 1, 'synthsounds': 1, 'enticing': 1, 'drawers': 1, 'evie': 1, 'mark': 1, 'lucas': 1, 'meal': 1, 'muffle': 1, 'coed': 1, 'accordian': 1, 'park': 1, 'elvis': 1, 'presley': 1, 'embedded': 1, 'pickups': 1, 'knife': 1, 'honing': 1, 'shimmer': 1, 'ghosts': 1, 'shivering': 1, 'trembling': 1, 'ballet': 1, 'alternate': 1, 'phrases': 1, 'spinning': 1, 'discs': 1, 'huayno': 1, 'andean': 1, 'percussionists': 1, 'arpeggiator': 1, 'li': 1, 'dveep': 1, 'reverbed': 1, 'kalimba': 1, 'schoenhut': 1, 'nai': 1, 'talkin': 1, 'trumelts': 1, 'kora': 1, 'damage': 1, 'critical': 1, 'excellent': 1, 'giants': 1, 'improvised': 1, 'lethargic': 1, 'uninteresting': 1, 'balls': 1, 'showman': 1, 'supporting': 1, 'crumbling': 1, 'bombing': 1, 'gujarati': 1, 'holy': 1, 'clocks': 1, 'pie': 1, 'devotee': 1, 'realisation': 1, 'electri': 1, 'lobby': 1, 'besame': 1, 'mucho': 1, 'basssound': 1, 'anticipa': 1, 'obscure': 1, 'incessantly': 1, 'phon': 1, 'kan': 1, 'consoling': 1, 'empowering': 1, 'produced': 1, 'guitarists': 1, 'vocable': 1, 'disorderly': 1, 'landscapes': 1, 'twilight': 1, 'practising': 1, 'homemjsic': 1, 'overuse': 1, 'amadinda': 1, 'verse': 1, 'sutras': 1, 'recitation': 1, 'shomyo': 1, 'incantation': 1, 'extatic': 1, 'blog': 1, 'acustic': 1, 'discomforting': 1, 'chac': 1, 'josies': 1, 'scarring': 1, 'daw': 1, 'emotionally': 1, 'die': 1, 'bossanova': 1, 'valentines': 1, 'sot': 1, 'switches': 1, 'tortuga': 1, 'martini': 1, 'using': 1, 'funeral': 1, 'trumped': 1, 'giro': 1, 'tenpo': 1, 'collectors': 1, 'choice': 1, 'pristine': 1, 'specials': 1, 'cult': 1, 'balkan': 1, 'confident': 1, 'meanings': 1, 'en': 1, 'wage': 1, 'sensory': 1, 'asanas': 1, 'suspicous': 1, 'mobile': 1, 'phones': 1, 'electroclash': 1, 'disappointment': 1, 'ridiculous': 1, 'vihuela': 1, 'mariachi': 1, 'empty': 1, 'shells': 1, 'causal': 1, 'preacher': 1, 'true': 1, 'tas': 1, 'tradition': 1, 'jittery': 1, 'injury': 1, 'mangled': 1, 'insistetnyouthful': 1, 'airway': 1, 'store': 1, 'differences': 1, 'cunfusion': 1, 'mild': 1, 'eurobeat': 1, 'android': 1, 'hindipop': 1, 'citar': 1, 'flirty': 1, 'let': 1, 'gently': 1, 'atonal': 1, 'advent': 1, 'slapstick': 1, 'martial': 1, 'arts': 1, 'paigu': 1, 'cellphone': 1, 'monosynth': 1, 'youthfull': 1, 'ancestry': 1, 'myriad': 1, 'diapason': 1, 'accompaniments': 1, 'disturbance': 1, 'biting': 1, 'selection': 1, 'select': 1, 'persistent': 1, 'friends': 1, 'parisian': 1, 'streets': 1, 'mini': 1, 'modulator': 1, 'somber': 1, 'protest': 1, 'counterculture': 1, '1960': 1, 'scratches': 1, 'chanson': 1, 'bike': 1, 'guiero': 1, 'discarded': 1, 'oil': 1, 'guider': 1, '909': 1, 'sensational': 1, 'woodwindninst': 1, 'gangster': 1, 't': 1, 'fiddlers': 1, 'angelically': 1, 'tritone': 1, 'variables': 1, 'request': 1, 'funkrock': 1, 'complaining': 1, 'n': 1, '1950': 1, 'season': 1, 'murder': 1, 'recordings': 1, 'syncopate': 1, 'urdu': 1, 'cloud': 1, 'electrostatic': 1, 'pianomusic': 1, 'soundsample': 1, 'montessori': 1, 'angel': 1, 'coke': 1, 'gradually': 1, 'percusssion': 1, 'lost': 1, 'defeated': 1, 'reload': 1, 'onset': 1, 'slows': 1, 'khartal': 1, 'sonata': 1, 'esraj': 1, 'downcast': 1, 'metalloud': 1, 'receptive': 1, 'descriptive': 1, 'automation': 1, 'idea': 1, 'transitions': 1, 'filling': 1, 'insect': 1, 'armenian': 1, 'rumbly': 1, 'balinese': 1, 'gambelan': 1, 'simplicity': 1, 'lacking': 1, 'cascading': 1, 'bland': 1, 'blocks': 1, 'insects': 1, 'tailpiece': 1, 'expertise': 1, 'lovely': 1, 'skillfull': 1, 'drowsy': 1, 'greatest': 1, 'eternal': 1, 'teacher': 1, 'unit': 1, 'gadget': 1, 'porn': 1, 'mocking': 1, 'whales': 1, 'bark': 1, 'beating': 1, 'terrified': 1, 'package': 1, 'infatuation': 1, 'frame': 1, 'cutouts': 1, 'skittering': 1, 'samoan': 1, 'acordian': 1, 'beatiful': 1, 'seven': 1, 'snippet': 1, 'morsing': 1, 'tooth': 1, 'magic': 1, 'cellar': 1, 'unknown': 1, 'swar': 1, 'cracklings': 1, 'batman': 1, 'processors': 1, 'generation': 1, 'sixties': 1, 'flower': 1, 'phrasing': 1, 'notesmonotone': 1, 'burst': 1, 'flicks': 1, 'form': 1, 'charitable': 1, 'organisation': 1, 'meg': 1, 'heartful': 1, 'digeridoo': 1, 'count': 1, 'reactance': 1, 'summer': 1, 'tingling': 1, 'psychotic': 1, 'repentance': 1, 'humility': 1, 'rehearsals': 1, 'peas': 1, 'cafe': 1, 'mania': 1, 'psychopath': 1, 'ttrumelts': 1, 'seagulls': 1, 'pacifying': 1, 'chapman': 1, 'bop': 1, 'product': 1, 'description': 1, 'harpsichordist': 1, 'slider': 1, 'scratchy': 1, 'muttering': 1, 'lurching': 1, 'creeping': 1, 'above': 1, 'spherical': 1, 'crisis': 1, 'exigency': 1, 'situation': 1, 'intesnse': 1, 'mechanical': 1, 'quaint': 1, 'malled': 1, 'sampler': 1, 'hihat': 1, 'gifts': 1, 'tingsha': 1, 'groo': 1, 'hillbilly': 1, 'trendy': 1, 'bubblegum': 1, 'burp': 1, 'disgusting': 1, 'popnrock': 1, 'sit': 1, 'inquest': 1, 'tollywood': 1, 'choking': 1, 'gardening': 1, 'machinery': 1, 'blades': 1, 'gruff': 1, 'vibraslap': 1, 'purposeful': 1, 'hardship': 1, 'seventies': 1, 'promotional': 1, 'ground': 1, 'aggresive': 1, 'dimuendo': 1, 'limits': 1, 'something': 1, 'droplet': 1, 'unplugged': 1, 'clavicembalo': 1, 'pannist': 1, 'stainless': 1, 'techo': 1, 'occasion': 1, 'ektare': 1, 'sapp': 1, 'tano': 1, 'barrel': 1, 'dholaki': 1, 'oftapping': 1, 'juvenile': 1, 'trailers': 1, 'flugelhorn': 1, 'aman': 1, 'motion': 1, 'schizophrenic': 1, 'flamboyant': 1, 'raspberries': 1, 'oceans': 1, 'tubey': 1, 'thunderstorm': 1, 'automobile': 1, 'tutn': 1, 'increase': 1, 'muscle': 1, 'gets': 1, 'horrorifying': 1, 'raising': 1, 'gallopping': 1, 'grasslands': 1, 'marshlands': 1, 'lyre': 1, 'surreal': 1, 'are': 1, 'scenario': 1, 'nuclear': 1, 'tambura': 1, 'regret': 1, 'synthesizers': 1, 'fm': 1, 'couple': 1, 'berimbau': 1, 'oohs': 1, 'aahs': 1, 'meaningless': 1, 'influenced': 1, 'blast': 1, 'inharmonious': 1, 'polished': 1, 'warbling': 1, 'bedouin': 1, 'tribes': 1, 'camels': 1, 'sun': 1, 'centuries': 1, 'impressionist': 1, 'classes': 1, 'prideful': 1, 'unintentional': 1, 'freaky': 1, 'exposition': 1, 'invasion': 1, 'charleston': 1, 'gurtural': 1, 'history': 1, 'finish': 1, 'climactic': 1, 'mis': 1, 'magnified': 1, 'randomly': 1, 'claviharp': 1, 'thirsty': 1, 'predatory': 1, 'ferocious': 1, 'insturm': 1, 'fully': 1, 'moment': 1, 'so': 1, 'beachside': 1, 'enjoy': 1, 'loungejazz': 1, 'upstroke': 1, 'akuba': 1, 'desolate': 1, 'wooshing': 1, 'furniture': 1, 'nails': 1, 'buses': 1, 'baptist': 1, 'last': 1, 'melbourne': 1, 'hyperactive': 1, 'maghreb': 1, 'attention': 1, 'aural': 1, 'visual': 1, 'intermittent': 1, 'faded': 1, 'ons': 1, 'basketball': 1, 'toner': 1, 'turntablist': 1, 'william': 1, 'byrd': 1, 'rowland': 1, 'grandeur': 1, 'court': 1, 'progrock': 1, 'hoe': 1, 'strung': 1, '9': 1, 'twoubadou': 1, 'intimidating': 1, 'rajasthani': 1, 'research': 1, 'error': 1, 'save': 1, 'dancer': 1, 'shaman': 1, 'yearned': 1, 'bassoons': 1, 'srone': 1, 'own': 1, 'fart': 1, 'jokes': 1, 'desk': 1, 'munching': 1, 'hare': 1, 'krishna': 1, 'sawing': 1, 'mediterranean': 1, 'crestfallen': 1, 'soundscape': 1, 'vibrational': 1, 'tree': 1, 'reindeer': 1, 'joyous': 1, 'dismal': 1, 'dreary': 1, 'ritardando': 1, 'sythesiser': 1, 'venezuelan': 1, 'housemusic': 1, 'goring': 1, 'sjic': 1, 'kickdrum': 1, 'frighting': 1, 'thunderstruck': 1, 'cheap': 1, 'cart': 1, 'round': 1, 'oldschool': 1, 'finale': 1, 'flageolet': 1, 'churchbell': 1, 'croatian': 1, 'barely': 1, 'ektar': 1, 'boudin': 1, 'melodiously': 1, 'tuneful': 1, 'homage': 1, 'paying': 1, 'rousing': 1, 'remembrance': 1, 'contra': 1, 'scracthing': 1, 'interventions': 1, 'rining': 1, 'uncomfortable': 1, 'ukuleles': 1, 'chalk': 1, 'blackboard': 1, 'faith': 1, 'texture': 1, 'stationary': 1, 'waiting': 1, 'channeling': 1, 'bassy': 1, 'maraca': 1, 'dizzying': 1, 'shuttle': 1, 'take': 1, 'rocket': 1, 'launcher': 1, 'dixie': 1, 'chicks': 1, 'muslim': 1, 'cubaine': 1, 'chest': 1, 'subwoofer': 1, 'allergissimo': 1, 'allegro': 1, 'extravagant': 1, 'spectacular': 1, 'celeste': 1, 'rat': 1, 'chining': 1, 'indie7rock': 1, 'powered': 1, 'explosive': 1, 'shocking': 1, 'disjointed': 1, 'mel': 1, 'bellchoir': 1, 'chrost': 1, 'excite': 1, 'best': 1, 'my': 1, 'struggles': 1, 'gang': 1, 'fights': 1, 'drug': 1, 'tough': 1, 'reciting': 1, 'resentment': 1, 'lion': 1, 'sufi': 1, 'forwarding': 1, 'lord': 1, 'instructor': 1, 'sedate': 1, 'trudge': 1, 'envelopes': 1, 'fluctuating': 1, 'nigthclubs': 1, 'militant': 1, 'soulfulromantic': 1, 'soulfu': 1, 'guita': 1, 'berserk': 1, 'popularity': 1, 'between': 1, 'carpool': 1, 'assertive': 1, 'neck': 1, 'pegs': 1, 'legs': 1, 'fixed': 1, 'cell': 1, 'beatle': 1, 'distortions': 1, 'odern': 1, 'licking': 1, 'layering': 1, 'synthesises': 1, 'seperate': 1, 'sigh': 1, 'enteric': 1, 'distance': 1, 'mellotron': 1, 'places': 1, 'senseof': 1, 'smoldering': 1, 'prodigy': 1, 'mashak': 1, 'ducky': 1, 'quack': 1, 'chakra': 1, 'alignment': 1, 'metalcore': 1, 'organist': 1, 'morals': 1, 'liens': 1, 'scissor': 1, 'sharpener': 1, 'hardbass': 1, 'hallucinatory': 1, 'yawning': 1, 'flourishing': 1, 'ringtone': 1, 'inner': 1, 'bicycle': 1, 'alpha': 1, 'stream': 1, 'vedic': 1, 'mindful': 1, 'sensuous': 1, 'staccatto': 1, 'artificial': 1, 'magnetic': 1, 'yoruba': 1, 'santeria': 1, 'candomble': 1, 'pandemonium': 1, 'binaural': 1, 'calmness': 1, 'stately': 1, 'noble': 1, 'counterpoint': 1, 'pub': 1, 'pepeasant': 1, 'perfection': 1, 'control': 1, 'caring': 1, 'sharing': 1, 'promises': 1, 'vows': 1, 'ke': 1, 'core': 1, 'combative': 1, 'belligerent': 1, 'dialing': 1, 'user': 1, 'mice': 1, '16th': 1, 'shutting': 1, 'narrow': 1, 'pochette': 1, 'relieving': 1, 'medicinal': 1, 'perfectly': 1, 'complimentary': 1, 'sentimenal': 1, 'chromatic': 1, 'banjos': 1, 'octane': 1, 'descendling': 1, 'per': 1, 'checklist': 1, 'scribbling': 1, 'outworldly': 1, 'perfect': 1, 'trumpeting': 1, 'gamesounds': 1, 'vic': 1, 'poignantly': 1, 'microtonal': 1, 'warble': 1, 'ternary': 1, 'strumms': 1, 'root': 1, 'fifth': 1, 'engines': 1, 'belching': 1, 'powerfull': 1, 'edelweiss': 1, 'sixteenth': 1, 'sidestick': 1, 'pretty': 1, 'clubbing': 1, 'euphoria': 1, 'omani': 1, 'measured': 1, 'doubles': 1, 'math': 1, 'congo': 1, 'regretful': 1, 'intricately': 1, 'coiled': 1, 'holding': 1, 'squid': 1, 'vigours': 1, 'agrgressive': 1, 'talent': 1, 'abs': 1, 'walkthrough': 1, 'garage': 1, 'cast': 1, 'fireball': 1, 'thundering': 1, 'reverberated': 1, '2010s': 1, 'sterile': 1, 'meditunique': 1, 'sidechain': 1, 'hurried': 1, 'clamorous': 1, 'seasoned': 1, 'powerfully': 1, 'elevator': 1, 'clattering': 1, 'preschool': 1, 'material': 1, 'schools': 1, 'zoo': 1, 'before': 1, 'sonatas': 1, 'hustlers': 1, 'money': 1, 'problems': 1, 'arpa': 1, 'jarocha': 1, '6': 1, 'sprechstimme': 1, 'folding': 1, 'retarding': 1, 'slowing': 1, 'marry': 1, 'saxophonist': 1, 'flourishes': 1, 'through': 1, 'stifled': 1, 'drunk': 1, 'censored': 1, 'naughty': 1, 'collapsing': 1, 'xbox': 1, 'beginnings': 1, 'spinal': 1, 'melodyspinal': 1, 'ohm': 1, 'fork': 1, 'digita': 1, 'monsters': 1, 'villainous': 1, 'actor': 1, 'sudden': 1, 'banger': 1, 'boxer': 1, 'failed': 1, 'attempt': 1, 'rubber': 1, 'terror': 1, 'gayageum': 1, 'nightclub': 1, 'poorly': 1, 'nosiness': 1, 'toubeleki': 1, 'splits': 1, 'asmr': 1, 'crackly': 1, 'grazing': 1, 'schol': 1, 'hmong': 1, 'shuffled': 1, 'bali': 1, 'kendang': 1, 'clickers': 1, 'unclear': 1, 'chatting': 1, 'xtra': 1, 'fix': 1, 'hindustan': 1, 'saraswati': 1, 'demonstartional': 1, 'guided': 1, 'averts': 1, 'secret': 1, 'agent': 1, 'woo': 1, 'her': 1, 'harmonybright': 1, 'horse': 1, 'cowboy': 1, 'beatboxer': 1, 'entertainer': 1, 'interactions': 1, 'kathak': 1, 'aorangi': 1, 'dixieland': 1, 'presence': 1, 'scraper': 1, 'chickens': 1, 'sheep': 1, 'cats': 1, 'pigs': 1, 'bodhran': 1, 'hallucinogenic': 1, 'xiao': 1, 'quartzophone': 1, 'quartzophonist': 1, 'brent': 1, 'awe': 1, 'brushing': 1, 'teeth': 1, 'claviorgan': 1, 'melodically': 1, 'authentic': 1, 'cupboard': 1, 'transformation': 1, 'habban': 1, 'pilipino': 1, 'beam': 1, 'sacrifice': 1, 'redemption': 1, 'backroundmusic': 1, 'resort': 1, 'fog': 1, 'legato': 1, 'klick': 1, 'incredible': 1, '3d': 1, 'psychophysics': 1, 'sensation': 1, 'stacatto': 1, 'multiharmony': 1, 'multitrack': 1, 'zhongshan': 1, 'nobo': 1, 'notice': 1, 'frog': 1, 'shred': 1, 'frenetic': 1, 'rev': 1, 'synthwave': 1, 'floghera': 1, 'units': 1, 'demos': 1, 'metallophones': 1, 'asain': 1, 'thumpy': 1, 'arangement': 1, 'miami': 1, 'larry': 1, 'happening': 1, 'paces': 1, 'husky': 1, 'kidsongs': 1, 'extended': 1, 'strange': 1, 'spillage': 1, 'sword': 1, 'slicing': 1, 'siredn': 1, 'chop': 1, 'sequences': 1, 'thank': 1, 'praises': 1, 'backdoor': 1, 'sow': 1, 'hills': 1, 'mountains': 1, 'gargling': 1, 'warriors': 1, 'dragon': 1, 'quest': 1, 'valour': 1, 'pride': 1, 'suoerfats': 1, 'lap': 1, 'ballade': 1, 'vocaloid': 1, 'miracles': 1, 'ade': 1, 'reindeers': 1, 'wrapper': 1, 'groupies': 1, 'bangers': 1, 'arnatic': 1, 'dissonance': 1, 'celebr': 1, 'conical': 1, 'bore': 1, 'hinduism': 1, 'exaltation': 1, 'cheerfull': 1, 'exemplary': 1, 'homemade': 1, 'earthquake': 1, 'enka': 1, 'pianist': 1, 'poly': 1, 'rhytms': 1, 'fuzz': 1, 'competition': 1, 'dancemood': 1, 'flutesound': 1, 'announcements': 1, 'funerals': 1, 'junkies': 1, 'riding': 1, 'youth': 1, 'heroic': 1, 'oboist': 1, 'charm': 1, 'brakes': 1, 'city': 1, 'officer': 1, 'criminal': 1, 'stillness': 1, 'aesthetic': 1, 'mellifluent': 1, 'madal': 1, 'reggeaton': 1, 'persian': 1, 'sway': 1, 'broadband': 1, 'wait': 1, 'expectation': 1, 'mediumto': 1, 'determination': 1, 'sportsmanship': 1, 'memdiumm': 1, 'g': 1, 'bavarian': 1, 'console': 1, 'packed': 1, 'heartthrob': 1, 'polyrhymic': 1, 'shape': 1, 'soundeffect': 1, 'mixes': 1, 'structure': 1, 'unobstructive': 1, 'barnyard': 1, 'lagging': 1, 'intuitive': 1, 'trick': 1, 'meets': 1, 'superstar': 1, 'deficiency': 1, 'overload': 1, 'used': 1, 'smal': 1, 'passonate': 1, 'breaths': 1, 'customary': 1, 'heartbreak': 1, 'pandeiro': 1, 'ruffling': 1, 'pranks': 1, 'just': 1, 'laughs': 1, 'energising': 1, 'trimmer': 1, 'innovation': 1, 'ethics': 1, 'technology': 1, 'minds': 1, 'rainfall': 1, 'need': 1, 'stro': 1, 'jaw': 1, 'haiti': 1, 'y': 1, 'deteriorating': 1, 'sputter': 1, 'entrance': 1, 'reunion': 1, 'gathering': 1, 'periodicity': 1, 'speeds': 1, 'study': 1, 'object': 1, 'cleaner': 1, 'skarock': 1, 'pre': 1, 'clapper': 1, 'dinosaur': 1, 'corporate': 1, 'clown': 1, 'alone': 1, 'goofing': 1, 'stop': 1, 'timbales': 1, 'poorer': 1, 'swoosh': 1, 'introductory': 1, 'shift': 1, 'shrieking': 1, 'spike': 1, 'bag': 1, 'crumpling': 1, 'significance': 1, 'ram': 1, 'wake': 1, 'authoritative': 1, 'bakcground': 1, 'rappers': 1, 'chindong': 1, 'gamemusic': 1, 'dropping': 1, 'shiny': 1, 'harpsichords': 1, 'elector': 1, 'mace': 1, 'missiles': 1, 'fair': 1, 'carnival': 1, 'swedish': 1, 'flick': 1, 'gruesome': 1, 'albanian': 1, 'guitat': 1, 'zen': 1, 'mideum': 1, 'whip': 1, 'cebuano': 1, 'disturbed': 1, 'cinco': 1, 'de': 1, 'mayo': 1, 'respect': 1, 'dead': 1, 'bands': 1, 'deterioration': 1, 'bulgarian': 1, 'instrumenatl': 1, 'showcasing': 1, 'czech': 1, 'despondent': 1, 'twinkling': 1, 'enjoying': 1, 'god': 1, 'slowed': 1, 'hunger': 1, 'hydraulophone': 1, 'azerbaijani': 1, 'amps': 1, 'buildup': 1, 'base': 1, 'hammered': 1, 'beautifully': 1, 'clarinetist': 1, 'precious': 1, 'cascade': 1, 'wow': 1, 'flutter': 1, 'send': 1, 'mehandi': 1, 'ceremony': 1, 'proverbs': 1, 'steadily': 1, 'ghazals': 1, 'ghazal': 1, 'tao': 1, 'handheld': 1, 'bumblebee': 1, 'twists': 1, 'edmdance': 1, 'pro': 1, 'indietronica': 1, 'royalty': 1, 'brassband': 1, 'repeat': 1, 'bubble': 1, 'trilling': 1, 'increases': 1, 'activism': 1, 'ceramic': 1, 'dancemusic': 1, 'exploding': 1, 'tumbling': 1, 'spook': 1, 'fearsome': 1, 'sheering': 1, 'function': 1, 'softer': 1, 'bowing': 1, 'procession': 1, 'didgeridoos': 1, 'performances': 1, 'groover': 1, 'steps': 1, 'transients': 1, 'pendulum': 1, 'vocabulary': 1, 'expansion': 1, 'latinmusic': 1, 'cuica': 1, 'ubeat': 1, 'chic': 1, 'ryymes': 1, 'rhumba': 1, 'ideo': 1, 'tumbao': 1, 'masterful': 1, 'tambirine': 1, 'rejoicing': 1, 'acc': 1, 'narrates': 1, 'dyi': 1, 'sirens': 1, 'gasp': 1, 'regular': 1, 'inducing': 1, 'utmost': 1, 'importance': 1, 'excishakers': 1, 'untintelligible': 1, 'simmering': 1, 'croaky': 1, 'adore': 1, 'benign': 1, 'accentuated': 1, 'fluid': 1, 'little': 1, 'pieces': 1, 'nose': 1, 'fugue': 1, 'chineze': 1, 'cracking': 1, 'vulcan': 1, 'classy': 1, 'differing': 1, 'fades': 1, 'banshee': 1, 'grimelectronic': 1, 'halluciatory': 1, 'roc': 1, 'bowling': 1, 'whine': 1, 'kanjira': 1, 'obscene': 1, 'anxious': 1, 'loosely': 1, 'structured': 1, 'trained': 1, 'hot': 1, 'gadam': 1, 'hocketing': 1, 'levels': 1, 'exorcism': 1, 'elves': 1, 'mirth': 1, 'wintertime': 1, 'signature': 1, 'screaching': 1, 'basssounds': 1, 'congressional': 1, 'intonation': 1, 'projection': 1, 'exhaust': 1, 'chicken': 1, 'clucking': 1, 'kilter': 1, 'dilla': 1, 'fountain': 1, 'caotic': 1, 'boating': 1, 'boing': 1, 'haze': 1, 'cries': 1, 'elec': 1, 'koboro': 1, 'rhythmi': 1, 'dvorak': 1, 'virtuously': 1, 'bangs': 1, 'sections': 1, 'six': 1, 'dreamscapes': 1, 'trudging': 1, 'disk': 1, 'jockey': 1, 'decks': 1, 'twin': 1, 'idiosyncratic': 1, 'shushing': 1, 'rollmusic': 1, 'brasssection': 1, 'emotion': 1, 'cyberwars': 1, 'indonesian': 1, 'raucous': 1, 'invigorating': 1, 'croacky': 1, 'identity': 1, 'cycle': 1, 'generational': 1, 'persia': 1, 'flow': 1, 'rubab': 2, 'twang': 2, 'darbuka': 2, 'renaissance': 2, 'iconic': 2, 'by': 2, 'sleepy': 2, 'drawer': 2, 'faint': 2, 'melodeon': 2, 'technically': 2, 'challenging': 2, 'kurdish': 2, 'baglama': 2, 'slowly': 2, 'fiction': 2, 'simulation': 2, 'hops': 2, 'clicky': 2, 'underwater': 2, 'beseeching': 2, 'ever': 2, 'm': 2, 'sorry': 2, 'ambiance': 2, 'rural': 2, 'pure': 2, 'polish': 2, 'manjira': 2, 'straightforward': 2, 'grass': 2, 'instrumentalist': 2, 'credits': 2, 'fanfare': 2, 'uprightbass': 2, 'duck': 2, 'days': 2, 'forgotten': 2, 'comfort': 2, 'narrative': 2, 'pans': 2, 'finnish': 2, 'bhangra': 2, 'samba': 2, 'elcetric': 2, 'china': 2, 'scare': 2, 'creeps': 2, 'desperate': 2, 'original': 2, 'sprightly': 2, 'well': 2, 'masterpieces': 2, 'paraguayan': 2, 'exstatic': 2, 'synchronous': 2, 'hymnal': 2, 'stadium': 2, 'overlapping': 2, 'playlists': 2, 'warmth': 2, 'native': 2, 'hypnotizing': 2, 'signals': 2, 'instrumentals': 2, 'unity': 2, 'loyalty': 2, 'croaking': 2, 'attitude': 2, 'or': 2, 'service': 2, 'blow': 2, 'rubbing': 2, 'amplifiers': 2, 'main': 2, 'strength': 2, 'flame': 2, 'surface': 2, 'zheng': 2, 'autoharp': 2, 'county': 2, 'soca': 2, 'hungarian': 2, 'drumroll': 2, 'searching': 2, 'jukebox': 2, 'men': 2, 'interaction': 2, 'pick': 2, 'plectrum': 2, 'gunslingers': 2, 'popsong': 2, 'friction': 2, 'disorganized': 2, 'buskers': 2, 'learner': 2, 'appealing': 2, 'circular': 2, 'passionately': 2, 'tron': 2, 'erhu': 2, 'sikh': 2, 'savage': 2, 'rehearse': 2, 'queen': 2, 'talk': 2, 'excessive': 2, 'tarantella': 2, 'potent': 2, 'slapped': 2, 'crossover': 2, 'boiling': 2, 'am': 2, 'broken': 2, 'trashy': 2, 'block': 2, 'po': 2, 'rumba': 2, 'concrete': 2, 'timpanis': 2, 've': 2, 'electroni': 2, 'triumphantly': 2, 'wolf': 2, 'squealing': 2, 'painful': 2, 'times': 2, 'imbalance': 2, 'layered': 2, 'guns': 2, 'education': 2, 'piper': 2, 'joy': 2, 'swishing': 2, 'snowfall': 2, 'rhtyhm': 2, 'swinging': 2, 'afropop': 2, 'gibberish': 2, 'plates': 2, 'jingles': 2, 'portable': 2, 'away': 2, 'historical': 2, 'violinist': 2, 'shaped': 2, 'hynoptic': 2, 'laos': 2, 'urgent': 2, 'turntables': 2, 'modules': 2, 'asphalt': 2, 'blown': 2, 'clasical': 2, 'orleans': 2, 'era': 2, 'claves': 2, 'rumbling': 2, 'godfather': 2, 'sneaky': 2, 'tricky': 2, 'intrigue': 2, 'glorious': 2, 'pressing': 2, 'annoying': 2, 'chewing': 2, 'thud': 2, 'leads': 2, 'cabaret': 2, 'match': 2, 'whizzing': 2, 'brain': 2, 'tonal': 2, 'pleasing': 2, 'message': 2, 'pakistani': 2, 'sympathetic': 2, 'pitches': 2, 'khaliji': 2, 'profanity': 2, 'anger': 2, 'coffee': 2, 'themes': 2, 'stoic': 2, 'crack': 2, '90s': 2, 'spelling': 2, 'made': 2, 'colorful': 2, 'whining': 2, 'wondrous': 2, 'cheeky': 2, 'naturesounds': 2, 'morning': 2, 'festivals': 2, 'mantras': 2, 'hamony': 2, 'bach': 2, 'fingering': 2, 'squishy': 2, 'chiming': 2, 'much': 2, 'burning': 2, 'diy': 2, 'ducking': 2, 'minimalistic': 2, 'moog': 2, 'dire': 2, 'taiko': 2, 'altered': 2, 'skills': 2, 'doorbell': 2, 'spirituality': 2, 'each': 2, 'oldest': 2, 'catholic': 2, 'stylish': 2, 'favourites': 2, 'eclectic': 2, 'mismatched': 2, 'agitated': 2, 'queens': 2, 'reading': 2, 'qin': 2, 'dizi': 2, 'professional': 2, 'still': 2, 'environment': 2, 'pong': 2, 'angst': 2, 'pumping': 2, 'shekere': 2, '2': 2, 'arpeggiate': 2, 'enjoyable': 2, 'forceful': 2, 'scissors': 2, 'steeldrums': 2, 'sneeze': 2, 'apocalypse': 2, 'dread': 2, 'orthodox': 2, 'wonders': 2, 'edgy': 2, 'monks': 2, 'whimsical': 2, 'elecronica': 2, 'spirted': 2, 'elctro': 2, 'conviction': 2, 'ponderous': 2, 'babies': 2, 'holidays': 2, 'happiness': 2, 'ghungaroos': 2, 'chicago': 2, 'dilruba': 2, 'gratitude': 2, 'honour': 2, 'noir': 2, 'regimented': 2, 'mourning': 2, 'gameplay': 2, 'sfx': 2, 'thereminist': 2, 'unusual': 2, 'knobs': 2, 'jugalbandi': 2, 'soldiers': 2, 'phrase': 2, 'padsounds': 2, 'subbass': 2, 'professionally': 2, 'popmusic': 2, 'feminist': 2, 'massive': 2, 'egyptian': 2, 'clinking': 2, 'person': 2, 'typing': 2, 'shout': 2, 'experiences': 2, 'paradise': 2, 'peruvian': 2, 'arab': 2, 'clothes': 2, 'fitness': 2, 'twelve': 2, 'woodblock': 2, 'merrily': 2, 'applied': 2, 'news': 2, 'report': 2, 'telugu': 2, 'performers': 2, 'gym': 2, 'solid': 2, 'octave': 2, 'instructions': 2, 'downward': 2, 'destructive': 2, 'acousitc': 2, 'bellsounds': 2, 'rough': 2, 'arranged': 2, 'animate': 2, 'stings': 2, 'serenity': 2, 'wop': 2, 'ugandan': 2, 'tutor': 2, 'dual': 2, 'carrie': 2, 'setup': 2, 'bursts': 2, 'silent': 2, 'say': 2, 'melisma': 2, 'tribute': 2, 'shutter': 2, 'affair': 2, 'sluice': 2, 'supercar': 2, 'impressive': 2, 'castanets': 2, 'connection': 2, 'explore': 2, 'speeding': 2, 'backgroundnoises': 2, 'tongue': 2, 'electronics': 2, 'crunching': 2, 'gated': 2, 'slangy': 2, 'firing': 2, 'riq': 2, 'speakers': 2, 'vociferous': 2, 'thriller': 2, 'friendship': 2, 'emotions': 2, 'mode': 2, 'cut': 2, 'urgency': 2, 'get': 2, 'recycled': 2, 'uilleann': 2, 'charged': 2, 'beauty': 2, '90': 2, 'smart': 2, 'violinists': 2, 'foreboding': 2, 'always': 2, 'modulating': 2, 'crime': 2, 'snap': 2, 'same': 2, 'learn': 2, 'delight': 2, 'tala': 2, 'mandira': 2, 'smashing': 2, 'unearthly': 2, 'chordophone': 2, 'dive': 2, 'cartoony': 2, 'kid': 2, 'softly': 2, 'sings': 2, 'wine': 2, 'glasses': 2, 'triplets': 2, 'stops': 2, 'manjeera': 2, 'leg': 2, 'trailer': 2, 'team': 2, 'goddess': 2, 'ghatam': 2, 'doom': 2, 'coming': 2, 'dainty': 2, 'rom': 2, 'tonguing': 2, 'ghostly': 2, 'sublime': 2, 'immersive': 2, 'songwriter': 2, 'crazy': 2, 'volatile': 2, 'sipping': 2, 'conductors': 2, 'threshold': 2, 'emergency': 2, 'panic': 2, 'toilet': 2, 'flushing': 2, 'sextet': 2, 'lofi': 2, 'swells': 2, 'oompah': 2, 'clipping': 2, 'ektara': 2, 'onomatopoeia': 2, 'filler': 2, 'auxiliary': 2, '50s': 2, 'tear': 2, 'how': 2, 'lightning': 2, 'maximalist': 2, 'switch': 2, 'synthesis': 2, 'konkani': 2, 'kriti': 2, 'bubbles': 2, 'dial': 2, 'blood': 2, 'beast': 2, 'moving': 2, 'someone': 2, 'nigerian': 2, 'propulsive': 2, 'piercing': 2, 'road': 2, 'preach': 2, 'toddler': 2, 'development': 2, 'stimulation': 2, 'chopped': 2, 'icelandic': 2, 'quarter': 2, 'greta': 2, 'titanic': 2, 'suggestive': 2, 'interesting': 2, 'current': 2, 'rebab': 2, 'swiping': 2, 'wah': 2, 'humour': 2, 'killing': 2, 'military': 2, 'broadway': 2, 'mandoline': 2, 'fairytale': 2, 'medley': 2, 'bull': 2, 'crooners': 2, 'sustain': 2, 'bhangara': 2, 'bagpipers': 2, 'writing': 2, 'screech': 2, 'portuguese': 2, 'state': 2, 'lingering': 2, 'dripping': 2, 'grave': 2, 'zither': 2, 'tanggu': 2, 'exhilarating': 2, 'screechy': 2, 'ghetto': 2, 'garbled': 2, 'def': 2, 'accelerated': 2, 'lecture': 2, 'passion': 2, 'against': 2, 'odds': 2, 'going': 2, 'vehement': 2, 'dominating': 2, 'bhakti': 2, 'skillful': 2, 'folksong': 2, 'shows': 2, 'imposing': 2, 'tire': 2, 'polyphonic': 2, 'glassy': 2, 'keeping': 2, 'buddhism': 2, 'vacuum': 2, 'papery': 2, 'afrodance': 2, 'chilled': 2, 'sniffing': 2, 'synced': 2, 'crystal': 2, 'tuner': 2, 'revving': 2, 'treble': 2, 'step': 2, 'voiceover': 2, 'counting': 2, 'shop': 2, 'nepali': 2, 'advertising': 2, 'accordions': 2, 'perforamnce': 2, 'ragtime': 2, 'backround': 2, 'walk': 2, 'treatment': 2, 'cartoons': 2, 'flourish': 2, 'king': 2, 'too': 2, 'clashing': 2, 'skill': 2, 'contrasting': 2, 'oink': 2, 'agony': 2, 'as': 2, 'silly': 2, 'maestro': 2, 'idiophone': 2, 'hammering': 2, 'fashion': 2, 'loving': 2, 'congos': 2, 'accident': 2, 'lego': 2, 'proto': 2, 'advanced': 2, 'ritual': 2, 'deer': 2, 'papers': 2, 'solutions': 2, 'hindustaani': 2, 'social': 2, 'bugle': 2, 'artists': 2, 'circus': 2, 'celebrating': 2, 'truths': 2, 'human': 2, 'timer': 2, 'snipping': 3, 'fretboard': 3, 'd': 3, 'irritating': 3, 'imposed': 3, 'unimpressive': 3, 'swiss': 3, 'arabesque': 3, 'mimicking': 3, 'airplane': 3, 'streaming': 3, 'pleading': 3, 'expressive': 3, 'i': 3, 'innocent': 3, 'cuban': 3, 'feet': 3, 'creative': 3, 'poprock': 3, 'interlude': 3, 'animation': 3, 'adorable': 3, 'tubular': 3, 'stimulating': 3, 'ducks': 3, 'quacking': 3, 'pig': 3, 'bouzouki': 3, 'design': 3, 'college': 3, 'beeps': 3, 'solos': 3, 'hippie': 3, 'extremely': 3, 'elderly': 3, 'dolphin': 3, 'words': 3, 'cuatro': 3, 'treat': 3, 'j': 3, 'half': 3, 'lips': 3, 'watch': 3, 'carol': 3, 'arena': 3, 'separate': 3, 'teens': 3, 'not': 3, 'focused': 3, 'sine': 3, 'emotive': 3, 'somali': 3, 'zipper': 3, 'explicit': 3, 'dirty': 3, 'eloquent': 3, 'passioante': 3, 'choreography': 3, 'rhyming': 3, 'basic': 3, 'cathedral': 3, 'unnatural': 3, 'hardrock': 3, 'grooves': 3, 'manically': 3, 'strum': 3, 'grating': 3, 'om': 3, 'stress': 3, 'focus': 3, 'environmental': 3, 'sighing': 3, 'synthpop': 3, 'west': 3, 'bouncing': 3, 'glory': 3, 'eighties': 3, 'side': 3, 'fervour': 3, 'threatening': 3, 'violas': 3, 'channel': 3, 'mashup': 3, 'modulation': 3, 'militaristic': 3, 'garmon': 3, 'button': 3, 'patterns': 3, 'yoga': 3, 'accomapniment': 3, 'shrill': 3, 'cold': 3, 'stretched': 3, 'skateboarding': 3, 'pandeireta': 3, 'depressed': 3, 'wolves': 3, 'vehicle': 3, 'bleating': 3, 'crispy': 3, 'silky': 3, 'bellows': 3, 'picked': 3, 'cumbia': 3, 'fry': 3, 'chain': 3, 'gamelan': 3, 'sultry': 3, 'vamp': 3, 'women': 3, 'wars': 3, 'dialogue': 3, 'india': 3, 'auditorium': 3, 'comparison': 3, 'ardent': 3, 'talks': 3, 'innovative': 3, 'mario': 3, 'roller': 3, 'skating': 3, 'hostile': 3, 'reggaeton': 3, 'reverse': 3, 'scientific': 3, 'sanskrit': 3, 'roots': 3, 'motown': 3, 'timeless': 3, 'palm': 3, 'congregation': 3, 'climax': 3, 'bossa': 3, 'nova': 3, 'bluesrock': 3, 'windy': 3, 'cellist': 3, 'ibiza': 3, 'shifting': 3, 'gongs': 3, 'natural': 3, 'skateboard': 3, 'hazy': 3, 'intriguing': 3, 'transverse': 3, 'electrical': 3, 'ring': 3, 'punching': 3, 'midi': 3, 'whammy': 3, 'vernacular': 3, 'wonder': 3, 'train': 3, 'objects': 3, 'cutting': 3, 'cream': 3, 'choppy': 3, 'kings': 3, 'tragedy': 3, 'sight': 3, 'breaks': 3, 'compressed': 3, 'groaning': 3, 'grief': 3, 'backgroundmusic': 3, 'ping': 3, 'raaga': 3, 'anticipatory': 3, 'sweeping': 3, 'cash': 3, 'run': 3, 'kindness': 3, 'peace': 3, 'generator': 3, 'peculiar': 3, 'gripping': 3, 'landscape': 3, 'felt': 3, 'cosmic': 3, 'discovery': 3, 'burly': 3, 'compound': 3, 'effected': 3, 'northern': 3, 'sleeping': 3, 'snow': 3, 'sing': 3, 'aristocracy': 3, 'santoor': 3, 'footstep': 3, 'from': 3, 'blasting': 3, 'cutout': 3, 'goosebumps': 3, 'introspective': 3, 'tight': 3, 'rudiments': 3, 'fighting': 3, 'masenqo': 3, 'slamming': 3, 'panned': 3, 'storytelling': 3, 'slapping': 3, 'ragas': 3, 'virtual': 3, 'synthetic': 3, 'sense': 3, 'bebop': 3, 'furiously': 3, 'chair': 3, 'knob': 3, 'turns': 3, 'making': 3, 'folklore': 3, 'elevating': 3, 'bomb': 3, 'scales': 3, 'altai': 3, 'combat': 3, 'rituals': 3, 'conch': 3, 'gangsta': 3, 'movement': 3, 'horrifying': 3, 'sexy': 3, 'carousel': 3, 'fear': 3, 'haunted': 3, 'additive': 3, 'ocean': 3, 'passing': 3, 'conversation': 3, 'accordeon': 3, 'commentary': 3, 'legendary': 3, 'rattling': 3, 'dominant': 3, 'therapeutic': 3, 'hype': 3, 'idyllic': 3, 'pause': 3, 'electronically': 3, 'beginning': 3, 'vinyls': 3, 'doo': 3, 'leaking': 3, 'tutorials': 3, 'pipa': 3, 'bamboo': 3, 'thunderous': 3, 'fiesta': 3, 'styles': 3, 'cars': 3, 'sarcastic': 3, 'abrupt': 3, 'woogie': 3, 'your': 3, 'rocksteady': 3, 'adoration': 3, 'discordant': 3, 'tremulous': 3, 'tranquility': 3, 'toys': 3, 'collage': 3, 'large': 3, 'starting': 3, 'rim': 3, 'repair': 3, 'mosh': 3, 'pit': 3, 'sarangi': 3, 'mythology': 3, 'temple': 3, 'comical': 3, 'mallets': 3, 'transition': 3, 'alap': 3, 'australian': 3, 'restless': 3, 'bodied': 3, 'spine': 3, 'testing': 3, 'guttural': 3, 'glitch': 3, 'sorrowful': 3, 'sincere': 3, 'drumline': 3, 'punch': 3, 'rugged': 3, 'videogame': 3, 'trip': 3, 'sped': 3, '12': 3, 'cowbells': 3, 'roar': 3, 'hair': 3, 'having': 3, 'momentous': 3, 'irregular': 3, 'informal': 3, 'heritage': 3, 'mic': 3, 'private': 3, 'lifetime': 3, 'impending': 3, 'informative': 3, 'office': 3, 'printer': 3, 'sonorous': 3, 'kazoo': 3, 'indo': 3, 'audible': 3, 'swung': 3, 'quintet': 3, 'defiant': 3, 'jive': 3, 'controlled': 3, 'extreme': 3, 'slight': 3, 'virtuosos': 3, 'processing': 3, 'waterfall': 3, 'bridal': 3, 'moments': 3, 'steeldrum': 4, 'mediocre': 4, 'monologue': 4, 'grunt': 4, 'dulcimer': 4, 'speaker': 4, 'longing': 4, 'soundeffects': 4, 'closing': 4, 'pastoral': 4, 'zumba': 4, 'machines': 4, 'traditions': 4, 'doubling': 4, 'terrifying': 4, 'timbale': 4, 'proposal': 4, 'brushes': 4, 'change': 4, 'fingerpicking': 4, 'ethiopian': 4, 'imitation': 4, 'contrabass': 4, 'polka': 4, 'earnest': 4, 'snares': 4, 'abstract': 4, 'insightful': 4, 'contemplative': 4, 'loneliness': 4, 'chainsaw': 4, 'whale': 4, 'relaxation': 4, 'air': 4, 'bit': 4, 'touching': 4, 'deck': 4, 'faster': 4, 'enegetic': 4, 'routine': 4, 'counter': 4, 'turner': 4, 'gliding': 4, 'rhodes': 4, 'wobble': 4, 'adventures': 4, 'sacred': 4, 'north': 4, 'multi': 4, 'cowboys': 4, 'hysteria': 4, 'pomp': 4, 'semi': 4, 'childish': 4, 'surf': 4, 'clave': 4, 'basslines': 4, 'drones': 4, 'plucks': 4, 'word': 4, 'giggling': 4, 'body': 4, 'creaking': 4, 'afghan': 4, 'bubbling': 4, 'ship': 4, 'records': 4, 'ost': 4, 'refrain': 4, 'encouraging': 4, 'hammer': 4, 'discotheque': 4, 'check': 4, 'moody': 4, 'synchronized': 4, 'interactive': 4, 'rhymes': 4, 'nu': 4, 'fiery': 4, 'jumping': 4, 'east': 4, 'mystic': 4, 'growly': 4, 'stab': 4, 'versatile': 4, 'forest': 4, 'famous': 4, 'repeating': 4, 'missing': 4, 'duel': 4, 'operatic': 4, 'charismatic': 4, 'improvisations': 4, 'turning': 4, 'progressions': 4, 'acoustics': 4, 'favourite': 4, 'crooning': 4, 'mezzo': 4, 'pulse': 4, 'phonograph': 4, 'atmospherical': 4, 'test': 4, 'confusion': 4, 'bhajan': 4, 'strums': 4, 'phaser': 4, 'frightening': 4, 'thai': 4, 'therapy': 4, 'narrating': 4, 'teenage': 4, 'knocking': 4, 'qanun': 4, 'spirits': 4, 'jolly': 4, 'bleak': 4, 'truck': 4, 'hardstyle': 4, 'musc': 4, 'yelling': 4, 'module': 4, 'sessions': 4, 'monoton': 4, 'sunday': 4, 'set': 4, 'movies': 4, 'untiring': 4, 'majestic': 4, 'pentatonic': 4, 'glam': 4, 'pipe': 4, 'increasing': 4, 'badly': 4, 'motifs': 4, 'brazilian': 4, 'van': 4, 'ambulance': 4, 'tragic': 4, 'loop': 4, 'lighthearted': 4, 'gunshot': 4, 'teaching': 4, 'keyboards': 4, 'hebrew': 4, 'go': 4, 'accompanying': 4, 'belly': 4, 'casual': 4, 'cough': 4, 'racing': 4, 'fills': 4, 'mumbling': 4, 'coughing': 4, 'international': 4, 'liquid': 4, 'tango': 4, 'parade': 4, 'concerto': 4, 'culture': 4, 'sands': 4, '80': 4, 'syncopation': 4, 'important': 4, 'honking': 4, 'work': 4, 'national': 4, 'outside': 4, 'clip': 4, 'customs': 4, 'program': 5, 'paper': 5, 'gothic': 5, 'optimistic': 5, 'science': 5, 'transcendental': 5, 'harmonic': 5, 'master': 5, 'rhythmically': 5, 'kicks': 5, 'cow': 5, 'anime': 5, 'bachata': 5, 'colourful': 5, 'galloping': 5, 'blue': 5, 'cute': 5, 'series': 5, 'bagpiper': 5, 'performer': 5, 'fat': 5, 'storm': 5, 'animals': 5, 'yodel': 5, 'hymns': 5, 'laugh': 5, 'inhale': 5, 'monotonous': 5, 'covers': 5, 'action': 5, 'deliberate': 5, 'artist': 5, 'carefree': 5, 'doubled': 5, 'growl': 5, 'lounge': 5, 'emo': 5, 'sync': 5, 'greek': 5, '8': 5, 'jungle': 5, 'click': 5, 'goat': 5, 'roomy': 5, 'part': 5, 'rides': 5, 'freestyle': 5, 'shredding': 5, 'euro': 5, 'instruction': 5, 'special': 5, 'dholak': 5, 'winds': 5, 'interview': 5, 'fearful': 5, 'traffic': 5, 'spring': 5, 'viloin': 5, 'techniques': 5, 'spoken': 5, 'goofy': 5, 'electropop': 5, 'around': 5, 'reverberating': 5, 'hood': 5, 'hurt': 5, 'odd': 5, 'mallet': 5, 'face': 5, 'bravado': 5, 'underground': 5, 'vivid': 5, 'pipes': 5, 'wonderland': 5, 'presents': 5, 'screams': 5, 'whistles': 5, 'soap': 5, 'glissando': 5, 'make': 5, 'crackle': 5, 'agressive': 5, 'downtempo': 5, 'urbano': 5, 'bassoon': 5, 'hammond': 5, 'girls': 5, 'layer': 5, 'djembe': 5, 'evil': 5, 'wheel': 5, 'sports': 5, 'helicopter': 5, 'manipulation': 5, 'breaking': 5, 'childlike': 5, 'exercise': 5, 'skilful': 5, 'lush': 5, 'an': 5, 'breezy': 5, 'prayerful': 5, 'fire': 5, 'self': 5, 'fret': 5, 'avant': 5, 'games': 5, 'throbbing': 5, 'uneasy': 5, 'arabian': 5, 'stomping': 5, 'thudding': 5, 'prayers': 5, 'dancehall': 5, 'detuned': 5, 'ney': 5, 'cembalo': 5, 'bee': 5, 'being': 5, 'evolving': 5, 'improvisational': 5, 'feeling': 5, 'bengali': 5, 'burping': 5, 'tech': 5, 'virtuosic': 5, 'theatrical': 5, 'birthday': 5, 'players': 5, 'celli': 5, 'scratch': 5, 'army': 5, 'zitar': 5, 'dream': 5, 'post': 5, 'friendly': 5, 'grunts': 5, 'fx': 5, 'angry': 5, 'octaves': 6, 'shrutibox': 6, 'dexterous': 6, 'quick': 6, 'screeching': 6, 'common': 6, 'neo': 6, 'clicks': 6, 'me': 6, 'war': 6, 'cry': 6, 'thunder': 6, 'mind': 6, 'toddlers': 6, 'gypsy': 6, 'musicians': 6, 'mouth': 6, 'at': 6, 'romanian': 6, 'dhol': 6, 'popping': 6, 'exhale': 6, 'granular': 6, 'sticks': 6, 'dexterity': 6, 'speed': 6, 'courtship': 6, 'sampled': 6, 'winter': 6, 'jarring': 6, 'chirpy': 6, 'festival': 6, 'vibrating': 6, 'varying': 6, 'ice': 6, 'signal': 6, 'sleep': 6, 'hawaiian': 6, 'heavenly': 6, 'jovial': 6, 'inaudible': 6, 'memories': 6, '80s': 6, 'ball': 6, 'fill': 6, 'sensitive': 6, 'clarinets': 6, 'taal': 6, 'sruti': 6, 'synthesized': 6, 'outro': 6, 'gritty': 6, 'accent': 6, 'lo': 6, '2000s': 6, 'breakbeat': 6, 'harmonics': 6, 'blasts': 6, 'active': 6, 'saw': 6, 'head': 6, 'score': 6, 'star': 6, 'unnerving': 6, 'boogie': 6, 'lyrical': 6, 'libs': 6, 'shot': 6, 'sleigh': 6, 'ascending': 6, 'normal': 6, 'experiment': 6, 'pizzicato': 6, 'inspired': 6, 'reverence': 6, 'stage': 6, 'nights': 6, 'rhyme': 6, 'punkrock': 6, 'hum': 6, 'cajun': 6, 'nasal': 6, 'monster': 6, 'sadness': 6, 'menacing': 6, 'bustling': 6, 'disturbing': 6, 'standing': 6, 'chilling': 6, 'rehearsal': 6, 'mridangam': 6, 'tubas': 6, 'dobro': 6, 'recorded': 6, 'countermelody': 6, 'shell': 6, 'confusing': 6, 'hiss': 6, 'triumphant': 6, 'violence': 6, 'descending': 6, 'regal': 6, 'shots': 6, 'gloomy': 6, 'motor': 6, 'desert': 6, 'experience': 6, 'day': 6, 'victorious': 6, 'three': 7, 'black': 7, 'skilled': 7, 'mystery': 7, 'chipmunk': 7, 'non': 7, 'scuffling': 7, 'class': 7, 'tender': 7, 'rain': 7, 'kindergarten': 7, 'european': 7, 'fervent': 7, 'shuttering': 7, 'congregational': 7, 'metronome': 7, 'solemn': 7, 'picking': 7, 'veena': 7, 'film': 7, 'hooting': 7, 'vital': 7, 'elctronic': 7, 'swell': 7, 'patriotic': 7, 'emphasis': 7, 'slightly': 7, 'family': 7, 'ethnic': 7, 'soaring': 7, 'response': 7, 'scraping': 7, 'cheery': 7, 'throaty': 7, 'feed': 7, 'duo': 7, 'laid': 7, 'busking': 7, 'woman': 7, 'backbeat': 7, 'clear': 7, 'oboe': 7, 'tamil': 7, 'alien': 7, 'cheer': 7, 'bluesy': 7, 'magical': 7, 'oboes': 7, 'first': 7, 'meter': 7, 'wobbly': 7, 'roaring': 7, 'driving': 7, 'hymn': 7, 'synths': 7, 'foley': 7, 'scream': 7, 'couples': 7, 'glockenspiel': 7, 'boys': 7, 'mod': 7, 'gunshots': 7, 'guzheng': 7, 'scene': 7, 'rattle': 7, 'fight': 7, 'puja': 7, 'beach': 7, 'overtones': 7, 'german': 7, 'bar': 7, 'tempos': 7, 'empahtic': 7, 'sea': 7, 'changing': 7, 'creating': 7, 'continuous': 7, 'flanger': 7, 'english': 7, 'festivities': 7, 'sequence': 7, 'computer': 7, 'foot': 7, 'recital': 7, 'twangy': 7, 'ticking': 7, 'brush': 7, 'grandiose': 7, 'volume': 8, 'hollering': 8, 'crescendo': 8, 'resonance': 8, 'crisp': 8, 'harmonious': 8, 'sci': 8, 'comforting': 8, 'amusing': 8, 'explosion': 8, 'fantasy': 8, 'art': 8, 'heartbeat': 8, 'major': 8, 'clanging': 8, 'frequencies': 8, 'vocoder': 8, 'percussionist': 8, 'erotic': 8, 'wistful': 8, 'multiple': 8, 'buzz': 8, 'squeaky': 8, 'dancers': 8, 'howling': 8, 'give': 8, 'commercial': 8, 'stick': 8, 'shuffle': 8, 'telephone': 8, 'ukele': 8, 'heavily': 8, 'cellos': 8, 'minor': 8, 'tanpura': 8, 'tape': 8, 'unconventional': 8, 'santa': 8, 'claus': 8, 'holiday': 8, 'afrobeats': 8, 'nursery': 8, 'fading': 8, 'aerophone': 8, 'virtuosity': 8, 'rave': 8, 'harpist': 8, 'impactful': 8, 'fats': 8, 'alarm': 8, 'travel': 8, 'sliding': 8, 'riffs': 8, 'diva': 8, 'barking': 8, 'musician': 8, 'opening': 8, 'sunny': 8, 'microphone': 8, 'jamaican': 8, 'gun': 8, 'outdoors': 8, 'lucid': 8, 'relaxed': 8, 'showcase': 8, 'polyrhythms': 8, 'along': 8, 'school': 9, 'nylon': 9, 'southern': 9, 'lower': 9, 'paino': 9, 'romance': 9, 'victory': 9, 'element': 9, 'whooshing': 9, 'explosions': 9, 'sax': 9, 'arcade': 9, 'cajon': 9, 'karaoke': 9, 'bending': 9, 'lonely': 9, 'pain': 9, 'videos': 9, 'acordion': 9, 'outer': 9, 'growling': 9, 'announcement': 9, 'radio': 9, 'devotion': 9, 'baritone': 9, 'huge': 9, 'whispering': 9, 'dog': 9, 'call': 9, 'autotuned': 9, 'legends': 9, 'changes': 9, 'overdrive': 9, 'subdued': 9, 'punjabi': 9, 'chiptune': 9, 'applause': 9, 'sophisticated': 9, 'yodelling': 9, 'bird': 9, 'cultural': 9, 'unpleasant': 9, 'unsettling': 9, 'spirit': 9, 'royal': 9, 'hardcore': 9, 'elegant': 9, 'clock': 9, 'fingers': 9, 'vibration': 9, 'ancient': 9, 'trio': 9, 'toy': 9, 'police': 9, 'flowing': 10, 'surround': 10, 'parody': 10, 'blowing': 10, 'guiro': 10, 'afro': 10, 'conga': 10, 'exquisite': 10, 'whistle': 10, 'crackles': 10, 'splashing': 10, 'inspirational': 10, 'tunes': 10, 'frequency': 10, 'breakup': 10, 'fresh': 10, 'turkish': 10, 'classics': 10, 'shoe': 10, 'played': 10, 'wave': 10, 'deteriorated': 10, 'beatbox': 10, 'crickets': 10, 'processed': 10, 'fourth': 10, 'deeper': 10, 'scale': 10, 'shattering': 10, 'banging': 10, 'external': 10, 'one': 10, 'chamber': 10, 'crying': 10, 'slap': 10, 'vibraphone': 10, 'workout': 10, 'dub': 10, 'gong': 10, 'aboriginal': 10, 'dull': 10, 'jewish': 10, 'piece': 10, 'acid': 10, 'amp': 10, 'silence': 10, 'russian': 10, 'drops': 11, 'airy': 11, 'raw': 11, 'squeaking': 11, 'rimshot': 11, 'chatter': 11, 'folkmusic': 11, 'sloppy': 11, 'muted': 11, 'influence': 11, 'virtuoso': 11, 'afrobeat': 11, 'end': 11, 'delicate': 11, 'educational': 11, 'melancholy': 11, 'shooting': 11, 'break': 11, 'spacey': 11, 'breeze': 11, 'baby': 11, 'excitement': 11, 'profound': 11, 'modulated': 11, 'lute': 11, 'sombre': 11, 'never': 11, 'mantra': 11, 'saxophones': 11, 'ceremonial': 11, 'random': 11, 'chime': 11, 'grungy': 11, 'raga': 11, 'recorder': 11, 'chants': 11, 'clap': 11, 'snapping': 11, 'waltz': 11, 'falling': 11, 'bend': 11, 'plastic': 11, 'narrator': 12, 'impacts': 12, 'tibetan': 12, 'angelic': 12, 'boxing': 12, 'snaps': 12, 'fingerstyle': 12, 'composition': 12, 'bow': 12, 'very': 12, 'hands': 12, 'medieval': 12, 'crashes': 12, 'thrilling': 12, 'straight': 12, 'running': 12, 'burgeoning': 12, 'full': 12, 'seductive': 12, 'dynamic': 12, 'danger': 12, 'plucking': 12, 'wood': 12, 'enchanting': 12, 'amplifier': 12, 'reed': 12, 'small': 12, 'amplification': 12, 'gear': 12, 'battle': 12, 'online': 13, 'bizarre': 13, 'quartet': 13, 'superimposed': 13, 'young': 13, 'ending': 13, 'gig': 13, 'playlist': 13, 'sweep': 13, 'analog': 13, 'record': 13, 'over': 13, 'laughter': 13, 'pluck': 13, 'ambience': 13, 'review': 13, 'fans': 13, 'layers': 13, 'excited': 13, 'scottish': 13, 'journey': 13, 'grand': 13, 'unrelated': 14, 'guitarist': 14, 'intimate': 14, 'harmonium': 14, 'beatboxing': 14, 'rustling': 14, 'motif': 14, 'bongo': 14, 'composer': 14, 'k': 14, 'korean': 14, 'free': 14, 'vocables': 14, 'image': 14, 'blaring': 14, 'euphonious': 14, 'praise': 14, 'down': 14, 'sizzling': 14, 'breathing': 14, 'bowls': 14, 'vibe': 14, 'wild': 14, 'stabs': 14, 'crunchy': 14, 'door': 14, 'dense': 14, 'serious': 14, 'plays': 14, 'tuned': 14, 'healing': 14, 'long': 14, 'caribbean': 14, 'gain': 15, 'hindustani': 15, 'celtic': 15, 'baroque': 15, 'boy': 15, 'italian': 15, 'industrial': 15, 'popular': 15, 'charming': 15, 'sweet': 15, 'strummed': 15, 'euphoric': 15, 'reversed': 15, 'tenor': 15, 'listening': 15, 'hiphop': 15, 'slime': 15, 'session': 15, 'disc': 15, 'maracas': 15, 'trombones': 15, 'resonator': 15, 'instructional': 15, 'kit': 15, 'is': 15, 'recurring': 15, 'waves': 15, 'unison': 16, 'animal': 16, 'alto': 16, 'whirring': 16, 'autotune': 16, 'turn': 16, 'persuasive': 16, 'speech': 16, 'build': 16, 'clicking': 16, 'footsteps': 16, 'celebratory': 16, 'enthralling': 16, 'composers': 16, 'anthem': 16, 'reflective': 16, 'madly': 16, 'easy': 16, 'cozy': 16, 'resonant': 16, 'japanese': 16, 'light': 16, 'thumping': 16, 'grunge': 16, 'samples': 16, 'merry': 16, 'grunting': 16, 'bowed': 16, 'tap': 16, 'bollywood': 16, 'crowds': 17, 'narration': 17, 'bansuri': 17, 'practice': 17, 'yodeling': 17, 'forever': 17, 'symphonic': 17, 'death': 17, 'vocalists': 17, 'laser': 17, 'girl': 17, 'hollow': 17, 'all': 17, 'tremolo': 17, 'boisterous': 17, 'distant': 17, 'tablas': 18, 'bowl': 18, 'hopeful': 18, 'beep': 18, 'compilation': 18, 'soprano': 18, 'goth': 18, 'ska': 18, 'together': 18, 'rapper': 18, 'busy': 18, 'patter': 18, 'creepy': 18, 'incessant': 18, 'keybiard': 18, 'serene': 18, 'tranquil': 18, 'ukelele': 18, 'electrifying': 18, 'with': 18, 'mesmerising': 18, 'robotic': 18, 'overdriven': 18, 'carols': 18, 'insistent': 18, 'hindu': 18, 'synthesised': 19, 'comedy': 19, 'camera': 19, 'learning': 19, 'memdium': 19, 'advertisement': 19, 'box': 19, 'nostalgia': 19, 'celebration': 19, 'prayer': 19, 'outdoor': 19, 'improvisation': 19, 'woodwinds': 19, 'muddled': 19, 'shofar': 19, 'raspy': 19, 'falsetto': 19, 'humming': 20, 'chattering': 20, 'harmonized': 20, 'table': 20, 'offbeat': 20, 'beautiful': 20, 'compelling': 20, 'vibes': 20, 'cool': 20, 'hitting': 20, 'you': 20, 'adventurous': 20, 'intro': 20, 'incoherent': 20, 'rising': 20, 'crackling': 20, 'back': 20, 'different': 21, 'ensemble': 21, 'cartoon': 21, 'a': 21, 'rhythms': 21, 'echo': 21, '808': 21, 'flutes': 21, 'african': 21, 'harmonies': 21, 'percussively': 21, 'irish': 21, 'slide': 21, 'filter': 21, 'resounding': 21, 'ad': 21, 'rebellious': 21, 'sub': 21, 'phone': 21, 'chorus': 21, 'fusion': 21, 'finger': 22, 'lessons': 22, 'bas': 22, 'lick': 22, 'for': 22, 'group': 22, 'entertaining': 22, 'anticipation': 22, 'delay': 22, 'paced': 22, 'great': 22, 'meditational': 22, 'triangle': 22, 'man': 22, 'carnatic': 22, 'space': 22, 'tribal': 22, 'adventure': 22, 'monotone': 22, 'comedic': 23, 'celestial': 23, 'whistling': 23, 'teen': 23, 'exotic': 23, 'eccentric': 23, 'remix': 23, 'night': 23, 'stuttering': 23, 'mix': 23, 'staccato': 23, 'engine': 23, 'fidelity': 24, 'ride': 24, 'bagpipe': 24, 'horns': 24, 'perky': 24, 'super': 24, 'quiet': 24, 'siren': 24, 'electronica': 24, 'arpeggios': 24, 'production': 24, 'conductor': 24, 'echoes': 24, 'pan': 24, 'car': 24, 'impact': 24, 'dulcet': 25, 'acapella': 25, 'symphony': 25, 'worship': 25, 'studio': 25, 'enigmatic': 25, 'instructive': 25, 'dubstep': 25, 'ringing': 25, 'tracks': 26, 'technique': 26, 'buzzing': 26, 'unique': 26, 'fuzzy': 26, 'bluegrass': 26, 'bagpipes': 26, 'viola': 26, 'influences': 26, 'rush': 26, 'hat': 26, 'play': 26, 'grim': 26, 'american': 26, 'tense': 27, 'musical': 27, 'walking': 27, 'mellifluous': 27, 'peppy': 27, 'off': 27, 'demonstration': 27, 'turntable': 27, 'intricate': 27, 'motivational': 28, 'melodies': 28, 'genre': 28, 'fruity': 28, 'horror': 28, 'age': 28, 'good': 28, 'old': 28, 'hall': 28, 'oriental': 29, 'shouting': 29, 'dangerous': 29, 'vinyl': 29, 'tom': 29, 'generic': 29, 'crushed': 29, 'infectious': 29, 'fade': 29, 'resonating': 29, 'woodwind': 29, 'march': 29, 'violent': 29, 'quirky': 29, 'tropical': 29, 'introduction': 29, 'vibrato': 30, 'like': 30, 'wedding': 30, 'spiritual': 30, 'chinese': 30, 'heart': 30, 'mexican': 30, 'licks': 30, 'peaceful': 30, 'sensual': 31, 'mixed': 31, 'drone': 31, 'rapid': 31, 'philharmonic': 31, 'booming': 31, 'ominous': 31, 'lilting': 31, 'crashing': 31, 'rimshots': 31, 'pensive': 31, 'up': 31, 'tv': 31, 'big': 31, 'jazzy': 32, 'demo': 32, 'oud': 32, 'building': 32, 'fiddle': 32, 'flamenco': 32, 'lyrics': 32, 'captivating': 32, 'rich': 32, 'out': 32, 'clean': 32, 'mystical': 32, 'sharp': 32, 'glass': 32, 'swing': 32, 'mixer': 32, 'punk': 33, 'festive': 33, 'beeping': 33, 'futuristic': 33, 'chimes': 33, 'progressive': 33, 'various': 33, 'asian': 33, 'slower': 33, 'four': 33, 'chant': 33, 'note': 33, 'messy': 34, 'vibrations': 34, 'droning': 34, 'life': 34, 'documentary': 35, 'hindi': 35, 'nature': 35, 'tuba': 35, 'breathy': 35, 'player': 35, 'south': 35, 'child': 35, 'warm': 35, 'time': 35, 'marimba': 36, 'salsa': 36, 'key': 36, 'arpeggio': 36, 'range': 37, 'white': 37, 'hit': 37, 'duet': 37, 'average': 37, 'soloist': 37, 'new': 37, 'street': 37, 'spooky': 37, 'adrenaline': 37, 'timpani': 37, 'thin': 37, 'contemporary': 38, 'suspense': 38, 'rolls': 38, 'snappy': 38, 'two': 38, 'bongos': 38, 'auto': 38, 'laughing': 38, 'open': 39, 'playback': 39, 'subtle': 39, 'tension': 39, 'filtered': 39, 'muddy': 40, 'trap': 40, 'articulation': 40, 'lesson': 40, 'cowbell': 40, 'manic': 41, 'chirping': 41, 'ukulele': 41, 'congas': 41, 'bassline': 41, 'tuning': 41, 'slick': 42, 'register': 42, 'birds': 42, 'sitar': 42, 'unbalanced': 42, 'dissonant': 42, 'lullaby': 43, 'harsh': 43, 'experimental': 43, 'youtube': 44, 'middle': 44, 'toms': 44, 'pads': 44, 'atmosphere': 44, 'feedback': 44, 'scary': 44, 'marching': 44, 'choral': 45, 'mysterious': 45, 'poignant': 45, 'minimalist': 45, 'danceable': 45, 'melodious': 45, 'buzzy': 45, 'jingle': 46, 'telling': 47, 'world': 47, 'stereo': 47, 'style': 47, 'mid': 48, 'sonic': 48, 'heartfelt': 48, 'sinister': 48, 'weird': 48, 'xylophone': 49, 'deep': 49, 'vivacious': 49, 'static': 49, 'funny': 50, 'indie': 50, 'bouncy': 50, 'inferior': 51, 'riser': 51, 'emphatic': 51, 'mandolin': 51, 'chanting': 51, 'disco': 51, 'track': 52, 'power': 52, 'dramatic': 52, 'dark': 52, 'calm': 52, 'metallic': 53, 'tapping': 53, 'nostalgic': 53, 'theremin': 53, 'modern': 53, 'clarinet': 53, 'chill': 53, 'church': 53, 'trombone': 53, 'feel': 54, 'hissing': 54, 'eastern': 54, 'water': 54, 'energy': 54, 'house': 54, 'harpsichord': 54, 'chaotic': 54, 'inspiring': 55, 'ethereal': 55, 'programmed': 55, 'arabic': 55, 'shaker': 55, 'religious': 55, 'vintage': 56, 'short': 56, 'pulsating': 57, 'show': 57, 'rapping': 57, 'spanish': 57, 'instrumentation': 57, 'meditative': 58, 'devotional': 58, 'bell': 58, 'progression': 58, 'trippy': 58, 'minimal': 58, 'plucked': 59, 'kids': 59, 'dreamy': 59, 'machine': 59, 'tone': 59, 'urban': 60, 'edm': 60, 'arrangement': 60, 'atmospheric': 61, 'synthesizer': 61, 'room': 62, 'gentle': 62, 'complex': 62, 'opera': 62, 'ballad': 63, 'story': 63, 'concert': 63, 'foreign': 63, 'epic': 64, 'distortion': 65, 'jam': 65, 'violins': 66, 'vocalisation': 67, 'higher': 67, 'classic': 67, 'tabla': 67, 'party': 67, 'christian': 68, 'regional': 68, 'hypnotic': 68, 'french': 68, 'harmonica': 69, 'hand': 69, 'tinny': 70, 'meditation': 70, 'haunting': 70, 'screaming': 70, 'upright': 70, 'single': 71, 'pleasant': 71, 'audience': 71, 'songs': 72, 'arrangements': 72, 'eerie': 73, 'groove': 73, 'orchestral': 73, 'soul': 74, 'pedal': 74, 'christmas': 74, 'bright': 74, 'speaking': 74, 'sounding': 74, 'engaging': 74, 'repeated': 74, 'powerful': 74, 'western': 75, 'gospel': 76, 'buoyant': 76, 'language': 76, 'in': 76, 'strumming': 77, 'dancing': 78, 'alternative': 79, 'cinematic': 79, 'positive': 79, 'elements': 80, 'steel': 80, 'chord': 81, 'notes': 82, 'funk': 82, '’': 82, 'double': 83, 'stringed': 83, 'crash': 83, 'playful': 83, 'lines': 84, 'beats': 84, '4': 85, 'riff': 85, 'pitch': 86, 'syncopated': 86, 'vigorous': 87, 'guitars': 87, 'amplified': 88, 'trance': 89, 'banjo': 89, 'tutorial': 90, 'psychedelic': 90, 'catchy': 91, 'didgeridoo': 92, 'uplifting': 93, 'pattern': 93, 'suspenseful': 95, 'heavy': 96, 'reggae': 96, 'reverb': 97, 'sad': 98, 'scratching': 98, 'tune': 98, '`': 98, 'singers': 99, 'trumpet': 100, 'sample': 102, 'choir': 103, 'cello': 103, 'saxophone': 103, 'bad': 103, 'r': 108, 'wind': 108, 'cymbal': 109, 'trumpets': 109, 'shakers': 109, 'boomy': 110, 'cover': 110, 'children': 111, 'hard': 111, 'claps': 112, 'sentimental': 113, 'echoing': 114, 'roll': 114, 'joyful': 114, 'hop': 114, 'club': 114, 'strong': 117, 'b': 117, 'talking': 118, 'rap': 118, 'game': 118, 'horn': 119, 'soulful': 120, 'smooth': 122, 'accordion': 126, 'harp': 127, 'keys': 127, 'organ': 127, 'theme': 127, 'addictive': 128, 'pitched': 129, 'electro': 129, 'retro': 131, 'melancholic': 131, 'soothing': 131, 'soundtrack': 132, 'on': 133, 'animated': 133, 'floor': 134, 'vibrant': 134, 's': 136, 'backing': 138, 'wooden': 138, 'home': 139, 'rhythmic': 141, 'people': 142, 'blues': 144, 'arpeggiated': 145, 'reverberant': 145, 'cheering': 145, 'noises': 146, 'clapping': 146, 'movie': 148, 'mood': 149, 'noise': 150, '&': 150, 'harmonizing': 150, 'of': 152, 'indian': 152, 'backup': 153, 'orchestra': 153, 'and': 155, 'the': 155, 'easygoing': 156, 'repetitive': 157, 'techno': 157, 'calming': 162, 'love': 163, 'funky': 165, 'band': 165, 'other': 166, 'synthesiser': 173, 'beat': 174, 'fun': 176, 'aggressive': 179, 'sustained': 180, 'tambourine': 182, 'muffled': 183, 'cheerful': 183, 'cymbals': 184, 'vocalist': 185, 'pad': 187, 'violin': 188, 'enthusiastic': 188, 'to': 189, 'tones': 192, 'intense': 192, 'lively': 193, 'exciting': 193, 'relaxing': 195, 'crowd': 195, 'traditional': 195, 'dj': 195, 'bells': 197, 'metal': 197, 'effects': 206, 'youthful': 206, 'flat': 207, 'section': 208, 'flute': 212, 'country': 214, 'distorted': 216, 'upbeat': 218, 'percussive': 219, 'effect': 222, 'percussions': 223, 'moderate': 228, 'spirited': 229, 'hip': 234, 'background': 235, 'jazz': 235, 'video': 236, 'melodic': 236, 'playing': 247, 'steady': 248, 'lead': 249, 'high': 252, 'latin': 266, 'romantic': 268, 'digital': 279, 'loud': 288, 'hats': 289, 'poor': 292, 'ambient': 294, 'brass': 297, 'chords': 299, 'hi': 306, 'string': 308, 'simple': 311, 'happy': 312, 'line': 313, 'classical': 336, 'wide': 343, 'solo': 344, 'folk': 347, 'soft': 349, 'hits': 353, 'instruments': 355, 'mono': 360, 'instrument': 377, 'accompaniment': 382, 'mellow': 386, 'voices': 395, 'uptempo': 395, 'drum': 406, 'strings': 410, 'snare': 416, 'e': 439, 'kick': 476, 'drumming': 488, 'shimmering': 497, 'keyboard': 514, 'performance': 522, 'singer': 522, 'vocals': 525, 'electronic': 556, 'fast': 560, 'slow': 562, 'sounds': 593, 'harmony': 601, 'amateur': 602, 'audio': 634, 'noisy': 642, 'punchy': 642, 'rhythm': 646, 'singing': 664, 'emotional': 668, 'live': 681, 'energetic': 748, 'dance': 762, 'percussion': 770, 'piano': 776, 'rock': 778, 'recording': 784, 'pop': 813, 'no': 861, 'passionate': 876, 'sound': 892, 'voice': 900, 'medium': 900, 'electric': 950, 'female': 972, 'synth': 972, 'song': 999, 'drums': 1002, 'groovy': 1149, 'acoustic': 1188, 'instrumental': 1282, 'vocal': 1400, 'melody': 1520, 'low': 1542, 'quality': 1862, 'male': 1928, 'tempo': 1938, 'bass': 1959, 'music': 2648, 'guitar': 2661}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVkyb8qG9F6G"
      },
      "outputs": [],
      "source": [
        "def testToken(input):\n",
        "  output = []\n",
        "  input = word_tokenize(input.lower())\n",
        "  for i in range(len(input)):\n",
        "    if(input[i]) in vocab_dict:\n",
        "      index = vocab_dict[input[i]]\n",
        "      output.append(index)\n",
        "    else:\n",
        "      output.append(\"<UNK>\")\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIpyjxd29f-D",
        "outputId": "50c5fea8-5c50-4809-a8c7-5770366578bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[94, 299, 532, 16, '<UNK>', 177, 532, 16, '<UNK>', 41, 42, 1520, 532, 16, '<UNK>', 42, 168, 20, 169, 532, 16, '<UNK>', 23, 180, 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 532, 16, '<UNK>', 334, 532, 16, '<UNK>', 147, 532, 16, '<UNK>', 720, 532, 16, '<UNK>', 72, 42]\n",
            "male vocalist', 'energetic drumming', 'loud electric guitar feedback', 'electric guitar lead and harmony', 'enthusiastic vocal backup', 'youthful', 'enthusiastic', 'energetic', 'vibrant', 'boisterous', 'voracious', 'intense', 'passionate', 'metal', 'hard rock', 'rock music', 'heavy metal', 'electric bass guitar\n",
            "153\n",
            "shots\n"
          ]
        }
      ],
      "source": [
        "testVal = testToken(ds[500][\"aspect_list\"][2:-2])\n",
        "print(testVal)\n",
        "print(ds[500][\"aspect_list\"][2:-2])\n",
        "print(max_len)\n",
        "print(vocab_list[69])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_search(id):\n",
        "  for i in range(ds.num_rows):\n",
        "    if(ds[i][\"ytid\"] == id):\n",
        "      print(i)\n",
        "      return ds[i]\n",
        "\n",
        "item = data_search(\"qsRPTMXFGsA\")\n",
        "print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXLa8DqSN95n",
        "outputId": "d17e6e73-9970-47a5-eb03-f96359468c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4829\n",
            "{'ytid': 'qsRPTMXFGsA', 'start_s': 210, 'end_s': 220, 'aspect_list': ['male', 'latin', 'singer', 'bad', 'quality', 'audio', 'latin', 'dance', 'band', 'deteriorating', 'audio', 'quality', 'groovy', 'dance', 'hits', 'retro', 'latin', 'hits', 'medium', 'tempo', 'bachata', 'vocal', 'echoes', 'latin', 'percussions', 'guitar', 'lead', 'keyboard', 'tones', 'enthusiastic', 'emotional', 'passionate', 'romantic', 'retro', 'latin', 'hits', 'latin', 'pop', 'hits', 'people', 'dancing', 'passionate', 'romantic', 'groovy', 'bass', 'line', 'latin', 'love', 'hits', 'wedding', 'music', 'people', 'dancing', 'latin', 'dance', 'hits', 'latin', 'dance', 'music'], 'caption': 'A male Latin singer sings this passionate melody. The song is medium tempo with various Latin percussions, groovy bass line, keyboard harmony and a guitar playing lead. The song is romantic and a classic Latin dance groove. The song is a Latin dance hit with a deteriorating audio quality.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(maxLenItem)\n",
        "print(ds[4829])\n",
        "print(len(ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "9U8_QHXPOu1r",
        "outputId": "82d1a6af-913d-4d78-9f3c-46d9a87055d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2059\n",
            "{'ytid': 'qsRPTMXFGsA', 'start_s': 210, 'end_s': 220, 'aspect_list': \"['male latin singer', 'bad quality audio', 'latin dance band', 'deteriorating audio quality', 'groovy dance hits', 'retro latin hits', 'medium tempo', 'bachata', 'vocal echoes', 'latin percussions', 'guitar lead', 'keyboard tones', 'enthusiastic', 'emotional', 'passionate', 'romantic', 'retro latin hits', 'latin pop hits', 'people dancing', 'passionate', 'romantic', 'groovy bass line', 'latin love hits', 'wedding music', 'people dancing', 'latin dance hits', 'latin dance music']\", 'caption': 'A male Latin singer sings this passionate melody. The song is medium tempo with various Latin percussions, groovy bass line, keyboard harmony and a guitar playing lead. The song is romantic and a classic Latin dance groove. The song is a Latin dance hit with a deteriorating audio quality.'}\n",
            "5521\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-562411d98073>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4829\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2794\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2777\u001b[0m         \u001b[0mformat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2779\u001b[0;31m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2780\u001b[0m         formatted_output = format_table(\n\u001b[1;32m   2781\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0m_check_valid_index_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m     \u001b[0;31m# Query the main table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0m_check_valid_index_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0m_check_valid_index_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'slice'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSOqyNR3H6No"
      },
      "outputs": [],
      "source": [
        "ds = ds.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhMuI8fEqYO4",
        "outputId": "a9c184eb-7776-4b7f-dc56-1a733d8c6bc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
              "  \"feature_size\": 1,\n",
              "  \"max_length\": 1024,\n",
              "  \"mean\": -4.2677393,\n",
              "  \"num_mel_bins\": 128,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000,\n",
              "  \"std\": 4.5689974\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "feature_extractor = ASTFeatureExtractor()\n",
        "feature_extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPn0QMQdKtxy"
      },
      "outputs": [],
      "source": [
        "def download_clip(\n",
        "    video_id,\n",
        "    output_filename,\n",
        "    start_time,\n",
        "    end_time,\n",
        "    tmp_dir='/musiccaps',\n",
        "    num_attempts=5,\n",
        "    url_base='https://www.youtube.com/watch?v='\n",
        "):\n",
        "\n",
        "  status = False\n",
        "  command = f\"\"\"\n",
        "        yt-dlp --quiet --no-warnings -x --audio-format wav -f bestaudio -o \"{output_filename}\" --download-sections \"*{start_time}-{end_time}\" {url_base}{video_id} --force-keyframes-at-cuts\n",
        "    \"\"\".strip()\n",
        "  attempts = 0\n",
        "  while True:\n",
        "    try:\n",
        "      # output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
        "      output = os.system(command)\n",
        "    except subprocess.CalledProcess.Error as err:\n",
        "      attempts += 1\n",
        "      if attempts == num_attempts:\n",
        "        return status, err.output\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  # Check if video was successfully saved\n",
        "  status = os.path.exists(output_filename)\n",
        "  return status, 'Downloaded'\n",
        "\n",
        "\n",
        "def toUppercase(aspect_list):\n",
        "  a_list = aspect_list[1:-1]\n",
        "  new_list = ''\n",
        "  for word in a_list:\n",
        "    new_list = ''.join(a_list).upper().replace(',', '')\n",
        "    # new_list = new_list.replace(' ', '|')\n",
        "    if(len(new_list) > 128):\n",
        "      new_list = new_list[:128]\n",
        "  return new_list\n",
        "\n",
        "# Convert the words into tokens\n",
        "def tokenizeCaption(caption):\n",
        "  output = [vocab_dict[\"<SOS>\"]]\n",
        "  input = word_tokenize(caption.lower())\n",
        "  for i in range(len(input)):\n",
        "    if(input[i]) in vocab_dict:\n",
        "      index = vocab_dict[input[i]]\n",
        "      output.append(index)\n",
        "    else:\n",
        "      output.append(vocab_dict['<UNK>'])\n",
        "  output.append(vocab_dict[\"<EOS>\"])\n",
        "  # Max_len -2 because I'm appending additional start and end tokens\n",
        "  # for j in range(len(input), max_len-2):\n",
        "  #  output.append(vocab_dict[\"<PAD>\"])\n",
        "  return output\n",
        "\n",
        "\n",
        "def tokenizeAspectList(aspect_list):\n",
        "  output = [vocab_dict[\"<SOS>\"]]\n",
        "  for i in range(len(aspect_list)):\n",
        "    if(aspect_list[i] in vocab_dict):\n",
        "      index = vocab_dict[aspect_list[i]]\n",
        "      output.append(index)\n",
        "    else:\n",
        "      output.append(vocab_dict[\"<UNK>\"])\n",
        "  output.append(vocab_dict[\"<EOS>\"])\n",
        "  return output\n",
        "\n",
        "\n",
        "def process(example):\n",
        "  output_path = str(data_dir / f\"{example['ytid']}.wav\")\n",
        "  status = True\n",
        "  # aspect_string = toUppercase(example['aspect_list'])\n",
        "  if not os.path.exists(output_path):\n",
        "    status = False\n",
        "    status, log = download_clip(\n",
        "        example['ytid'],\n",
        "        output_path,\n",
        "        example['start_s'],\n",
        "        example['end_s'],\n",
        "    )\n",
        "\n",
        "  # example[\"tokenizedCaption\"] = tokenizeCaption(example[\"caption\"])\n",
        "  example[\"tokenizedAspectList\"] = tokenizeAspectList(example[\"aspect_list\"])\n",
        "  # example['aspect_string'] = aspect_string\n",
        "  example[\"audio\"] = output_path\n",
        "  example['download_status'] = status\n",
        "  if(example[\"ytid\"] == \"qsRPTMXFGsA\"):\n",
        "    example[\"download_status\"] = False\n",
        "  example[\"image_path\"] = f'./spectrograms/{example[\"ytid\"]}.png'\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqRSt4Waay0g"
      },
      "outputs": [],
      "source": [
        "def stereo_to_mono(wav):\n",
        "  chan_1 = wav[0][:]\n",
        "  chan_2 = wav[1][:]\n",
        "  mono = (chan_1 + chan_2) / 2\n",
        "  return mono"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNaBNcfVULd6"
      },
      "outputs": [],
      "source": [
        "def resample_waveform(example):\n",
        "  filepath = example[\"audio\"]\n",
        "  y, sr = librosa.load(filepath, sr=16000)\n",
        "  sf.write(filepath, y, sr)\n",
        "  waveform, sampling_rate = torchaudio.load(filepath)\n",
        "  if(waveform.shape[0] == 2):\n",
        "    waveform = stereo_to_mono(waveform)\n",
        "\n",
        "  example[\"waveform\"] = waveform\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDN_72fZqp7x"
      },
      "outputs": [],
      "source": [
        "def wavToInput(example):\n",
        "  wav = np.asarray(example[\"waveform\"])\n",
        "  inputs = feature_extractor(wav, sampling_rate=sampling_rate, padding=\"max_length\", return_tensors=\"pt\").input_values\n",
        "  example[\"input_values\"] = inputs\n",
        "  example[\"inputs_shape\"] = inputs.shape\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "caf864f927bb4dfd9a920af784e6279a",
            "c820ef37e37f46ae97f8f8c7835d6155",
            "6ce05079f751444e858fdec3490c643d",
            "f10c7b8c53434b149a738349e2db4f83",
            "efbd27fbeb2743e5959f922766f7af1d",
            "9afc25d4ce5947d5a6d9a18efb1867f5",
            "6ab758d6094b48f0bc16c97d0f51bdd1",
            "c9796c68ea3b48f8ab531dd95da9248b",
            "d8600763699148a7ba75cb5bf452760e",
            "15a9eaedc8404c5ab058991e29755084",
            "eebc759d45fc4ee0adb0c909a666256d",
            "fbe5e88f46814addb420127fba3e1a72",
            "98882b6be26d4adb984b780f18b42475",
            "cbcdddb134184651878d4095e86f568a",
            "0b3a52a94e964d3d88cd3f4af589ec32",
            "8cb19431548240c6aef34ee2f7b727d9",
            "f51160fe4f0f4428a849ae2f45cdeb6f",
            "4e50c217fc9a4593ad1a4b13d3cd6520",
            "39f7e377db9d402589c0b62459eeb6f8",
            "a4e0be3a213144b28c49e5bf8bfb3cea",
            "0414bc80ce8843089e4cb2703c148d4c",
            "92f8854f16fa4aa589e5cca56519e17e",
            "bfefceaa9a994572bc75f13848d17e34",
            "1b182fdc6fb142e99a3e1c68e64a85c6",
            "0a12a718706941388f4648d6f253aff2",
            "dc91bd5090d146b1898283e57504f417",
            "79e43e78edd44d659c596010bb8cd8cf",
            "dfa698a1c6114d4e838cead88aadd973",
            "50f48d378d984300b20567188119f2a7",
            "0bf2bf40e7b94e5788c62e90eb130811",
            "408414e23a3f486f8f1ca8ddcd58571e",
            "59b83da868d64aacb2813ee62aa56592",
            "5d0b7242250542b3bd24fff37f9b8c0f",
            "edc9bfb111894241b7743ade8368adc4",
            "8cc7c21de84f42baa203e7a6cbfd4dcd",
            "8c8ce7cf8338462e90432586090c2546",
            "d95723b737444067bd108b9d98e93730",
            "30ab350318e84c0a9946c2335e69c3c9",
            "2d3e65a266f34760804bc2251ff5f982",
            "1e74f90df3724ac994b8b7fcb36ccae5",
            "046c9b249add4637946e8737e51b8873",
            "34f82ef2f34b46459cc0fd66b2486ecf",
            "6b9c235094cd462980e3493da044942c",
            "898aa92f313841f1a5a668a73b342a70",
            "1c3ee0149e064d1a8c546e91aa99d8af",
            "a04b0b6f18014987a1eb327448d52e00",
            "e194bcae55cb48f680b425ca5dec78f9",
            "19a5b8526e3647619c6394e6171d6061",
            "054aeb09d15d4e56a05d24e2bb9bdebb",
            "8cf66265813542a088ec4c0802fba527",
            "a3458938928b4a3a870d6adb8aa92982",
            "d3b3722deba44609867fe515213b6cce",
            "b26c31d96cca4b248fc5f687c3819115",
            "e9af07bdf9764d45bb758fd91b93b643",
            "fab2854df7ba4574888d6f97b545171e",
            "225c1f91cb1c405a84eb42282a1fed5b",
            "652cfb71336c48ac83069d0126c2d98a",
            "579d5da2cf524faa829462f30d8edc8f",
            "49ea87b042404059a62a4b78de5fe987",
            "8500fd266cca4dfdb71773360136fbf8",
            "d52b0397f846448f88138aadf54245d4",
            "f43b3ecb31d64e1cb8b3b7113fd5ff8d",
            "218f39ee38134945b6ed0f237154475e",
            "bed47b85e2f1445a8f233f4d140ab006",
            "9ba7c9753e16428d95c64cf451000ac2",
            "933d03e0e2d34787ac431aaadcf34744",
            "3818e5a00b7f4d77b0a7e91a7cb6ba6b",
            "6574f3aa167e4b5fb791455ff8789429",
            "9cba04b8c0734986a8ee9e1be3573da2",
            "c6dad448169d470888ed1f37ec78be9a",
            "c1ebebe46d35491a866e7a7a34b7f9ec",
            "566b1fed17164827a967a19d62446262",
            "102b1f901b3a4a8c8d4cb3483bc07cc1",
            "9a911bca4b4b40f5924db04dd7519d39",
            "e9a3996898c643c38c803a943decc4f6",
            "d959a491d010482695ba8ac117d6e7ca",
            "77ba9fb0314c44ed91835b93a5577e11",
            "c80bf7c0d05b45b1b061a9e555d2d772",
            "4ff16ebcaeb4401aae8fd9fd10d807a0",
            "9b9d18e620994db09fe389d3411d2820",
            "b908ef8c300f496481de5127b838cfaf",
            "64100adbcf824998b54afdc5db21c645",
            "4931815f9a114a908023a22ed7134a07",
            "52a2fc382b3845d9a7c82a858b8575a2",
            "42dd6b3080104ad595d4c408d57dae3c",
            "8147f2c3087148e99e73d5f1f1965327",
            "2fdf0a40211f4b7996ed41a163b82389",
            "7679a1e2a97442568d66d62f3ee15a33"
          ]
        },
        "id": "VhNDVeTr8hzw",
        "outputId": "33f038f8-68df-483f-8469-f40046032332"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caf864f927bb4dfd9a920af784e6279a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe5e88f46814addb420127fba3e1a72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/3938 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfefceaa9a994572bc75f13848d17e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/3938 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edc9bfb111894241b7743ade8368adc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c3ee0149e064d1a8c546e91aa99d8af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "225c1f91cb1c405a84eb42282a1fed5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/786 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3818e5a00b7f4d77b0a7e91a7cb6ba6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/786 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c80bf7c0d05b45b1b061a9e555d2d772"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "samples_to_load = 4000\n",
        "cores = 4\n",
        "sampling_rate = 16000\n",
        "writer_batch_size = 1000\n",
        "data_dir = \"./music_data\"\n",
        "upper_limit = 5521\n",
        "lower_limit = 5000\n",
        "\n",
        "data_dir = Path(data_dir)\n",
        "data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# ds = ds.select(range(lower_limit, upper_limit))\n",
        "\n",
        "# ds = ds.map(\n",
        "#     process,\n",
        "#     num_proc=cores,\n",
        "#     writer_batch_size=writer_batch_size,\n",
        "#     keep_in_memory=False\n",
        "# )\n",
        "\n",
        "\n",
        "# ds = ds.filter(lambda ex: ex[\"download_status\"] == True)\n",
        "\n",
        "ds_train = ds[\"train\"].select(range(samples_to_load))\n",
        "ds_test = ds[\"test\"].select(range(int(samples_to_load*0.2)))\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    process,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        "    # batched=True,\n",
        ")\n",
        "\n",
        "ds_train = ds_train.filter(lambda ex: ex[\"download_status\"] == True)\n",
        "# ds_train = ds_train.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
        "ds_train = ds_train.map(\n",
        "    resample_waveform,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    wavToInput,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    process,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        "    # batched=True,\n",
        ")\n",
        "\n",
        "ds_test = ds_test.filter(lambda ex: ex[\"download_status\"] == True)\n",
        "# ds_test = ds_test.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
        "ds_test = ds_test.map(resample_waveform, num_proc=cores, writer_batch_size=writer_batch_size, keep_in_memory=False)\n",
        "ds_test = ds_test.map(\n",
        "    wavToInput,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaKSs_xlprjB"
      },
      "source": [
        "# Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEplgTXjpqfK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4v7rWOWqhVM",
        "outputId": "675bfcd8-4231-46f1-ff04-7e07332e19d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here we have a slow piano piece played in a major key. The peace feels calm and happy.\n"
          ]
        }
      ],
      "source": [
        "train_data = next(iter(train_loader))\n",
        "print(train_data[\"caption\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "TxCq2ngxtZ0N",
        "outputId": "8337c164-89a9-4db2-bd70-d16f9903b24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([-0.6306, -0.9950], dtype=torch.float64), tensor([-1.0666, -1.2776], dtype=torch.float64), tensor([-0.6898, -1.1508], dtype=torch.float64), tensor([-1.2776, -1.2776], dtype=torch.float64), tensor([-0.2374, -0.9357], dtype=torch.float64), tensor([-0.5634, -1.2617], dtype=torch.float64), tensor([ 0.0054, -0.6809], dtype=torch.float64), tensor([-0.2595, -0.9754], dtype=torch.float64), tensor([ 0.0394, -0.7316], dtype=torch.float64), tensor([-0.2751, -0.8052], dtype=torch.float64), tensor([-0.1032, -0.6333], dtype=torch.float64), tensor([-0.6595, -0.7263], dtype=torch.float64), tensor([-0.6062, -0.6730], dtype=torch.float64), tensor([ 0.0416, -0.9412], dtype=torch.float64), tensor([-0.0257, -1.0084], dtype=torch.float64), tensor([ 0.2385, -0.9479], dtype=torch.float64), tensor([ 0.1090, -1.0531], dtype=torch.float64), tensor([ 0.1664, -0.9936], dtype=torch.float64), tensor([-0.0412, -0.6724], dtype=torch.float64), tensor([-0.1746, -0.4530], dtype=torch.float64), tensor([-0.4436, -0.3369], dtype=torch.float64), tensor([-0.1457, -0.2578], dtype=torch.float64), tensor([-0.1415, -0.2577], dtype=torch.float64), tensor([-0.0991, -0.2170], dtype=torch.float64), tensor([-0.1222,  0.0667], dtype=torch.float64), tensor([-0.3219,  0.1102], dtype=torch.float64), tensor([-0.2284,  0.1039], dtype=torch.float64), tensor([-0.1115,  0.0634], dtype=torch.float64), tensor([ 0.1791, -0.2222], dtype=torch.float64), tensor([ 0.2258, -0.3449], dtype=torch.float64), tensor([ 0.1805, -0.4310], dtype=torch.float64), tensor([ 0.0699, -0.6074], dtype=torch.float64), tensor([ 0.1332, -1.0168], dtype=torch.float64), tensor([ 0.4793, -0.8776], dtype=torch.float64), tensor([ 0.7124, -0.4607], dtype=torch.float64), tensor([ 0.7423, -0.4182], dtype=torch.float64), tensor([ 0.6654, -0.5187], dtype=torch.float64), tensor([ 0.5028, -0.5022], dtype=torch.float64), tensor([ 0.0797, -0.4956], dtype=torch.float64), tensor([-0.0657, -0.6031], dtype=torch.float64), tensor([-0.1284, -0.9543], dtype=torch.float64), tensor([-0.1547, -0.9957], dtype=torch.float64), tensor([-0.2311, -0.9972], dtype=torch.float64), tensor([ 0.0384, -1.0352], dtype=torch.float64), tensor([ 0.1693, -0.7671], dtype=torch.float64), tensor([ 0.1602, -0.6415], dtype=torch.float64), tensor([ 0.0080, -0.6557], dtype=torch.float64), tensor([-0.3279, -0.8172], dtype=torch.float64), tensor([-0.4694, -1.1557], dtype=torch.float64), tensor([-0.4685, -1.0908], dtype=torch.float64), tensor([-0.4194, -1.0772], dtype=torch.float64), tensor([-0.3494, -1.1536], dtype=torch.float64), tensor([-0.0907, -1.1002], dtype=torch.float64), tensor([-0.0774, -0.8232], dtype=torch.float64), tensor([-0.1502, -0.6259], dtype=torch.float64), tensor([ 0.3139, -0.6014], dtype=torch.float64), tensor([ 0.5757, -0.7617], dtype=torch.float64), tensor([ 0.5667, -1.1704], dtype=torch.float64), tensor([ 0.3301, -1.1782], dtype=torch.float64), tensor([-0.1733, -1.2776], dtype=torch.float64), tensor([-0.1973, -1.2776], dtype=torch.float64), tensor([-0.3454, -1.2776], dtype=torch.float64), tensor([-0.2530, -1.2067], dtype=torch.float64), tensor([-0.0938, -1.2211], dtype=torch.float64), tensor([-0.2540, -1.2776], dtype=torch.float64), tensor([-0.2471, -1.1719], dtype=torch.float64), tensor([-0.1511, -1.2351], dtype=torch.float64), tensor([-0.2562, -1.2776], dtype=torch.float64), tensor([-0.3737, -1.2759], dtype=torch.float64), tensor([-0.2957, -1.2499], dtype=torch.float64), tensor([-0.0734, -1.2101], dtype=torch.float64), tensor([ 0.3392, -1.2776], dtype=torch.float64), tensor([ 0.4515, -1.2776], dtype=torch.float64), tensor([ 0.1931, -1.2776], dtype=torch.float64), tensor([-0.4392, -1.2776], dtype=torch.float64), tensor([-0.6160, -1.1705], dtype=torch.float64), tensor([-0.4811, -1.1996], dtype=torch.float64), tensor([-0.4595, -1.2342], dtype=torch.float64), tensor([-0.6208, -1.2776], dtype=torch.float64), tensor([-0.6144, -1.2776], dtype=torch.float64), tensor([-0.7006, -1.2776], dtype=torch.float64), tensor([-0.5158, -1.2776], dtype=torch.float64), tensor([-0.3133, -1.2776], dtype=torch.float64), tensor([-0.0226, -1.2776], dtype=torch.float64), tensor([ 0.0466, -1.2776], dtype=torch.float64), tensor([-0.2600, -1.2776], dtype=torch.float64), tensor([-0.5053, -1.2706], dtype=torch.float64), tensor([-0.6241, -1.2667], dtype=torch.float64), tensor([-0.5506, -1.2770], dtype=torch.float64), tensor([-0.6686, -1.2776], dtype=torch.float64), tensor([-0.7054, -1.2311], dtype=torch.float64), tensor([-0.7245, -1.1160], dtype=torch.float64), tensor([-0.6492, -1.1096], dtype=torch.float64), tensor([-0.2620, -1.2155], dtype=torch.float64), tensor([-0.2649, -1.2281], dtype=torch.float64), tensor([-0.7758, -1.1406], dtype=torch.float64), tensor([-0.9449, -1.1568], dtype=torch.float64), tensor([-0.8839, -1.1224], dtype=torch.float64), tensor([-0.7738, -1.2109], dtype=torch.float64), tensor([-0.7799, -1.1968], dtype=torch.float64), tensor([-0.8935, -1.1325], dtype=torch.float64), tensor([-1.0493, -1.1418], dtype=torch.float64), tensor([-0.7260, -1.2776], dtype=torch.float64), tensor([-0.8060, -1.2602], dtype=torch.float64), tensor([-0.9147, -1.2065], dtype=torch.float64), tensor([-0.9938, -1.0247], dtype=torch.float64), tensor([-0.8743, -1.1051], dtype=torch.float64), tensor([-0.8847, -1.1154], dtype=torch.float64), tensor([-0.8259, -1.2511], dtype=torch.float64), tensor([-0.4515, -1.2032], dtype=torch.float64), tensor([-0.4621, -1.2776], dtype=torch.float64), tensor([-0.7911, -1.1300], dtype=torch.float64), tensor([-0.8814, -1.2200], dtype=torch.float64), tensor([-0.9519, -1.2701], dtype=torch.float64), tensor([-0.9327, -1.1550], dtype=torch.float64), tensor([-0.8509, -1.1250], dtype=torch.float64), tensor([-0.5689, -1.1801], dtype=torch.float64), tensor([-0.7546, -1.1141], dtype=torch.float64), tensor([-0.9862, -1.0912], dtype=torch.float64), tensor([-0.9532, -1.0166], dtype=torch.float64), tensor([-0.9222, -1.0007], dtype=torch.float64), tensor([-0.8348, -0.9621], dtype=torch.float64), tensor([-0.6334, -1.0944], dtype=torch.float64), tensor([-0.8421, -1.0862], dtype=torch.float64), tensor([-0.9464, -1.1542], dtype=torch.float64), tensor([-0.9453, -1.0941], dtype=torch.float64), tensor([-0.9253, -1.0134], dtype=torch.float64), tensor([-1.1187, -1.1778], dtype=torch.float64)]\n",
            "<class 'list'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-23ba81c83916>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# input_tensor = torch.tensor(input_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "  for i, data in enumerate(train_loader):\n",
        "    input_values = data[\"input_values\"]\n",
        "    test = input_values[0]\n",
        "    print(test[0])\n",
        "    # input_tensor = torch.tensor(input_values)\n",
        "    print(type(input_values))\n",
        "    tensor = torch.tensor(input_values)\n",
        "    [t.size() for t in data[\"input_values\"]]\n",
        "    input = torch.tensor(data[\"input_values\"]).squeeze(1)\n",
        "    print(\"Input shape\", input.shape)\n",
        "    target = torch.tensor(data[\"tokenzedCaption\"])\n",
        "    print(\"Target shape\", target.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rqo2cIFX5lG"
      },
      "source": [
        "# AST Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvhRQoviwiWJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "model = AutoModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLv9lgeOaQsv"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWwJ3RU__7Kj"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "    super().__init__()\n",
        "\n",
        "    assert hid_dim % n_heads == 0\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.head_dim = hid_dim // n_heads\n",
        "\n",
        "    self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "  def forward(self, query, key, value, mask = None):\n",
        "\n",
        "    batch_size = query.shape[0]\n",
        "\n",
        "    # query = [batch_size, query len, hid_dim]\n",
        "    # key = [batch_size, key len, hid_dim]\n",
        "    # value = [batch_size, value len, hid_dim]\n",
        "\n",
        "    Q = self.fc_q(query)\n",
        "    K = self.fc_k(query)\n",
        "    V = self.fc_v(query)\n",
        "\n",
        "    # Q = [batch_size, query len, hid_dim]\n",
        "    # K = [batch_size, key len, hid_dim]\n",
        "    # V = [batch_size, value len, hid_dim]\n",
        "\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "\n",
        "    # Q = [batch_size, n heads, query len, hid_dim]\n",
        "    # K = [batch_size, n heads, key len, hid_dim]\n",
        "    # V = [batch_size, n heads, value len, hid_dim]\n",
        "\n",
        "    energy = torch.matmul(Q, K.permute(0,1,3,2)) / self.scale\n",
        "\n",
        "    # energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "    # attention = [batch_size, n_heads, query len, key len]\n",
        "\n",
        "    x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "    # x = [batch_size, n_heads, query len, head_dim]\n",
        "\n",
        "    x = x.permute(0,2,1,3).contiguous()\n",
        "\n",
        "    # x = [batch_size, query len, n_heads, head_dim]\n",
        "\n",
        "    x = x.view(batch_size, -1, self.hid_dim)\n",
        "\n",
        "    # x = [batch_size, query len, hid dim]\n",
        "\n",
        "    x = self.fc_o(x)\n",
        "\n",
        "    # x = [batch_size, query len, hid dim]\n",
        "\n",
        "    return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd5W3ysr1jXt"
      },
      "source": [
        "# Transformer Decoder Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG5uJu8J1osB"
      },
      "outputs": [],
      "source": [
        "# Create a starting output state\n",
        "  # Pass this into an output embedding (size of 768)\n",
        "  # Use positional encoding\n",
        "  # Pass this into a masked multi-head attention mechanism\n",
        "  # Add and normalize\n",
        "\n",
        "# Take the output from stage 1 and combine it with the output from the encoder\n",
        "  # Multi-head attention\n",
        "  # Add and normalize\n",
        "\n",
        "# Feed forward\n",
        "  # Add and normalize\n",
        "\n",
        "# Linear activation function\n",
        "# Softmax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LwFv1dG2sWx"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.attention = nn.MultiheadAttention(embed_size, heads).to(device)\n",
        "    # self.attention = MultiHeadAttentionLayer(embed_size, heads, dropout, device)\n",
        "    self.norm1 = nn.LayerNorm(embed_size)\n",
        "    self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_size, forward_expansion*embed_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(forward_expansion*embed_size, embed_size)\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, value, key, query, mask):\n",
        "    # attention, _ = self.attention(query, key, value, mask)\n",
        "    # Shouldn't need a mask to ignore padding on inputs since padding is not needed for inputs\n",
        "    attention, _ = self.attention(query, key, value)\n",
        "\n",
        "    x = self.dropout(self.norm1(attention + query))\n",
        "    forward = self.feed_forward(x)\n",
        "    out = self.dropout(self.norm2(forward + x))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMgAofOR6IgS"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads, forward_expansion, dropout, device, max_length):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = nn.MultiheadAttention(embed_size, heads).to(device)\n",
        "    # self.attention = MultiHeadAttentionLayer(embed_size, heads, dropout, device)\n",
        "    self.norm = nn.LayerNorm(embed_size)\n",
        "    self.transformer_block = TransformerBlock(\n",
        "        embed_size, heads, dropout, forward_expansion\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    # self.feed_forward = nn.Sequential(\n",
        "    #     # Target shape[1] to forward_expansion*embed_size\n",
        "    #     nn.Linear(max_length, forward_expansion*embed_size),\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Linear(forward_expansion*embed_size, max_length)\n",
        "    # )\n",
        "\n",
        "  def forward(self, x, value, key, src_mask, trg_mask):\n",
        "    # A feed forward connection adds other parameters so there is an additional case to learn if needed\n",
        "    # x = self.feed_forward(x)\n",
        "    attention, _ = self.attention(x, x, x, trg_mask)\n",
        "    query = self.dropout(self.norm(attention + x))\n",
        "    # query = self.norm(x + self.dropout(attention))\n",
        "    out = self.transformer_block(value, key, query, src_mask)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER1XVfzI4Ev6"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.device = device\n",
        "    self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
        "    self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "    # self.position_embedding = nn.Parameter(torch.randn(max_length, embed_size))\n",
        "\n",
        "    self.layers = nn.ModuleList(\n",
        "        [DecoderBlock(embed_size, heads, forward_expansion, dropout, device, max_length)\n",
        "        for _  in range(num_layers)]\n",
        "    )\n",
        "\n",
        "    self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([embed_size])).to(device)\n",
        "\n",
        "  def forward(self, x, enc_out, src_mask, trg_mask):\n",
        "    N, seq_length = x.shape\n",
        "    pos = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "    # x = self.dropout(self.word_embedding(x) + self.position_embedding(pos))\n",
        "    x = self.dropout((self.word_embedding(x) * self.scale) + self.position_embedding(pos))\n",
        "    # positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
        "    # positions = position_embedding[:seq_length]\n",
        "    # x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
        "    # x = self.dropout((self.word_embedding(x) + self.position_embedding[:seq_length]))\n",
        "\n",
        "    for layer in self.layers:\n",
        "      # x = [N, seq_length, embed_size]\n",
        "      x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
        "\n",
        "    out = self.fc_out(x)\n",
        "    # out = self.softmax(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWubbuB28DSs"
      },
      "outputs": [],
      "source": [
        "class Instantiate(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Instantiate, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRqHc7vX-dUT"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "src_vocab_size = 1024 # max_length of feature extractor - not even used\n",
        "trg_vocab_size = len(vocab_list)\n",
        "embed_size = 768\n",
        "num_layers = 12\n",
        "heads = 12\n",
        "forward_expansion = 4\n",
        "dropout = 0.1\n",
        "device = device\n",
        "max_length = max_len\n",
        "\n",
        "src_pad_idx = 2\n",
        "trg_pad_idx = 2\n",
        "\n",
        "num_epochs = 20\n",
        "# Number of training samples in the batch\n",
        "batch_size = 4\n",
        "learning_rate = 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDSVpVZU77fC"
      },
      "outputs": [],
      "source": [
        "model.layernorm = Instantiate()\n",
        "# model.decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, droput, device, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTohuA8MGet_"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,\n",
        "               src_vocab_size,\n",
        "               trg_vocab_size,\n",
        "               src_pad_idx,\n",
        "               trg_pad_idx,\n",
        "               model,\n",
        "               embed_size=768,\n",
        "               num_layers=12,\n",
        "               heads=12,\n",
        "               forward_expansion=4,\n",
        "               dropout=0,\n",
        "               device=device,\n",
        "               max_length=max_len,\n",
        "              ):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = model\n",
        "    self.decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length)\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "# Src mask is used so the encoder does not pay attention to the padding values appended to the input\n",
        "  def make_src_mask(self, src):\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # (N, 1, 1, src_length)\n",
        "    return src_mask.to(self.device)\n",
        "\n",
        "  def make_trg_mask(self, trg):\n",
        "    N, trg_len= trg.shape\n",
        "    # trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
        "    #     N, 1, trg_len, trg_len\n",
        "    # )\n",
        "    trg_mask = torch.tril(torch.ones(trg_len, N))\n",
        "    return trg_mask.to(self.device)\n",
        "\n",
        "\n",
        "  def make_trg_mask_custom_attention(self, trg):\n",
        "    # trg  = [batch_size, trg_len]\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # trg_pad_mask = [batch_size, 1, 1, trg_len]\n",
        "\n",
        "    trg_len = trg.shape[1]\n",
        "\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
        "\n",
        "    # trg_sub_mask = [trg_len, trg_len]\n",
        "\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "    #trg_mask = [batch_size, 1, trg len, trg len]\n",
        "\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    # trg_mask = nn.Transformer.generate_square_subsequent_mask(max_length)\n",
        "\n",
        "    enc_src = self.encoder(src)\n",
        "    enc_out = enc_src[\"pooler_output\"].unsqueeze(1).expand(-1, trg.shape[1], -1)\n",
        "    out = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVR5fildVPoW"
      },
      "outputs": [],
      "source": [
        "newModel = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, model).to(device)\n",
        "optimizer = torch.optim.Adam(newModel.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21BNuiE94yjM"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab_dict[\"<PAD>\"])\n",
        "optimizer = torch.optim.Adam(newModel.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYt99TCvRG3P"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "  def __init__(self, pad_idx, eos_idx):\n",
        "    super(CustomLoss, self).__init__()\n",
        "    self.cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=vocab_dict[\"<PAD>\"])\n",
        "    self.pad_idx = pad_idx\n",
        "    self.eos_idx = eos_idx\n",
        "\n",
        "  def forward(self, logits, targets):\n",
        "     # Calculate standard cross-entropy loss\n",
        "    ce_loss = self.cross_entropy_loss(logits, targets)\n",
        "\n",
        "    # Penalize extra tokens beyond first occurence of <EOS>\n",
        "    eos_positions = (targets == self.eos_idx).nonzero()\n",
        "    if(eos_positions.numel() > 0):\n",
        "      # Only consider the first occurence of <EOS>\n",
        "      first_eos_pos = eos_positions[0, :]\n",
        "\n",
        "      # Count tokens beyond the first <EOS> position\n",
        "      if first_eos_pos.dim() > 0:\n",
        "        # extra_tokens = torch.clamp(first_eos_pos - logits.size(1), min=0)\n",
        "        extra_tokens = max(first_eos_pos - logits.size(1), 0)\n",
        "      else:\n",
        "        extra_tokens = 0\n",
        "\n",
        "      penalty_weight = 0.1\n",
        "\n",
        "      # Add penalty term to loss\n",
        "      extra_tokens_penalty = penalty_weight * extra_tokens\n",
        "      total_loss = ce_loss + extra_tokens_penalty\n",
        "    else:\n",
        "      total_loss = ce_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "pad_idx = 2\n",
        "eos_idx = 1\n",
        "custom_loss = CustomLoss(pad_idx, eos_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczqsAkDEcw1",
        "outputId": "2850f637-e813-49ed-d6ac-0dcf004e37de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18432 ['cY3g6N5Sokk', 'feC0L9MtghM', '-Umconw-CRE', 'A6HJBIU1rD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18433 ['YE2rN3xknlk', 'B_kAtTBUDIA', 'EkmHGd0U8yE', 'BVt8RgNrwbQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18434 ['A5fPSkTvjmY', 'PlQibWaPAcM', 'ymuRKv9iJm4', 'LAHWV6fZwUk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18435 ['X-uVubaJ3II', '244y56-vLWE', 'nU7x170OvJ4', 'paeNnR33i5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18436 ['cG1dpyC8gV4', 'n3X8RGZsGg4', 'sDoV3sMgDhE', 'lSb7Y-_3to8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18437 ['iqEQBCrOLWc', 'XYOnq7ju7o0', '8jDanS4ZzRc', '-0vPFx-wRRI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18438 ['-1UWSisR2zo', 'EGIeykrN4eg', '8Ha5qGnT7lg', 'sYIymaJi6tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18439 ['Tt3BnoJw8ds', '9K8EePrEDdo', 'iUxy2s5d60o', '-VI2IRq17rs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18440 ['7JE2eBK1f9M', 'hRbukCd6N68', 'WmyhSRhWh3k', 'OEjgIDubFbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18441 ['Ca3b8qNUbsk', 'TnJE6W6Z6mM', 'N_LKZjw9DLk', 'U4UtZeTl2DE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18442 ['nqcVA89BD6I', 'SEHE3WGui30', 'xrqDoBor2dk', 'c9JyKnsegog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18443 ['rLQ93N6RJC0', 'BBmXMoI9Qus', 'pte5jvRKwsA', 'uTfLf1Y8hhM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18444 ['1ACn3u5UnBw', 'T9dKp1EN4p8', 'VDYqYuPzW8E', 'ohikUtjUN7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18445 ['OoyxPPoPmt0', 'K9zE9x2ccJk', 'NwA9JSlK_lM', 'n179cK8EubU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18446 ['GUwBLItoJXk', 'cJ80eZY03Yg', 'WditOomsdRU', '9Y8NR6nDxjk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18447 ['vmVOWilkmOA', 'BquHBzP5Ep0', '4TDtUHo5cSE', 'KUE_I30--AY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18448 ['KdNhYvN4Xoo', 'JOhK7oq9KtU', '7_80oVTLkGU', 'iYWvaxU5OXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18449 ['C7WAx3n57Hk', 'jBmP7xTI_TA', '4Gow6qZcNZI', 'iUHqyjf3NcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18450 ['9YnYlDFKn-U', 'zYM0gtd_PRo', '-4NLarMj4xU', '1SO5RJLWKAs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18451 ['qaQjG9SwORU', '7AC9RqECN5k', 'gTX4SG70cEY', '-hSMzrWZCAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18452 ['2vQTq4QLP8U', 'yfZ0z1C3blk', 'sfmAeijj5cM', '28wBrNjHXOM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18453 ['zWJC_qr2610', 'DTkKGYCRMlc', 'OzaVvthCvtk', 'YAYp2E5vMNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18454 ['UQKLBsZJsww', 'UxT3KG4AHAI', 'echeYDYFhlY', '4QES-SJ7mP0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18455 ['ZM0imDMXuw8', 'SEDfsU63w8I', 'tUZB_Xf1m6k', 'YcWJUHWt-64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18456 ['GWcMqKYOJR4', 'xzgnLpKkvdg', 'qW4kBJsudLI', 'L5UDz2PJ9sk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18457 ['_78P-0zWJtg', 'BEZdszHKGTQ', 'n_boIyhZqWc', 'HwGK5RvNOFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18458 ['RDNatVYvpeA', 'YNoR-SR5t1s', 'w9EGDo9Yybc', '6lPgzqrvHHw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18459 ['L0oun9F67tg', 'e2tZmQI8ICw', 'hBT0bbJl1dU', 'TA-O_bVnvLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18460 ['WMtztIW1f6k', 'QUB_vpjogmo', 'AzWIKyRnhG8', 'GG6XkHATIyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18461 ['Ns-iXXKmzzU', 'l5QPXVIxxwk', 'Wu-Oh9OJIlI', 'MfX7Q0ucts8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18462 ['l0fCHZhKEDA', 'aO0QzRPiEC4', '3sIlpn9nvKU', '6YXjJ6ABnZU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18463 ['zdtVT2xwrHU', '3EXXs3x4Ius', 'DC0C-KO9EJk', 'Lc6OfmzV7Pk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18464 ['54yI3In3DrU', 'LSaLPObrnZw', 'RdKQGIzKZ_c', 'L9GXrmmlYhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18465 ['CxTFgimfNfA', 'grisjVTZeTk', '1JqNiV03kog', 'BL181hSAG60']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18466 ['9gkppwB5CXA', 'RFKTlhbnfXA', 'SUclDZHax0w', 'B_ohqOgK6T8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18467 ['xUVvBF9BWdg', '6-CMq6xw0fg', 'hlHb9HwNxk8', '-qcTD2o6I9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18468 ['j-TVVmVmygg', 'D3FyfFIKLVc', 'KLFoZA8btu4', 'TCRxCAYyduo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18469 ['-YATTKBtmRA', 'XdBf_omYIO4', 'kdxW11WBlQE', 'HQb2jhmw1BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18470 ['_u2cNlW5DxQ', 'hTlIqICkbW8', '3OLeJZF4oI0', 'TPYNIc_M1ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18471 ['2z1elo4ucis', 'KoAGZ_dB8MM', 'ikEuQPSBY-0', 'Pgpd1yxLcLI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18472 ['HY1KdNS19CM', 'j0FynYzQvcM', 'oGbNzR_lpSk', 'MHkfPjW0aRg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18473 ['YW4AKwkpYxs', 'yO7MWuJ7zLA', 'hrCf8rMBtA8', 'c6Fiz5IznkU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18474 ['lNg2y6SRZPo', 'WCiS9IDILQg', 'G7pD1K3jYg4', 'ATDi-irUEWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18475 ['h-3DrDQC62k', 'R5KBk76b9HE', 'YxkYVsE0UdQ', 'AVVfOYSmexM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18476 ['67S7s_jFXhc', 'lYtoy8sa-Q0', 'GwxSvUoYSZg', 'cOgNXgF21u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18477 ['19-GI2LzOtc', 'Qz2PIXM60iE', 'B-1QW7g81gA', 'Gow0TlxIx7U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18478 ['4gEmWJCPZGo', 'sgJT5lIFttM', 'CM2rKZmcR0I', 'bTlp5Qr99RY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18479 ['2zrPFxxT1VM', 'Xm2ciX0_UP8', '2IpapScfsT4', 'Y8ULUSXWTcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18480 ['ksYM8YzzWXo', 's3Q8pVDY7ZI', 'fU9woCZqemw', 'KDzy3ZL626U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18481 ['F2ekiX14ID4', 'M-RX7LqL50A', '2qO-OQtOBK0', '6cQjwXNY4sc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18482 ['9kt7rsziUVQ', 'XUzaEsoOlWQ', 't8uF3PZ3KGQ', 'EZAwPnGOJPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18483 ['nBSMh7pgn2o', 'aWK9CcvOK9w', 'gkMbHlNAFig', 'bqeVxA97TQU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18484 ['15CZ2h5VL-A', 'BdhaR2QUGqY', 'A2NtJ12KIuU', 'lV0-LMVpZLg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18485 ['ql7aH8wF6JM', '2y1QnNBaxAU', 'LK6zk03lPlM', 'mQ1E8rx2dnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18486 ['qtnE1hnCD0M', 'eISYX9koocM', 'CD3OyaDW348', 'B00nfVc4FPI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18487 ['AmAThmRphk0', 'tmabzx6yxqs', 'qeoYWM1uYPI', 'R5JRh08zgMo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18488 ['_KYo_89lgf0', 'nnc6m1pBJ4c', 'Fa1KdG8niq0', 'smU92Nu0FmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18489 ['eUZ-v8GEcNk', 'UR3k09hOxI4', 'C6m_OWe-JE4', 'hwSOjoHFLn4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18490 ['evG8CQRCdV8', 'FFQVVwFjy7s', '0oIFGARD9xE', 'CZuH43NPynA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18491 ['frqnZb8Ssjo', 'gCSShNsw-_A', 'BsLFQV8HVZE', 'hvmCuosF0Xo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.7434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18492 ['qcjzfHmQvxg', '0a6uLBmqZgA', 'fAfk9yrGhWw', '5pIdH6p3kuo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18493 ['WTVC7ZI9WtY', 'O28kY0aN8VI', 'Q2Omtt4A8ls', 'VHyXvbg6y9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18494 ['Inuq5W98ktA', 'XjoRxeEyjz4', 'mRKud6yP4iU', '8pYHLfKqHL4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18495 ['91Qp8XUskXo', '6nWWTNVRDjw', '23xC7lTBikU', 'GuHDy--gWiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18496 ['fXhN3_gGpQw', '3e6GleQ9sl0', 'S8WTaKLpmmg', '7RtQpW2dSU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18497 ['4Mm5mBgktG0', 'A_oaLt-n4fQ', 't7oAteGa55g', '6jdeSAmkzEU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18498 ['kMK10SknFAI', '3bg0iy-ypcw', 'R6k2BkwZt1Y', 'UO9HtZMrbBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18499 ['yBYd03Hr2kQ', 'YddV91xnUz4', 'O2HttJtcec4', 'R6lRMU-zBLA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18500 ['VSf3_XpiPkQ', 'FXVu-YwjhxM', 'nY4tpb8O_Rg', 'VlXi2TxMXbc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18501 ['AzhfZ8rNhRk', 'pKFXFu8st9I', 'HyJ2YaNrA3U', 'Brc_nOquNbY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18502 ['65KYS3lIRII', 'UhcoWyEQwBI', 'd-KxsdWX9xE', 't3758pixHZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18503 ['1xhwyUVSRQk', 'svNayU6q3Dg', 'HFVM5pVTwkM', '9ZeoYezrI7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18504 ['5xAzHL8Zlcs', '3sRO6iwfUxo', 'ihJT65fZaHY', '0a91szM1Ivw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18505 ['XWhmLbnrtd0', 'fhWzjWZqzvs', '2juYRZnhF3g', 'ZVMIk3xYaYo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18506 ['NSyqj1DXZKg', 'UinQGYfmZhE', 'pcOPueObfWs', 'f7OQTtTdgrA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18507 ['3TQmts_MxyQ', 'RS43EP1EXz4', 'lfCWGQ6URds', '-wymN80CiYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18508 ['4jzr88nEdCM', 'u3n2OcpEC48', 'UEOUXjX5R2I', 'mqyeBqaUeN8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18509 ['entThp930cw', 'BsVsoZ4ojp0', 'QqRrZzOY2xw', 'UxrAsZ7Z09Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18510 ['0hfU27A6tus', '1RhYdQnZ_hw', 'DYp8940tHso', 'zTuxNA1y6Os']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18511 ['UOC4VWQpnDM', '4M0njWKFsME', 'tMMjurLqYJQ', 'vnwKpQeza3A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18512 ['IiBgER0W8iA', 'dzW5M4sCphI', 'p2fXNAPYD20', 'Ux3YosKD-9I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18513 ['Vx4aO4-nr0c', 'gEYTdeQiFv8', 'I368EWBLIs4', '9aE33JEIGOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18514 ['VuWr1HXHoZg', 'mMf4vJFT8Fw', 'thHSYzhoLo4', 'woyCm7d2UIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18515 ['CdFutCUKTXI', 'fUC45bzOOJw', 'O5IulN0n6d0', 'SSVlD_ZDb70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18516 ['YFhbrSUb0JQ', '8MbxazeMw2E', '4CrPPlHN9_s', 'Pf9AaTV4-yw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.7092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18517 ['1ypKEH2kd7g', 'W7KbboEOmeM', 'ODRAYQE9GXs', 'b12xqPnM0So']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18518 ['ua0hgl8fi0I', '5qVc9y3TNnY', 'NdiSW-p2I0c', '-BIMKnb3tlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18519 ['vBkDLBO-Aok', '-T4GeTHKtJQ', 'tUBTRs7Avk0', 'oBBTqXQFTiA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18520 ['8hO1S9VIfPY', 'p4T1pddBia0', 'Y02VBGoTi9w', 'x1S2oreZBWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18521 ['Zmtw8tP-KFo', 'IhNPDueFVSo', 'I-Z3gB6pfIA', 'qtNTHnXOQew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18522 ['IC_Wpalzzm8', 'IcPbxJRbe5g', 'bxF2vxTzlvo', 'p2yedR_jMTU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18523 ['qDiTICmdUQg', '4LZSSya3ZZQ', '7avMUhHOCR8', 'e1KHGfMekek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18524 ['4ueN2gGsH5Y', '1FnT0RrfMEA', 'TZlFTbvfKPE', 'u6tgeRXOxnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18525 ['AVuh8-CucrE', 'w3QIsHxQfPE', 's1eMgmzCMDM', 'Xxe6vTEwFvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.8902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18526 ['FXQxobF8FWw', 'J7d3nuS9wqg', 'OwukabRF7I4', 'W2EJai-3k2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18527 ['P5IxlG4-CY8', 'OiAJB9uydS8', 'HTQySJM4Jhg', 'u0CgRmXMXNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18528 ['ikJKSqnTylI', 'uJPW9BEhU6Y', 'mJuJfKbcJcw', 'D_QEW1Lnl2Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18529 ['I5CBPhpimtg', '58f4AsxOYhU', 'lRTeWmoeen4', 'ZFg6KpT5ehU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18530 ['Pm6vRblouxc', 'xseL3oZc7pY', 'ZahBai58_Ec', 'PE1ges9nn6A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18531 ['m9MQdg0k1t0', 'RoDS0k7qrIo', 'QtjMlA_7dds', 'bTuKGXDrqdQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.8073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18532 ['pIE-3sIPlvY', '3tlaELkmRqs', 'iTWZsfVCyBs', 'N_Wx35sNqdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18533 ['d352jaSSiFw', 'FkpJaXzgMBQ', 'macnXLRXbHU', 'q-sJu8CoZts']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18534 ['sbOBTkrivXM', 'nvvXOfLs-ng', '-m9pH0WXQto', 'F1X7egd8Us0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18535 ['MMGAKKhqxKg', '8Z5xnSxUmGE', '1LA64TXatWk', 'oynXCFZWxnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18536 ['E6B81rrUlnE', '2Ui85-AOLyo', 'xx1RccwlF5g', 'zj2G-KVw4N4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18537 ['4q-eGdrqiIw', 'yPou7kokTgA', 'RFNRR78dh-8', 'chw8sAKOM5k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18538 ['lymmNwQA0WA', 'Vo6eT8eMMfQ', 'YqZNMFyPJOQ', 'P97w3AdePgQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18539 ['3zntWbS9XeI', 'UY2_Q830lqo', 'Wu3LKQG1fwU', '4b8gTARnmVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18540 ['7FHzw4HV75Y', 'y6NS77HLjEE', 'qfVIeq7s6tw', 'dO3VsX4rKNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18541 ['HOIIp5NyFx0', 'bAJrcYJgllE', 'sxMYFYDNF_g', 'f8QGA4vN6HY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18542 ['X7LrhZX4rdU', '1BVSYfNCcv0', 'TkHZdMJPwKc', 'hVPQu1UJ2N8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18543 ['4Yc71_dU3m4', 'weJKl-6TiDQ', '2CzfBZ1mYBs', '9ZWmZdgrE78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18544 ['iQ7qeIrssds', 'IJcLW4arT6s', 's25X6KwBpxw', 'BN6W6OQnVoE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18545 ['QCbUlDMu7Hk', 'MdsRmMxkF4k', 'yaUK4XvVGTg', 'TiDdR-6bIcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18546 ['VzHL56yq8bI', 'vx5iuWuE2Ng', '4l441DdEJfU', '1rhsnmWLeGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18547 ['VswY2mI7Wbo', 'jHEBYrI8zHE', 'FsnRM2irjvI', 'ZqnbgQeeRbM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18548 ['APSbmhJam74', '6L8066DGqcA', 'q7s7C4oNlFo', '6Q5N1DfzGj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18549 ['c-85TtcfVSI', '5r4jLwjj_Ik', 'sUh43prJYMM', 'YvFY7xU2kGk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18550 ['Hxf1seOpijE', 'oVhhEku6ECA', '50QEapyTPD4', 'kSdH9z8snac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18551 ['-mB_XLq6g1g', 'wwHi10qX8u8', 'N8Fg3L1Cc5E', '3b3s0TvjGwA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18552 ['5ZX1-GAb7IM', 'lIBsL97sUmY', 'AiGGDpbgp6I', 'b2XAPiRUoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18553 ['cTJqIkSuf6s', 'xGHN0kphhWM', 'xhOsZuB_Zqc', 'JC41M7RPSec']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18554 ['UsdoUjuczY4', 'n7yLkcSfiuM', 'OR_YbeqV5tA', '_qf0UiKtB3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18555 ['cqolOXDF86g', '7TmKzUgWiRU', 'MNlzpCwdh4g', 'Xaq-segSEsQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18556 ['GcbCOmNiVm8', 'HLsRePLObfI', '_Ra1Y6K7nSs', 'knQuxZj9rTA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18557 ['tEdeb9eSKDI', '669Fk7afszw', 'tOb0M2k3deo', 'ba5xPgcHN_0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18558 ['vf3n40mDLHw', 't-CMJ6RsZzY', 'ALcCb2HJmG8', 'UrgzGbGVV8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18559 ['7dmT4SgS_EM', 'dW4eW0Xreik', 'I0q3IGmTkRo', 'U-L9YCIdLbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18560 ['HRxTN4TH-80', '9iYxf1hS4Yk', '4i1aizhCnfg', 'vhTWW5Bx15Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18561 ['vrNQbCbBlLY', '6CaZAITdAsk', '-ZHpNr_KRXU', '6QAZJ4H_5rA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18562 ['KyRJP_fDrbk', 'ppAT0f2YCyM', 'stobfk1Mfjk', 'm0FhT3UnXjA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18563 ['x85BtdoxRek', 'GmGWvBNO8JI', 'M0ygCD6WyXw', 'FiKY19GK6-8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18564 ['colnyHv9CAA', 'bKS_m7JObxg', 'vEN9szBPBkw', 'nB2Lf5TTmBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18565 ['6pHo6fPdPvM', 'd20qTsF6ll8', 'dUhE6H72Qpg', 'LaaC_q3QDUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18566 ['evy2azZk3kE', 'KXuB62SMFvA', 'zYUZEXCE7gw', 'hhohfEC82JI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18567 ['rez5KDmIZoc', 'xSDkn9PtQm0', 'dj-DWiV1z9g', 'Hnk45Z0EAxg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18568 ['2kcSUBkFbaQ', 'oYEzy8gH6q8', 'LzSWdj4izHM', 'g0WLA0BKxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18569 ['qp4Ubx7WOAQ', 'C0sSgrr5xrQ', '-FEPOSP7ay0', 'yG1bzzXDIak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18570 ['6TSluKI0X54', '9x7jWb4lE7c', 'dwSj0Rr3vFc', 'zopos1B6Elc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18571 ['k4ttuqKjiw0', 'Yj7YyxKyXPU', 'r_KdRKquXsM', 'qHRRWdWvjxI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18572 ['1SqihV_DnEg', 'efTVnvwI2PQ', '89eBh_Djflw', '74p3DLeDCHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18573 ['e6lTl9JIW5Y', 'c-8SLUH5pp4', '5tNOauvQWQQ', 'bYwoYjbPm-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18574 ['05JAmKFVy44', 'bNW18IztiZY', 'XjrVSk0_4vc', 'HEhogaw0vUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18575 ['EzP7PB2x670', '9JlifkCmUOk', 'IGAzIIZRczw', 'uSZQGP_i3gs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18576 ['JsHTGDW5dgw', 'X6Q53uXgaHc', '78S8DnvLQDY', 'K5ilD6nEJ-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18577 ['mtapmFDmImA', 'DG5d4megH8g', 'OPimGlHcSRQ', 'tvcJENqxr1c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18578 ['S0W_zIUYwrE', 'emDU4QvdwVk', 'nvBPPOzcW-A', 'GiTmjE7az74']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18579 ['RFbWkL818XQ', '7eZTmLV9gcY', 'YyYEzAY2e2I', 'lbB2VQYIMo0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18580 ['c7IL4fDqs_I', 'OJuVsBojdvo', 'FvQgVl5IBHw', 'rizanOQM61k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18581 ['_KaRkSyELy4', '02Qntw26enM', 'N4eMppEnPE0', 'DvOA0K-DIFM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18582 ['6BitLl5Bnxw', 'VG6-MlmCgzI', '6II4JGJDyZo', 'YeIXmKPyTVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18583 ['tdrz4EkIsow', 'ASgLbz48BaY', '5xBfKiQcMZQ', '7EvLwfwRrqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18584 ['QrJVAHIkpCo', '2UY_-oF1vqo', '5fPxUI0Fl-4', '64auWicQqZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18585 ['pvxx3aokwCU', '4KqSdK5KM-I', 'nSinUcyFFqg', 'oKab6-syQD4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18586 ['BYwS1dJRTi0', 'tFVvupXoRoM', 'qRgefptkDeo', 'wIP7AqIOU1s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18587 ['UzDVZzIIcy8', 'Z0O2r0Dl2T4', 'UOAv5b6MGxw', 'L9j9fCHHPeg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18588 ['cfeTMVWFHLo', 'nj6N7m8SeK4', '0nk7utNkHOY', 'Q7oWXOByo28']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18589 ['7lV4IvuW2lk', 'Th6Tf6kA8RU', '45iNSkfzOwM', '6iyinlZEgS4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18590 ['76ON0Ixrr9s', '2nsZhXxes68', 'mU6cfEWw5Og', 'RtXe5T7NFrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18591 ['RiqtelZs_2I', '3ZhyXbwFQAM', 'NVo-stvk_QE', 'ylKvglDzBU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18592 ['MWS-Uxf1MRw', '_5w5TVK5B90', 'XYQnMxWnetY', 'uT-S_JC_GzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18593 ['c9h4p6325Xo', 'MwE7REVj8JQ', '-M-6VinyMiY', 'o8FsD7l5er4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18594 ['l3pK8prEnrQ', 'rkQPSAHNoeI', 'K_G_k1WTdoc', 'nqd7mXvHupU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18595 ['J8pkQfYlJA4', 'ba3QPheW8mI', 'A6ilKRqIDH4', '6KXd7l5pThg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18596 ['IUjzBX2Qm4k', 'qlWEAm4AUTU', 'EY8boPZ1hPs', 'DQrdOgRb-oA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18597 ['8zGJ9N7c6pE', 'b-7oO1Rw-fo', 'pWZqzEpygE0', 'zR4ebAuqy8w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18598 ['4_s5vHgfxnw', 'MsjeOXuUYG4', 'N-dzfI3L5ic', 'J1-Qvl7u2TI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18599 ['lXrypwLQO3U', 'qRCjs90-1RQ', '4mtfOkzOvBI', 'A8P5zzHCjJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18600 ['6UJhTZgnVro', 'CIoEXRnAr-Y', 'zx_vcwOsDO4', 'WYxXUBP_XaM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18601 ['YB28WMv7wUE', 'DRU-IFx-7yQ', 'cYSW6Y884dA', 'f1_YKSYgtbI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18602 ['2ShO1jZYZeA', '0u1sk49gAU0', 'u9n4R78UBtA', 'VCrnnx9jTqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18603 ['dEc7tV30KJo', '3zPvfVmL0nE', 'r9AxQfXYLEs', 'XOsHEjo-RSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18604 ['9jeEfi6nDak', '9PQZSLa_A8A', 'BjAL68IMlp0', 'vtVfl5Ff5lw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18605 ['Y_eh6C0EBP8', 'Zq92ED3IvLQ', '4cg3MsrvJqw', 'RQbNC1J4Jfk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18606 ['38R9Vnwt890', '3Wdxjm-h36w', 'WcC9sKxJ1gI', 'wDpz90boBzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18607 ['-mA_bqD1tgU', 'GQz_u0Vc8Os', 'Sj5MQtqDw8Y', 'nSBDyxxscks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18608 ['hRQJgZVxRX0', 't6jlx6jAb-Q', 'RceCfg1FQq4', 'XILyHZyyCik']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18609 ['-EVRXQpt1-8', 'YLlbLSNxdQ4', 'H-bTMbePj0A', 'pqsU95TNNP8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18610 ['-ByoSbgzr4M', 'O3Cvn4yXrao', 'VV85n-ebuUU', 'Al_OdIuqoe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18611 ['msnm_tYXcYw', 'kjmmzA6i5rk', 'KzydTOkZty8', 'lYJAqOpp6RM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18612 ['lTOzGIOIfq0', 'XfdySM4X9Xo', 'r1W1z_31Obw', '92k_81uqMSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18613 ['C25xvcl4YAU', 'RXGDlFry3Vo', 'C8Euv69GR3U', 'nP05Sf4Fgac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18614 ['gFxLnprPgv4', 'eAFKjP7o1as', 'zd3lShuZNmU', 'Ubj0jlheyvk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18615 ['vxIF3B4YqW8', 'XcvY-NdM8WA', 'DyPmDDN8m78', '1ZaxqZMs21M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18616 ['B8pesuUc8Ek', '1PN-bfs2EhY', 'ZmgkpmzvL6c', '682ODyTqKyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18617 ['5JQIsqc8HBc', 'nbIwdOQ7D8A', 'jcZQhxb5lyw', 'KJHqQ5aKu8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18618 ['i3zayf6Hiog', 'qdWTfyysMN8', '6F8qv0JBWkE', 'LRUdmYcXFuM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.5003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18619 ['VSAbMy1Rlio', '0S5zWt91Bwo', 'UDS6PrY9ZIM', '-7B9tPuIP-w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18620 ['xVi1wNljxjk', 'AZsupJ68Hp0', 'DA8lw6Mq0DY', 'QRKc90kuAaE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18621 ['rh0vBy1JD8A', 'rNUtYf6EdW8', 'qXgSlhWbWLU', 'kMmjr8deHis']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18622 ['hTNKYJ6suII', 'ryEXhKy1QUI', 'I1fcUe9MoMw', 'uXMMzpgrY2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18623 ['5jT_i7S9QSM', 'DQ_gcdLhAsY', 'PB3i02Cjf1k', 'pKDnn0CBIe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18624 ['qDSvHlHbAqM', 'hYlSisv-VRU', 'L2-EGNKzUAQ', 'B3lq6U4PDZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18625 ['Iz611KubW70', 'LR3U4b_fVBc', '-m5ZlWziIeA', 'UJA5AWbt6HM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18626 ['cHGziT0hrZU', 'ABVYSaLu_VM', 'yHd5DzIbWL8', 'kbCh5HrmgN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18627 ['99ZgIQwLC60', '3OWArQGgmm0', 'wFTlySgdWX4', 'W2KaBnoGxek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18628 ['PJRG2bwphUc', 'TqWmuwAYmnI', '3ZyuBJEbmJM', 'E2gstPe3Im4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18629 ['aVNcweinmEM', '8KIoQ2HZ0Hg', 'TWV3YLscSaw', 'C3Jhu77uffQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18630 ['PTLOLz9YzmM', 'kkjNpwNcMWI', '0EzWmAPwoTs', 'fyLctn3jNUs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18631 ['Xus0LI3QV2A', '1Xtkou9dtyA', 'aBEiuYSSEH0', 'm-eyGzf9Ux4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18632 ['D_usHKfOXCw', 'pyumNmhV4_s', 'R3urUtvSgkU', 'MyjxrBI9k4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18633 ['NlUf1ppoSG4', 'P240GHf9Eq4', 'JYYfw3id3ek', 'KDuusOmEMHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.8190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18634 ['ZVvX2-ldhvY', 'eZE0RmJESFU', 's5wdG7xbTNg', 'dztizAgcQ08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18635 ['ZUcHBeueBww', '0H3FAoDgzhI', 'QpX9dSCFxRI', 'kjn6I3AurgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18636 ['9ZryMX2UtAo', 'B4lGhVjoMTk', 'O40E8bpmONQ', 'Js_3Aa214xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18637 ['qwI32Si0ipE', 'AnErEDywInE', 'JUrYWttZJBM', '2SenLjPbGzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18638 ['BRTHyoVgZT0', 'WIVu5PapmX4', 'fHNAxa0QaOM', 'lBtAULJAFp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18639 ['MvnC1TfNiPY', 'CJjyrDGmxIY', 'mBG-st0VUXs', 'aUH12rRIVDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18640 ['OoRUo92emGo', 'fD1xB9lDbPQ', 'Npbs_4DZgEQ', 'VRfi64fecj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18641 ['ySY5J3TDgag', 'nv1hWkBbG0g', 'HtCkwxfAmzw', 'P-eIhvCaK-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18642 ['qni67aUJbw4', 'Nt0U-CXK6O0', 'jFek2xLbEww', 'I-C14nCneBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.9251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18643 ['uYCAxX2F6DA', 'Qe_KwKVDgoE', 'I_wT76iYBdQ', 'MpjN21Z93JY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18644 ['O0y-m0pCi5E', '-o0ZtQIkM60', 'GNjsxLdSwHI', 'P4aTFrJws40']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18645 ['6807299U5eg', 'iHYOaGNdweo', 'OMApGp219Zc', 'AaajkQEU3A0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18646 ['7LlnLjZOqVI', 'EIzBD62ja8E', 'BfMKdrK9D8M', 'aURLQXt_6fE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18647 ['BkoCi-IZccI', '2SQxfaWAJJg', 'lBSS2AbA560', 'Euu6zlJQSD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18648 ['h7DOBV43UPQ', 'NsYVaRI6rXg', 'x9bcsYF_by8', 'DVuWm53IlVw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18649 ['Z-Vb1Ay-zNA', '1y1lEOGBcWM', 'J9ZlahUawkg', 'IqGB4nQIAcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18650 ['GYCfrx0ruz4', '2I6pPRWKsCQ', 'H4tyvJJzSDk', 's59pQGs7Q3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18651 ['QQTWFTNy-WA', 'tKawN2sxhYc', 'fvhbI-7e89s', 'hSK405L-DlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18652 ['qMd2DTyF9EE', 'bHNdoIWxXDk', 'HMQfp_qtF-M', 'A446kjocnCg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18653 ['yeu6OEIKwws', 'vTXb8P7sAFY', 'V9jIsOTC1lY', '7OjXHfVoI64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18654 ['3gh1oldZ7Zc', '2wZCoeq9Ppc', 'AgtY6m-b3Gk', 'ura8EjHjGC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18655 ['R0b3pU4AKNc', 'oC0e8GXYy_4', '2uvHgwAljPA', 'JI26wmUPcrM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18656 ['t-yy7v7P0IE', '3C-5_z01Olc', '0M7nETLOsKQ', 'yuWjB3XA8tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18657 ['1QSD-dzEv7Y', '_GxqvILlmAw', 'R_HAtyDbw1M', '8Nrp4jUZeGE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18658 ['PP3kNqPM434', 'XI9CNsX6JSE', '3tbFP_JKzXw', 'Rwt8j_USbWI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.6336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18659 ['_miAGxDX5FM', 'st92BzeUzFU', '4lcZkOMhKv8', 'Zz1Bz1a7yPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18660 ['raM8Lp0aGCk', '49nqh7uI9fw', 'ANaaOqwO0Uo', 'SlnjJv305Vg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18661 ['IjP5kKfgBiI', '9Cfs00bZRCg', 'ApDJYsi9UGg', 's1QeDT7jqHQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18662 ['XPGtOugQ69U', '7YWMPBHKdyY', '9Ijpv6e57a4', 'xR2p3UED4VU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18663 ['C0eCERYt4bA', 'R77XPtKgvy4', 'WJIrkvEq4EI', 'hqQvatf1RUY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18664 ['6zgvEiJJrM8', 'e4R2O7XpIXU', 'PwmXO0J-PAA', '1JwoLPCIGhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18665 ['0zolXzR9Oi4', 'zeUEOxTd8IE', 'JPZlyvPNZj4', 'G2uCAwYS6w0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18666 ['1lgqqW5TsJk', 'UHvYrO1IGCc', '3nbB3F-OdSM', 'AFWy1qyyMHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18667 ['jlIbJVfnHB4', 'gMgN50wSnNc', 'd9r_kYpOvW8', 'PRRcVdXsBQg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18668 ['ORikRIu7s1o', 's6U8DtBK3Us', '_yXtw_z2xf4', 'BXcEsM8ykhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18669 ['YIhfk4Zaevk', 'CpHRQ-f4UtA', 'RDW_kz4SXo0', 'aCTm1TcL7z8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18670 ['RtgHU1UMo5o', '4T2KBwRxi_g', 'GFJNgqcX7u0', 'uAYPacrJnyQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18671 ['-1LrH01Ei1w', 'vd1dgdxlA94', '2xGRCsW6-Bk', 'NqDxpJ2uR_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18672 ['BsnjK6DypAg', 'DYpjbiyPUho', 'UNJswfXKJ3s', 'Z9hnLYpypCU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18673 ['UfEGX0rNOvA', '6C0HoQe4Y-Y', 'oFCzd9bJo9A', 'qVdBBOpSoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18674 ['oD0Xp--xxjE', 'LEG7xkYOsWA', 'LM2C1eIUX9M', 'CyiPyjYX6AE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18675 ['EKZvq0dUk50', 'TzPuAqjoL80', 'p9nbp0Oo1U0', 'ZJZxWLYzNh8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18676 ['sC7T0sEG6ek', 'wwbATvWFaLY', 'rUIGOcQMaSE', 'Rf7vygfb7w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18677 ['xZukWGb52BI', '7vC1iriZlX8', '2ZYzviKuq9w', 'si_IAMPOXlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18678 ['Cwbtn_h6TP8', '_y07ENAx2_E', '3TO4C7SiC7I', 'uF1KTW5rT-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18679 ['-7wUQP6G5EQ', 'tpamd6BKYU4', 'uYYpqx0rzok', 'EPvnkbo5wrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18680 ['AJw-x30L46E', '5P5XAclO8ko', 'AwcuLXAPFDs', 'pHzjKCj9INw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18681 ['2gc1L3g1itU', 'RI126_DmGLQ', 'gNpzuFPu6q8', 'PF5LgwJjYuA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18682 ['qsFfUzErXqw', 'dBAeAk7dXnU', 'RI71ebbU0PQ', '2zpITTJiw7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18683 ['Mp1MHSeHa0o', 'Qz8hNRg-7G0', 'UeYmnV-B8so', 'vK9x7UQ9Y7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18684 ['PqTTIfja0y8', 'xxCnmao8FAs', 'F5zDEHggiMg', '1W2Cz2Jj76Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18685 ['W_MZo88gzrA', '07FxCXxknY4', 'aUx0xMF9pwU', 'je96vkMY60c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18686 ['tIRHm8VhK_4', 'YpOHemscGCk', 'z7vNtEcM9Bk', '2_kLD3IbF2c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18687 ['5rsQHo-6DI4', '08mf5GxT820', 'darQBSIlol8', 'IN71kMOAk_k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18688 ['1l7BjFDQLUM', 'eWNERam16Hg', 'aeDZVfGk7bk', 'QKkhwAAGLIE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18689 ['vOU-qA25xNM', 'too9MtXBwts', 'OKZF0oG1E14', 'D8-x1T8M4gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18690 ['I-xPuRe9vF0', 'eyFBIA_HOmE', '3VEMHWnewuc', 'rccs9c1gteQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18691 ['16TsDMjHzYU', 'rOOBAGxxjBk', 'mq_b6QKVsuc', 'MC0Aeu7RLSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18692 ['F9LJIyqQFe8', '2ctgUIqyaBk', 'ZU6sI1Plq50', 'h2f_CKjQQg8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18693 ['YZH-PZBir3E', 'KkW6ZkmAlEw', 'KmBaE7ozWow', 'THfTLXBLpJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18694 ['gAURHUoIK0M', 'OheHnFixwVk', 'navn7jCBp_o', 'dLUobee5JEs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18695 ['QIzSxE0WlKE', 'nYO8n62Piys', 'MROotmz8a-U', 'qknDM3pcoD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Step 18696\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18696 ['x1x54MgStxQ', 'mQM3Fd3eN9E', 'ZsmfIMEzrQs', 'WaddbqEQ1NE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.7003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18697 ['qFrvkOOR2HQ', 'jZi0VVWt72E', '06Brdf83RZE', 'p1DNl8BF49U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18698 ['fZjQBgPD1Ys', 'Ve6Zy1BXBbY', 'Occ4uW0lw0k', 'UC_XpUcIQ_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18699 ['Kd7aHdOwh0I', 'nzdlPYd8XUs', '2x9735gU01s', '_qP21HqOmA0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18700 ['HIDXdH6R6T8', 'D712KM8PE3I', 'qET3h3w35EA', 'V0zQHNmz0gU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18701 ['3OUNEL8XaR0', 'H6qzijVEqZQ', 'tv14XEQcY0c', 'HvuHSr_yncE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18702 ['u3yOMK8SuRI', 'AobHGHJSd-s', 'Zon9WGTwAME', 'ZX2fVPmUidA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18703 ['m-NM_tIWjxs', 'MVYSWTF11Nc', 'hgJK2ZDgWtU', '5NCUtndrsHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18704 ['Ou2rEaq28PM', '5h5NdW6cYY0', 'UUJ1DNycpiQ', '4zZiWBp0b08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18705 ['40xkia7fwEM', 'kp5OxEzxuSg', 'B9ME0Vcm_xA', 'sZwZ2fOWWSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18706 ['v9TTtjEngjY', 'IL1n6jzABVw', 'FCzMqo8kh1o', 'XRQyoAk-Qz0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18707 ['Hn46VuvS88Y', 'Lhw0H3P4zUE', 'eBF0zRHCbZE', '2YAyM0aHFRU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18708 ['XDBxMQrRaFY', 'I06TOd9pXng', 'Wdtku1dqJo0', 'DsAp3b1poeA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18709 ['CYZZIkEw_jY', 'WT2iyJmKkc8', 'AFwmMFq_xlc', 'qlqJF5yPmUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18710 ['etmmUjsRNRs', 'AeXDtbfpQlQ', '60OIHit4Q-M', 'NC5tIv4-8fg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18711 ['cS2gRhH6it4', 'hZfCziBaGTI', 'QT1SjY9mQxc', 'wMelBK3yArA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18712 ['mQWht9mv7sE', 'sVF7NNvdoJc', 'IISJXKl1Ih4', 'IwdjPDw6o5I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18713 ['eStzDzEopDI', 'TworrkXAPuI', 'VlwbDjggUKk', '1bSP4wLfMpA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18714 ['Q8X6geEBR2o', 'yrme-KRBvzk', '2i4UNf8tjvU', 'EUmfsCvmkgo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18715 ['PfpP3WjY118', 'jhsce15byHc', 'gwBfZJ5IGOA', '9UD7qz7DuVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 11])\n",
            "Loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18716 ['_cg_IfaD1C0', 'yYpfb_xV--4', '-VclCul6FrI', 'AgJH6Ul1EFg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18717 ['x1KyLxsnJY0', 'MwK9HYjeeN0', 'X96v9LlsjJM', 'Ux1vBolJf5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18718 ['XM4hxyK-Ddo', 'YODoF8e7Jlk', 'cs-zcTX2tRA', 'CdgQIiMdBa4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18719 ['J2BDMndrvhA', 'oNqBsQiNoAU', 'KqtlecvEOGw', '1kYDbl5Y9Sg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18720 ['pdIAN6lMXSU', 'j-93krRXAaY', 'Rdwtr2IX8ek', 'd1VB1vA-UsI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18721 ['BUDb8YieUgU', '2unse6chkMU', '9uToez74x_M', 'Ha-FS_CHmGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18722 ['zcc7dJIY7uc', 'A8CJ4YSsUgs', '9HQNvz4eZPU', 'BUzsQ6WohH4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18723 ['4ls_8xIjBzM', 'iFSaNmZyPQo', 'av-1Ih0S82s', '3QNFY4MKTy4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18724 ['8GKbDSu9Xd0', 'kVuG_F3qCuY', 'B4KIQtk7fT4', 'BWvKAcOV_co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18725 ['lpHa-S_x1LA', 'V1M3HiUz0ZQ', 'b1j-hD9zs6Q', 'xxNroISqkt4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18726 ['MX0wS7MX3Zo', 'Wd4T3iTsgrI', 'r0I-G70gyo0', 'YErpnsceZw8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18727 ['p20KE0LhL68', 'QSaX7QfeWog', '6VJ_auuKzss', '_zQTlTCqMzs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18728 ['saEDf6EV9wg', 'j8z9a9A8LV4', 'ce03XKuyDtk', '4T_5clu_0OM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18729 ['1a_nvi4sW64', '4Lk8pUeLCwQ', 'HVA9-fjtv6U', 'QXe9BpTENCc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18730 ['v8bBrrXUpdo', 'PWVr9weg00U', '0Q1JLNfm8oU', 'FsCQmTluSDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18731 ['yZNgqVInQGw', 'B1ixRtiUJ-U', 'jP4M9V_Ka8k', 'F3uf_RleI3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18732 ['b9yT3nGcD_I', '3PuzzYmTDA4', 'INBx8CrIWcg', 'sp77ueBkqS0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18733 ['id5ibIqjRto', 'n615BjoN7fI', '6N1LWG4aztA', 'IizUHzmcPGA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18734 ['jOkHEMsCCFc', 'HkXSX7Kdhms', 'dPM24O4my-Q', 'qOSdHmfwLF4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18735 ['BDH7Fx1APR8', 'EHm7vLZewS0', 'bZuXMxR2S4U', 'rY9zjr9T_WI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18736 ['7lG2zPKo9e4', 'E4a3s8NRqUM', '_RLsXrr0fQo', 'U3TpCc2zHrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18737 ['d2gHgzfC-Oo', '2WxUIkF2zEw', '1OIfQHKnAcw', '20Vh6z6Ie0E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18738 ['8Yt55huZGZc', 'S48GsFznk50', 'CGYflJRiLt0', 'kpsYSXR1wao']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18739 ['JKbUVdMJAO8', 'rnuGOQ-aSjs', 'DKBbLySEGic', '9NJEKpPeWpE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18740 ['Zlbo8ygfPSM', 'N0q5vPAsHLI', 'ILE12hEW5Ck', 'mpikDeSk-mM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18741 ['0u5-WiBKam8', 'Wvh59Y4OzUM', 'jjg0TCq3wbY', 'DGON0D8E17Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18742 ['MzUgHy7SyS8', 'LnczSOwV9Ds', 'cu0k3Uclp1I', '26jTWRMRoxY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18743 ['FYux89o7Hhk', '6XZGmRuaOfo', 'BqIZipifARo', 'PmiH7RnCkhI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18744 ['YNdexakUGOo', 'XscNEv9tX5U', 'LadgIxZu8Oc', '4kZ0EZg5JRU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18745 ['cMhajmOBr0c', 'Qw468qlDaAE', '6ieXDFjLKNo', '5gh5H0QqJl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18746 ['O6xMQnKJROc', 'YNv7mzbUUHc', 'Kt2MwCHV3Ko', 'pn6toTLXAck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18747 ['fSJ4qAPHaVM', '3YuO2UOYKRk', 'PBMfPDei93s', 'Q789S_9JCio']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18748 ['eQTK2fo3RoE', 'XmMN-6g1L8w', 'W_979HkE4EI', '05OJDYeHLMc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18749 ['lSbCqHZy_l4', 'ynWPvcGXFrM', '40i3_JH6FYw', '1jATjKL2vAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18750 ['D3q_stCeCA8', 'YGWweVRzFrw', 'qwOLhVbuhpM', 'cGUhG5PZp0A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.5686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18751 ['kh6rmFg3U4k', 'GFbSHWBjuuQ', 'Weu8nsJRMqE', 'tllFsEPv7Ls']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18752 ['_m-N4i-ge28', '3-_QS346VWo', '9QwaP-cvdeU', 'Du3Q6NdsSso']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18753 ['ZkGQhIbEDrs', 'laVgKAcv8XA', 'ChqJYrmQIN4', 'fRpJfrfjoZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18754 ['FteW_2gNtD4', 'F8MCOgWhgvY', 'G2JDDwIuNrQ', 'C3s-DmHtDUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18755 ['nlWXsfjHeA8', 'GQPOpFX20Gw', '0RpkkfkUBRU', 'C6-JxDWYJ-A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18756 ['hm0SeoNSGkc', 'kSKXtXXAD70', 'AEyeITzfPa0', 'Ki7Bxz1CThI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18757 ['iHXUaVWi7kE', '3cEQfNZ_F1w', 'LTG-uVV_6q0', '7zP5kNyDn88']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18758 ['xe9vDoF8TQM', 'CSzMTqkLHyg', '4tF0Lt9VEp8', 'maeSHVZX8xc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18759 ['EyO5vB4eqo0', 'SFHoTmcgw8E', 'rmKh9uaikTU', 'pWHkmo9Kn8g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18760 ['pzpg2-jYu6k', 'gp1DYuoQH08', 'KWpsFxRTGkI', 'V7RPmwxyhBA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18761 ['xvryKn-V-JM', 'Tp8PG2xae8c', '7fVfG0DrLjI', 'G22YfD5xxMU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18762 ['UcNVLU-cRNg', 'II1oyaWPiD0', 'I_kUf7vgVNM', 'CWKBzt-v8w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18763 ['hM88FG1_D5Q', 'qxWVr67g6yY', 'agw-ujSdX0A', 'JPVRBbdykSw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18764 ['yreWOyWr6Uk', '07xGXxIHOL4', 'wcLPCMoy5hk', 'hkWOAj09_dY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18765 ['L_fWnna7Np0', 'XxKlsW4H0qo', 'yQN9gj7Vk0w', 'jZkHpNnXLB0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18766 ['fw_cFbj9eHQ', 'Dg8BLvkzdr0', 'RmyyW-TMkVc', 'AsR5us-IS00']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18767 ['nc6h6rC3wdk', 'GuJdy864xWM', 'lh6ACdwNlyk', 'w0A-4EbkVz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18768 ['bZJoTauRldE', 'Phy-_ko0zWU', 'RPuCtUVfntk', 'NmMJgUo19Gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18769 ['HQ9HlWProm0', '28pkN4m1x6I', '68DacKw1hlE', '4q6e_ZDFOZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18770 ['blsYgo-B1k8', 'L1s-oPHsOac', 'TEoDtxjlctA', 'LbPRGDwlfqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.7747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18771 ['Simd4JoehW8', 'BfUoopDpmmY', 'clefr8E-iZQ', '8r1y_Bz4VfQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18772 ['qEGNzCWQdqo', 'BscoQHJrNm8', 'P4zWSoib5BU', 'FoFMRXlNJ6Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18773 ['Mhvgz5AjV3U', 'ieEPKa3HiGo', '6dFCMXNlmzQ', 'v1EDTMRmJlY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18774 ['fWypK9RHJJI', '40sAH2ZB0Pg', 'Wnl0qbVynL4', '_6C2ffY_-mc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18775 ['Di7Rs4QmYKI', '9QYo50tFm6w', 'DaeJYtWgcoI', 'k9w2aaNKenE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18776 ['Ycid0vBwqUg', 'MlnK2sa7mm4', 'EijTwCm-pRM', '6og50XOZeIk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18777 ['8WPG0dD20lg', 'UkqayNnk00w', 'KeSbjmMeyrY', 'iuNpXisjsLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18778 ['3uz_ZrGsIaA', 'Vr7wbGcvFts', 'Sl9ZkYViEIs', 'XEIP1OUXU8E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18779 ['LKUYtvUHn0Y', 'o1E579RL33w', 'vWM2qG-nU-Y', 'P0vjXnnIiR4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18780 ['t-L_PuzR67U', 'Bx3nzrmGXhw', 'hlbjpc48Vrs', 'k3A5xX8yfig']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.7133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18781 ['oZScu7DU5qk', 'yesyhQkYrQM', 'ZE0f_S44O7M', '8q0An6WY7_c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18782 ['F7JllgnefSI', 'aC3IBcRNyro', 'JIoA1KsfioQ', '1j13NdQiw8c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18783 ['2Gja9wBkz6U', '5UXnulANF8g', 'lnnlghshsVo', '5w3s2T0VBug']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18784 ['DlVgHV1UobM', 'aRGAnD12qdw', 'eiFyXXqd9Rk', 'rTBQmP6Vt0g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18785 ['fer_4HvG3aY', 'qVgVh9t_7ac', 'dsU3B0W3TMs', 'bTVl2GeNfqI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18786 ['br4A2uNud50', 'mLaon9oK1OA', '0JbGxIR8JTk', 'NsR60ehkHGA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18787 ['G9gsCU85c8k', '-r2-9oyIzkQ', 'ZfSlWX1C8yY', 'CaCjiFUL6Fg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18788 ['YDBxdZchOuM', '5D4siJjh1j0', 'vvfs2TUj-D4', 'b9rgWct9ivI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18789 ['8zDbEfC6Uf0', '6lPw0wKu7_M', '4QJktFv916o', 'Tsmx6Pb7CnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18790 ['zXxJymYt8Z4', 'mvZLlJpyDyc', 'MIexFfOsuJs', 'vEMNk-lbGTE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18791 ['xIbSUwO43Ig', 'Xf0aZ3a3Toc', 'u1a5eyk-9ig', 'pOZWVSiRwv4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18792 ['t5RqDGLiDvo', '7pdrGzdWMzI', '-NmjCyqIavI', 'sEGxoHiAPiQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18793 ['Akg1n9IWSrw', '0NTzOtVmoiU', 'EoZH1gyRlr4', 'PfO7ZVdzfZ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18794 ['IJw2o_Yg00Q', 'rGgvqyHKI4Y', 'k_ET0i2y0Ow', 'wPmTJWybq_E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18795 ['pSt8NwXyDlg', 'mlpTCec4igo', '7h6nTyP7d9o', 'yRWndZvIAHc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18796 ['iBh37YAaHMU', '0bP2MH3LqvI', 'hmkPWxTIwwU', 'y5I5pq0bXmg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18797 ['FCvs17jk10A', '4EwWBI-tHLk', '4PGzlwvXMnE', 'A4jSRfZ6yd0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18798 ['ou3LJpAM4mk', '2Q20hVyYjBM', '5JRvGMTjEzQ', 'tWByqbOvYQE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18799 ['YcfGSJB1YvQ', 'iVBNoH6XgW4', 'JvqCsVj0I4k', 'PaQGXIh94uc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18800 ['SwdhfGXkMCo', '3otUlQ4wvLY', 'JU6GUqRqbtI', 'AVogdV8khxc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18801 ['OI7S7vaBT4I', 'HplcVmJhuIc', 'Vy00ycBpqpc', 'Ur8O3h8S0K4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18802 ['jlmCu2GMoG4', 'uQTCfT5XDzQ', 'oT6ud0OdR_E', 'KgMD2_Yhw7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18803 ['q7U8p-m8J3s', 'maZ3b5w6xVI', 'JxwRvkjNJQ0', '03frQGyrgQ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18804 ['Qa-Qs9CtOOw', 'PvHKu1XRSJ0', 'Zs3arUuPciY', 'MVBQrBAXgw4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18805 ['fEHsR679g1M', '_G3lYKAITu8', 'EUNTykrvpok', '-eDAoheZrY8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18806 ['70pyoqX0U9Y', '8NIxqHJrL68', 'JLYb7DwCaQU', 'uGQ7QnKqeY4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18807 ['_IP6zlayY7k', 'HXwX9f9ugZ4', '-wVWjl9Kq6U', 'GyxH8ep_Vx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18808 ['F5e-SEICJP4', '5bsUYmXIgMA', 'sGVzzQLcT0U', 'kOREaTKeyZw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18809 ['vG0QJ3bjfqk', 'C5Zs-Lb2rIM', '6oqbYipROOs', 'TcoRmHHHNgI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18810 ['Uo-Okq1D8Xo', 'BkOfrw3c3EE', '7NtM1MM76s0', 'itgeNVRhBKs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18811 ['7ZXz3Xa7APs', '8qeTEfOqB0A', 'ccsgja0XsWE', '52odOK7G2kg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18812 ['q7sK_xrJz-k', '0EOQco76eXQ', 'FGZ0sLt4dXA', 'PQrYV7hJWDg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18813 ['kbAMGp-TKJo', '6jeq5lP5Up0', 'Lg1HG6D_0Qk', 'eayGg2OlHOw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18814 ['ihCl2ImrOYE', 'T2zoWLYzEpo', 't8SLY7xn7Sc', 'yIFP8fkq8GU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18815 ['eCyMTN6Hg5k', 'nZmhIHZINL8', 'WCl93HBuj60', '2gvyOxKuQPY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18816 ['LAeWwMC2EaI', 'KbDLu4VozGg', 'PF6Mn51Nkvs', 'hVVrl9FkKnY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18817 ['8MKemM0h5mE', 'hUcuXIvDN2E', 'j6O_U9EseKQ', '3QqVP0odOw4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18818 ['iLIBaMceZQc', 'yNIZaqTHUnc', '7J6U-HE3Lko', 'nzpnWuk3RjU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18819 ['ZsmxO0wnqdQ', 'WtN6uiDikRM', 'KSye2ifWZ_Y', 'XscK8V4Veac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18820 ['x9xXU30ktcY', '0ISHZQJdeSw', 'o2bqT0ZTz7E', 'xVab_CbwecE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18821 ['5rjQU4vOIlw', 'kZYBpOwNGZU', 'fpdgtpBOh-c', 'fjxD32KIHgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18822 ['cQWJeYfyw8Y', 'BaMBwXQwK3g', 'OyouRYAq-tE', 'tvqvuGywD8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18823 ['bm5IT7e2vvI', 'uUoEB3DBSjo', '31iD2VPLMxQ', 'dNQh2iLVAoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18824 ['apA0IY_5-2g', '-f1DNyngKVY', 'pHj8U-3RHc4', '7qaRlUc4fb0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18825 ['90NsBZvepy0', 'TJyzBaMwXFY', 'kvIt_9P79Ro', 'kR2yBlL6nFU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18826 ['40vmsGsFBsw', 'QZNrK337wow', '5KvjUzQbMT4', 'i8bt6Mb0rUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18827 ['HMJe5jS0Yt4', 'JqmOqYtQqB8', 'jD0nqkyuHPg', 'DOb8htND5_o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18828 ['T7khbuOBHbo', '4Mo7tdV2LZk', 'AEwkS57P4eE', 'ZAT2_-x59pY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18829 ['2zo5z1I0CeM', 'XfLIbeSJSHE', '1V7ReAk9k-4', 'Nz4iLzJBTBo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18830 ['0QAaln-hjPw', 'Ife1WaGirdQ', 'lIEnbqr3O34', 'nf3LGAL1LZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18831 ['Q0KwG3ynscI', 'BjIksWR4oKw', 'z8Wjdss5uMg', 'ICtri0ElFZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18832 ['MXdVnDVjSL8', 'q4PfLl3JVfg', 'M1ds6tRFxhs', 'ZUg7rRpFGvA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18833 ['Mv90uA0tmgc', 'x6U1gX5a_4M', 'Aky0DF507fw', 'ovVrS-q3Rzk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18834 ['IlUcHzBzZvg', 'bY_EvbARc5Y', 'IQxr3xwAbKk', 'G13NEVAm6-o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18835 ['CPr0YRTcaKg', 'MHgPpImV7b4', 'NjoKxRwQxCE', '2U8Dvh7nwFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18836 ['b6hr31Qaemg', 'jV8kq0MpWMU', 'jzij1UX73kU', 'Ezodz2aZnzQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18837 ['1pR0SgbqP3M', 'OKquGBKOgME', '7Msk_hkz6zk', 'E29kpquu8W4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18838 ['r8B3-yBc-4U', 'cWOohqFud6g', 'hHqrcLiKJRg', 'KxVbdGPAfjE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18839 ['aT7LGemDB40', 'ET7yQfaiF_8', 'AHmcuClSTL4', 'F5xnAYHuGlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18840 ['hzznbzry5R8', 'rrWQd5SZK74', 'hjrl1KHEuqE', 'G6ihF82lvEA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18841 ['LnL3KFKGqHE', 'iaRDUksPv50', 'BI8YQ3ueD24', '62L5kn1qFeY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18842 ['-Q9MTRXS4bE', 'EgwGYmAH0BA', 'NgniX3tg_Mo', '6-MdbipzKS0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18843 ['9JeN1ld-3fY', '11fNNN95_og', 'pS1X6Au1EAU', 'KxZ0yDfyaJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18844 ['CzHZNJEV-3o', 'pELIBvAnbkY', 'mhru3GXbkHY', 'mFcHGbnNtSQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18845 ['WNv-YNn1cZ8', 'vrxT5jhqu0Q', '0RcMzUdXDRQ', 'ZtcHktwEfAU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18846 ['YlgCFc3OvmI', 'nPlDt1R8Qfc', 'bt8iHoIf2mo', 'Y1ItBiA8nKU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18847 ['DQzg3cZeYSw', 'UxlrI-9RtWg', '8PcfPX11Hjg', 'Obtx-A9Lt5c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18848 ['8WnXfe3ud4E', 'NHA1l_Czm38', 'qVgnzJuGDBE', 'VgwsGjRk61M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18849 ['bJVogLOURmc', '0VsjSa1X7iA', 'fa0lR26K23E', '7XMqcbZKNNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18850 ['LfbGHMumxIQ', '2ZfthfWQowE', 'bzOeufhFITk', '3UHHjbO0ThM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18851 ['KB79k456DhI', 'C-NYmja61zE', 'WQsuFvw43RA', 'YvT7qFbUOO0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18852 ['IO5QJRyoqO8', 'CxgVq6eovRU', '2cxvYC9QZac', 'Jvj2WqgVy78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18853 ['vMU7ZKY2Eso', 'GuYRF0no7hw', 'v88cAXP03As', 'XW6tS4zAZ5E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18854 ['bpaq5wQKOkU', '8zcogfmAD_o', 'WY73T0xaY0A', 'AI9P6HoiJy8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18855 ['ax8hXst_b5g', 'yqb4GenP8gs', '9z4YXc9rjTo', 'm7i4g_o-znQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18856 ['0i8VM_EooCs', 'EBpa2CADNJA', 'yfaxqwNHe7w', 'Ts04bBeY1d4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18857 ['UoxHwOl2gN0', 'MVq9PYtypy0', 'Bd0PbyrG6H4', 'L8zjEoQFws8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18858 ['RmDfwz0OG8E', 'rJZgUpzqAyY', 'n4QSYx4wVQg', 'On9epzZ_ceI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18859 ['jKjj66pRXZA', 'm8-aK8egg84', 'BkjpjAohg-0', '5dG1oPahyto']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18860 ['Y-qOOR0izlE', 'XWj7nP7kfdQ', '9VE1-3q27Qg', '4H1nc2Xv2Hg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18861 ['DLJGT99uEh4', 'PSYURntIjuc', 'ZdqPnWEANuI', 'CPX6f-Awx-0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18862 ['jaJdPUAv6N0', 'hSSzn4bIwZg', '9gSOOPDuD4Y', 'BKQYrrJVg6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18863 ['xZTlnE6IcYQ', 'n1PTn_NH_K0', '9PMoI31ncIs', 'Y3WXrp3JFxU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18864 ['hj7VJnNq6A4', 'SWyF5TSxWso', 'o-ISARPUGlo', 'SHYGoXwgKtk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18865 ['mwwnfWgV_5U', 'pZgzjL5wbtA', 'LqP4F4a-HOc', 'whIj6mrUGzQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18866 ['JZnOGRCBW0I', 'SsVc1TAVsSc', 'kko1uYyqJ_o', 'nnUva-yCR08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18867 ['5-tx4Fgqetc', 'mFp1nrnlGx4', '9m0tNvskmTc', 'JpMHnsdsCiY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18868 ['RBniJk6GKK0', 'c2akbbdS7I4', 'w2MeQg3W7Po', 'Jq2w30NYstQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18869 ['nZ19mW-TMRk', 'BdKiPR3kdjo', '9FLDpfkbxZs', '3dzR3ZWOe8Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18870 ['sc7KNFUEdfY', 'OEIj1UX5ZRg', 'nH_lVl3a3Uw', '1Rd1w7Ty1ak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18871 ['ivymRS3iEZk', 'qCUJ-8AlecY', 'C6roSYqchkk', 'xydcedfPePM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18872 ['3vEsFxolnFs', 'aeujZtBvMFY', 'P25JeM4lPGw', '7cvqeU9Wh-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18873 ['EieK70X8lnw', 'N5BAnG2zoUY', 'eWwWwoQLtVg', 'JRfU_hF1wdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18874 ['gy6R280ZUMQ', 'a2Wuroc8DQU', 'FTdcanPJw6E', 'DE6bdmnmPtg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18875 ['LUtBqNS27AQ', 'LMGpKPavV4Q', 'ocCIB2bPq_Y', 'FYFapDVOFHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18876 ['0u4gY1bBUwQ', 'pbVYSktQ5jE', 'vZ9IanI59gE', 'KRKX_UtYV9c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18877 ['yOVaak2hemM', 'gb8PG-5i5YI', 'DAX9uKYlDvw', 'BTMWpYzpu5g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18878 ['EwDiNj_5PEg', 'CwmUMySSNQc', 'dIPW9gLGSx8', '2YQPwRLB1s0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18879 ['HS_ikHx4LIQ', 'O73wigUotGo', '4PNPgaLKFlc', 'WqC-fx3uNVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18880 ['CuUu6L5hhMs', '6OcoDIrbMtY', 'YTYj8Bk0qM8', 'wT2Y0DCq5LI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18881 ['Ip6FptuXHyk', 'AzGtPHlrlzU', 'qRLRLp-KTFs', 'Bx1HZVX4UxM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18882 ['HFH9tcIK_PM', 'YXDHyD4HU0E', 'aW6greyYuO4', 'O9Ag-dE-yfQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18883 ['C-7ubPOCeJk', '7OgH3B49_E4', 'LwmwCpAVPWU', 'W5BB6pubJZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18884 ['338iZ76huSQ', 'yWU0zNEy2_I', 'UoSID1KzWuI', 'VM-U7MyZAck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18885 ['z9UJD6O7EAE', 'JHkcCXF5vII', 'AagemOzvoZE', 'vtnuHbHbveg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18886 ['YSrTtw6ku2E', '0EvpBtracsk', 'qjJ41iwU9LY', '8wty3wJfmEY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18887 ['VAqPLAgn9NI', 'wj4ukZFNEgs', 'bpKbpKZB0Q0', 'Wh5JSj89tW8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18888 ['ymOjaaxRDLU', '_VmCPixy9GQ', 'DroAzooK4yw', 'tt5-i1R78ms']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.8122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18889 ['D9893od03Sc', '0Gxn9FtaJFc', 'wgIf0FX6WzI', 'VZjE27e9X7o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18890 ['NuN-ug3dIkw', 'uHgpDP_4Lsc', 'OLy3C8YpMsY', 'FKChZXXhufE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18891 ['aTeOMq8ave8', 'InKK8z21UYo', 'WhEd8h7J0Lk', 'O9_avJFKIQk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18892 ['w6zHc6nRJ0o', '6c1vNidtVTc', 'E6JR3htwgyE', 'mOFyRCMlXIo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18893 ['BBSApRvkaqY', 'uBENjCPS8LI', 'rgWm0-a0kAo', 'KN9vuaQvld0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18894 ['fhs7AkJsYao', '-3Kv4fdm7Uk', 'LaeRCg-NdeY', 'qie2k2gZ7wA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18895 ['bHiRX6QYwEk', 'jIoDR_eskaU', '1i1sbQOILb0', 'XaqVAF-ADWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18896 ['O8rHjrG3HM4', 'ypg2ItQIc2c', 'eWSA0xubW7I', 'LoTRWc9WK9Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18897 ['awax48X8YlU', 'X2gHQb5ubco', 'JU4CZ-GApu4', 'LGi38MqlPFA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18898 ['CQlh4k5pXKA', '8fInAz_GICs', 'wLQiZ-0VW4c', '-FlvaZQOr2I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18899 ['cGorUmWMrwo', 'rVdI-aD9pq8', 'aqhhfkXKJ1o', 'bKm2_67xtVs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18900 ['qXSG2uq2tNw', '6QHfXuVLhe0', 'J0lA7ZDfPLE', '1h2sb2xeCt8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18901 ['NZn4-gP2GiI', '26IOFykrJrc', 'jd94Ox7KJ9Q', 'KFB1raoIhoU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18902 ['SkIDF7iNJQE', 'KSFND-AdqZs', 'C5MhO2HM2Wg', 'O66lIRbF4Gw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18903 ['EsssGCL-Axw', 'GLIXnXZEOxY', 'tr2iVjsu4xs', 'xZSioXdxo4Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18904 ['588osm3C4bw', '0RDz0rLakwc', 'JR-1k8GHYAw', 'K1PzpuR6CqY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18905 ['CWQvCCRuU6k', 'KrmG43H1u70', '1dt9eL2rmSY', 'aOGNUGgTQ8k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18906 ['4o0bARRMYQ8', 'Jjr0_CbcYdg', '-1OlgJWehn8', 'oARFeTnImOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18907 ['kVaQA3PhSio', 'sGAYO93RR5Q', 'piyYJ2l_h8Q', 'BAUQY0e25DM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18908 ['g-ghr5fAVpE', 'NzvkMWY4EjA', '4vGLTrW04UE', 'c5NGOcNyF4g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18909 ['t12O05LVSBA', 'JEJLTct-014', 'XQB27QPic3k', 'pTzINk_nVHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18910 ['hDzmNYd_eaA', 'wKE9STHwX-Q', 'tBKOvAiNOQE', 'NmwmOY6iBFg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18911 ['tZgww16UyU8', 'wMHBhCVv--g', 'MPe6ztPtF0Y', 'I5KHYgtrVBw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18912 ['aY8-pXDdwiw', 'JXS5eW7g4HY', 'okAn7kjxmes', 'cYRsnYEPIiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18913 ['9rgB0wKU1-g', 'XFuw-m2gYOQ', 'oZoJ26C6LrU', '73YTz8RC2Fo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18914 ['pDgWT99uaJ0', 'cCyfADwHiWs', 'OH8urnIthoQ', '0s0Uy0-zBa0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18915 ['hhVFK9tYu84', 'B3WaJ_3M0vw', '2KkNk9Ao7G4', 'f6H0TMWDaZg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18916 ['dbftWJH0OvA', 'vo-o3dG8Oq0', '7p_Mnxl4Vq8', 'Qu76GhRO9Yk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18917 ['0NZY0GHQBP0', '_8OIugVSFeE', 'EN_FOFkxAEw', 'NZ2kFIaW05k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18918 ['sgTZHSTnU40', 'agK1OkzW5Yg', 'JzRb1OVpat0', 'zPhuyMYy9EI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18919 ['0298WjE3_tk', 'TFLt7mn57ZI', 'URM1QgX5Ar4', 'MmqRlHntd0Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18920 ['JRmfjBDKCpE', 'fe10sxFSz_I', 'RSryuuvUfDM', 'yGXohnxCLCA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18921 ['je1amtXOKF4', 'ZX7EzqMBjfo', 'tcOHcop3sCQ', 'TIAj-fi_R7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18922 ['axb48YrvRmw', 'VHYxygh1STA', '_43OOP6UEw0', 'Cd7JefC6-Zw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18923 ['I6eU2qRjJ7Y', '3noh9LiQNrs', 'uLp6z37bfVE', 'D6xrH93lnoc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18924 ['fcpVyvn5vKk', '8oTTgXIO0-I', 'lDGQu122JdU', 'zGBKakEGSyc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18925 ['FE2kALvHjEU', 'z_fEIZOv0JY', 'YSXrSxC68VM', '-88me9bBzrk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18926 ['jqiD3VeM_hY', 'sgwvhvkNELc', 'Y7mTjfgcybQ', '3tyb0cXoX2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18927 ['JDrnf3vldLw', 'p2jnUySmuvA', '24cmo2fEQo8', 'caFMauLQvd4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18928 ['DGlP6oTqe5Y', 'aUvHaURNgY8', '4refolVb_uQ', 'BMgYWTTJv3s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18929 ['h6Y0KDtUNHw', 'DA3fNvbZoBM', 'AjjQqd0eLzw', 'idUZsNLnyDg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18930 ['UOKWQ2EHJQI', '4TXy2i036LU', 'kf-U7I0-DdA', 'z31iCbkqYyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18931 ['nZOgoVEud_w', 'JZyw6YUsGzo', '0bRUkLsttto', 'cGrQw46ftj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18932 ['qVT6GX1KHUY', '8hSmQpOPXJE', 'XI-tRuDZ6HA', 'pQWpa484HQM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18933 ['DW3z-ByrfWY', 'KMQmM12G9Z4', 'ZoAfkpmztww', 'AqSV_WKZxEc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 60])\n",
            "Loss tensor(0.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18934 ['aGMdcxeF6Ak', 'EwoCbcSXlSM', 'tnJb9WyhCUc', 'OxxRnDpN9cc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18935 ['qbexOeoH5hg', 'yFh6J72KnCM', 't8os583-_JM', 'oRVivXC83hA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18936 ['7ZW8xO37bA4', 'Z2c1npe5AYY', 'qUWYzx7pBSw', 'B1vY7kxQ9Xg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18937 ['FaD9qs2ACpI', 'tsdNl72WVs4', 'jKWl63gozLE', '33LJ36nAozM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18938 ['fWfQxB2pVrc', 'nAKUDXMeWeQ', 'I0skZ6yT36E', 'gffng5G4X4w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18939 ['D8zK7PHIkgA', 'HNf9eHqDT1A', 'Wh_g-Eiw9Kc', 'KPymcVenomk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18940 ['CBUAy9Zl6ZE', 'sOJSjVp6UTc', 'DHo1z0_ZUNA', 'tWseBEYhE1M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18941 ['FNnKFUkFJ5M', '39MksqVeLdY', 'J9PJI1UwIQ4', 'kVYXcbvw9u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18942 ['whZygh228yw', '4a1a-lmDVaY', '6k4lcF9IGUk', 'tnSM-SnE5Lk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18943 ['doHRurF8bf8', '8dE1x--TuF8', 'YVEqyQjyy1Q', 'sOSU7p9pLjs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18944 ['1ToIyrmWFjw', '_5fwnVeZbvI', 'en56uOGTwzg', '7ym-LzgwSPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18945 ['GbjtSTTEFK4', 'eXWBC3XfiXY', 'ZzyWbehtt0M', 'HpkPTa1fQDE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18946 ['wv6YaiCGPi0', '7IndxxjZe1c', 'fM8elJ4jkic', 'LClTjcyNJSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18947 ['iQJvAXOohoU', 'YyHmz1vcob8', 'fBEGBuO3RXg', 'ltZCJ7aPtO0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18948 ['giPa2vVEyVc', '1cqcTbDxsHM', 'e4abjaPD9R0', '0VjPCd62oKg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18949 ['IwobTmzjOiQ', 'Tfc6184uCIk', 'EptdhC17avY', 'YMq4wE6KxmQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18950 ['IFimpFwvbz8', 'US3ZL2zhXgI', 'fvw3Bi0GONA', 'XfLI8gHCuFE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18951 ['bwHPVG6vbNQ', '5AdeNHlPnvs', 'fYk2U9yJvps', '2aPVOidHLXI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18952 ['BEhIGoq9tow', 'kepd6_X_vS4', 'p1-07VdP__Q', 'vQ09gQBt1IU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18953 ['Xn0wIqnt_44', '9L6ePkWtZI4', 'NNeEzTVATHg', 'L9xj_v65UhU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18954 ['XE4NRSDLYG8', 'WIuLaxWIAAI', 'HEclHruM37s', '6iZ49s7eH5g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18955 ['LFYRuK8YstI', 'PeWXdkEUPbo', '9GRNQKSsbvU', 'QzMsoz4XIkM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18956 ['JvvnL7UnCGA', 'I2yA-F-_A2E', 'BcVapmCbULQ', '8XBsesSEbbU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18957 ['BiPwCMlghhQ', 'vpU4XIISXtM', 'U4MdEIQcZxs', 'C8VECv8kicU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18958 ['YtYjdkTK5oY', 'RJViDdqUYyo', 'AareFwTIg1s', 'ZF8uHVu4Res']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18959 ['c1hLduV1p88', 'OhZmxS5DUKU', 'sZuhztdaFYA', 'LYO7_GxyaZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18960 ['2KGnpMYHBGI', 'UtZofZjccBs', 'ZnBvXFDWpWo', 'ZgooDijn2as']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18961 ['-5xOcMJpTUk', 'fPYxUa1ZVAY', 'g8XTU3OalGs', 'PRzBkZSSyY0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18962 ['O84YjlJ_Qw4', '0SNhAKyXtC8', 'dKJk3JavNzo', '-XN0NtrnfMY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18963 ['Z8L3jychP14', 'hYy0na5oUzE', 'mOmYcOBqhwo', 'd0Uz_RnRV88']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18964 ['GcYeBWujhjw', 'lDCDayKyOQA', 'HyyHwIK9SSI', 'EXRKJRL0TDU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18965 ['0KCVgexi4yU', 'LCzldLY3E4g', 'NQXQsVawPhU', '0m9-5BkL4Mc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18966 ['vKjC5HTH22o', '55vMO5LzMHM', '0_hH79HnEdo', 'HHTgjmgTV6c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18967 ['5CtvEcPtknI', 'GQbUpJFArKI', 'adYFXYPqo2M', 'mwqluX7sXXU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18968 ['Z5x5BLzQKZI', 'qAr3mFkEvco', 'n3EeS2mVU5w', 'M61BBJpvvx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18969 ['Z6q5doznOcI', 'xXRGgPVnkqk', '6QfM3BRp-78', 'k4kbpRRRgcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18970 ['1Ziku4FLka4', 'hdlnugbWjKA', 'eSIxvnEQ6R0', 'DXeiJpZXVAI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18971 ['nVsAyArtEh0', '2sIfE3KOi5s', 'HVsXJDR1_Lw', '1RwhRTe-OKk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18972 ['Z0htOHTOtHY', 'EnewI6fNhVA', '2SI_uNBcSyw', 'fsXfBoNcLeM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18973 ['xWmcax3aX5U', 'k-J2-Ou1Fm8', 'w0yHqPxybQE', 'rsCQ1PIGcm0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18974 ['zkYXE0-JsY4', 'a4BjqKd8FsI', 'hLwMYygjRfI', 'VeXcCHo5iMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18975 ['JUwu4xOs8K4', 'TEWYFkjH2jc', 'PQ7cX2Cnusg', '7LlKoQAvXUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18976 ['HHZGjS4g-w4', 'YxQzJweGS2c', 'NPXZIqxKvXA', 'WySgNm8qH-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18977 ['g0aOPWwNMFQ', 'ZHsAU90h8oc', 'gDzi8N3BYMw', '3tSPMzvuQpk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18978 ['qfwTbBprDVU', 'eVjcfdxSFKQ', 'J7jVR6y6REA', '6KqFiP_ux5U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18979 ['uPGasFKZSBo', 'KZ8gBHLNmH0', 'DaiVfxATCEE', 'T7bG4kIEw-M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18980 ['-YIT4HBM__g', '6sWVG6GyJBU', '7MuFNZHhrOE', 'M5sptjrboqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18981 ['8pl1D6oG38k', 'RD8kf4453cY', 'a-P0p_UtagM', 'BzM0qok5Cns']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18982 ['PcdpjUIa8l0', 'dYVy7moyQCc', 'fKni4PUSxu4', 'VJ-dpTx_3Cg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18983 ['TyMZJqYmrwE', '9BHvpWP2V9Y', 'VTagIq90b7s', 'bBfi3iEu9fk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18984 ['2BGzxAuetOA', 'NLQts9t7d8k', 'Z_0Ta-m_-hU', '5QtjEBcZR6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18985 ['H_2ZPxy80Eo', '9dBWFEpcJIo', 'A-7dmBdsFXc', 'gsBXngKgy-Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18986 ['gOhONZR_F7c', 'VB82vMSTYK0', 'jtwRKyQ8-lg', '9-R70gSqvrc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18987 ['5iUwBOf4yek', '0PMFAO4TIU4', 'WhX3jQxHZWc', '07-vpXo91XM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18988 ['AtWf5OAE8aM', 'wc4UEh8wvCA', 'ftKCLRd9_no', 'GNu_hiHGEp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18989 ['rs5ecH8Lh3s', 'GOTy3yhCylw', 'XHczpbtBhk4', 'XrjkzI6TVwc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18990 ['kGo-dAQXtsA', 'mB2FAS0DNkk', 'rfQ94EXIpTc', 'PTl5ixI1Ogc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18991 ['6gTrMRQPZMU', 'VjbRot21Hq0', 'tOnjlUzqSC4', 'jrwhxVnvMdk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18992 ['FSQ3E4XbpPU', 'PFtcnQqLdEc', '-5f6hjZf9Yw', 'Q6dVti1YVwM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18993 ['drqKxGmdf8Y', 'ZwfzBagtpV0', 'ADxuhHNZVCc', 'oOlMzQpK690']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18994 ['-nlkWWphiaM', '5hEt87nd7os', 'L_ghM-NrH58', 'eWqD_VOympU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18995 ['ZaUaqnLdg6k', 'xIdWJyhWueE', 'vYP60jdTupc', '9r01cpNx2vk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18996 ['3XRjrSOVBnQ', '7V0G65FK2VQ', 'atWaDoSyGgY', '5Tq56BN8PCQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18997 ['_dF-ZGquRNY', '6AC84nr6ckM', 'W4nQpOHIPEw', 'H6Y_7Ax34-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18998 ['iMTHDuW_xKc', 'CZoPTJNmiCw', '_gWEpDgPAho', 'fp0oCFL6w4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.5018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18999 ['PufDOSkxwzQ', 'gEvCUcZ6w88', 'ORt8LSgn-uA', 'OrsfEkAhie4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19000 ['KV99GJg0tvA', 'AFwtBviVhhM', 'Vbx6TFxSPYY', 'oSg1VJHiPOE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19001 ['R-aMYx9f0Ho', 'bSX5-VPL8rE', 'OH2SQhJqZDg', 'w0QJT6ywza0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19002 ['-0SdAVK79lg', 'OII3VJoE0WA', '7k3OZ_fPXuM', 'WFPGA_BYkKU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19003 ['gD6UoStqCsg', '78BtX0oNXHQ', 'R6mhBqTU0Tc', 'oSDZZHN77PI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19004 ['UcabTrKowlI', '9xV0nmojVeg', 'GAohd8KvONo', '3TP1itJqv-E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19005 ['9gCeNCnWZhE', 'v6A7Iggebm4', 'zfkPKRn8ah8', '4Psyk_xyBl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19006 ['9vbsI9xFuo8', 'vEl7ImwLlrA', '8ZK1ajW598M', 'mWuX--EEq2E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19007 ['wQN7fRaPl2A', 'gkB4KBHBV9g', '8vFJX7NcSbI', 'lnJdWXRgjKo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19008 ['4ZwGxgOwBUc', 'JnfMv9ti9Sw', 'heZw1TTrtTU', 'SbUwQctvbHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19009 ['rVymW4Nb4NU', 'tGv_L09pf6E', 'WSMdqFEjGXE', 'O1EmHJyz5ds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19010 ['Pd4WnsXwdqw', '7JMN4DdhwsM', 'AOgbZUl0y0A', 'pYXx0xXZiXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19011 ['FKBryvLMTY4', 'hbCaMcbT8to', 'vNPL092rPgQ', '_R9Ma9rjEWg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19012 ['kOBh4NZ4wZQ', 'ZEN8_GtW_UQ', 'ZiHlhUvmgzQ', 'd6w3d9S1LVM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19013 ['VjXt63pqUgw', '4ezo771lGts', 'TWm0OilO0uw', '3kXukXBvDQQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 58])\n",
            "Loss tensor(0.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19014 ['Ail32Z1T4QM', 'b98BJ36K1wo', 'kTyI2unrdv0', 'wLITXWAuZy0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19015 ['GzRvq0gJbj0', 'h-2KO5ufrcw', '2MpzHv5KNZU', 'zw5dkiklbhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19016 ['a-11dtG7aK4', 'YgX85tZf1ts', 'TbA_TZn35LA', 'tUJ_ZniLjhc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19017 ['DAPGvg8qOAU', 'HvOSaS8sXQM', 'wz-7sy_Rin4', 'Rhn6K9HCbC8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19018 ['w4ayJNZ5w5o', 'Pq1jBX0RW2k', 'sxgMEmp5aGE', 'cjTrK-kA6x0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19019 ['BS2ZnUhmHj4', 'QNQ3sAMxZPY', 'BQ_KrefFiTw', 'LKurVRvkmKc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19020 ['RcfaWoTywcA', 'vWiq7n4yTAw', '-XkbErI_7EU', '-R0267o4lLk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19021 ['BxbB2_N5Xtk', 'WPguqXCBQCI', '9hCnEfZFZ04', '72_Hk1cdoxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19022 ['bztxC9EFfCk', 'deIj55UAxeo', 'NxpnW_IdkSY', 'ZQwpXl8qnnk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19023 ['V1A4wBgvPgI', 'NnmJ1UHWlas', 'EOaQnfDjVyo', '4yJZ4VX8XQI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19024 ['Zhurw43-Y1g', 'kbquMoJrhC0', 'BtdzVnXZ0i4', '0ewWspUqB6Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19025 ['2FQKfGCwjSE', 'AVmJF1uaRuE', 'Fa1c4qfBqzE', 'PZZxVIIOQPo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19026 ['H_5wh4aMQe0', 'CRUd8kY3L70', 'HtSznF9_784', 'vStedb9LiDk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19027 ['7RUkkhkqyUw', 'VfARCp38XtA', 'ITg9o6Gwsbo', 'ZV_ZbmjPpkw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19028 ['4kKVGPDCIK8', 'cqeVEFFzz7E', 'mPaRs96jtFY', 'YuiQRYaF9SA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19029 ['GOujNXEtDmg', 'I11AcD1sGes', 'Ac4M-EkdkDs', '_lq8nEXh064']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19030 ['ETl0hYRlVmg', 'iS8YQGp2_ng', 'P65yE_EXLd8', 'ckOe-8qdaew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19031 ['ClNTn1wtq7E', 'f5eMUCSZCjc', 'SG24NL2Xi3A', 'QlaW568SeDc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19032 ['5xIBQGMjiX4', '1AOe82obwcY', 'DgqPgNqW2hE', 'rWitVrXe5tg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19033 ['2x4694ExyCU', 'QDTCAxyXt80', 'lDsQWSf1h3I', 'XzTBNfQ7_GA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19034 ['nFoktpUVeVw', '0ZNFJz-eZTU', 'Yiau7DypQi0', 'tG5C-Smp-eY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19035 ['hPIh5RYA-5M', 'aNjtfIoVzas', '0jFQ21A6GRA', 'T7A0RejsZIo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19036 ['W7U-glgu4GM', 'b2-izZk5_BM', 'hNKTrKk4hZs', 'CrkxrgTiVyk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19037 ['BHu95Y_kVQA', 'un-OXLWhvDc', 'P5uIpVLEpm4', 'HrwpdRe7meM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19038 ['rzVNYg3nClo', 'CMfAu72qma0', '4sD0Bvt3FKk', '40kbMyL2Wgo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19039 ['AT_076RUWPs', '9cojCCMSABc', 'rn_v88OiRks', 'cJD5JFWnxNo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19040 ['7l4-QmvXxEs', 'DTnCrtCro44', '2KwSyaLT_mw', 'v5SsASLy2c8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19041 ['gBuLpP4klvI', 'Eop_sG9FVgA', 'In44gO8Ej90', 'xSmmTveNPSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19042 ['1ArUx6UCxe4', 'iEQwupwwp0s', 'Mwy5Y0S5jfM', 'AnMR6SOBa9k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19043 ['Q0VVfneN8MI', 'LTDle_h2YD8', 'Nlg8AbWRV_c', 'tpnvHb9ZhlU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19044 ['WeDA1mDFSCo', 'SNhfvhWPXNc', 'u68Ghaf_Phs', '4L9KyVVsQOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19045 ['AElgGuUSSKE', 'NDJEKij2qOg', 'XXBVsNt2Qr8', '0RgGrVklaao']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19046 ['XgLUXNAC7b8', 's_BKo_1LzJM', 'oN9_GYDkNcM', 'SLdVSirZMSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19047 ['d6nURbq86zM', 'aek3GoFr5MI', '-e4wXAy1iVo', 'NSS9_2FFVeo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19048 ['JKihzveDE5g', 'K0x_DxNxtbk', 'DB38NRSHw9A', 'rC4PNZ1XOmU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19049 ['k5kPBsMFlOc', 'Ok-ia7ziJy0', '36ToDxW_hns', 'Wdl7A3de0L4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19050 ['hQ5OBio4Cy0', 'WsDb16qzA5Q', 'BiqPn3d_dKM', 'bqMgL5qmZ-k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19051 ['VrqBeY3kfKI', 'R4ulZgTCw-k', 'Ysrlv2UlG8A', 'rGEJVUcFA2U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19052 ['vjW8wmF5VWc', 'lqeAf-DqE3I', 'zrb76mJOZQQ', 'j3a60_lwWjE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19053 ['w_z9oSn-eIM', 'gqkqzqCHM3A', '0fiOM---7QI', 'ZOzavOPeuJQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19054 ['01PzcPKT3_E', '9M4IT3lOU10', 'IQbzpgmi4Ec', '26HLgXWF-Co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19055 ['8fibq2VXibw', '-BHPu-dPmWQ', 'i_NNY_mgxIs', '_GQnXfIGNKY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19056 ['HdRPdh-cSTw', 'SkFG5SoXsVk', 'A7RgbrJYe_s', 'iFWtsT5zRKo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19057 ['ehJKd9HLA04', 'dql-sQqgVXI', 'KubrAnJ0o0o', 'vNPx6RS8PiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19058 ['KrK8Giu9ZUc', '7Mv4eKPe850', 'DueNcVFHI0k', 'AlVr7-ntuqw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19059 ['uCCdUB7D10U', 'AJeRSlZuZbk', 'GHQlBD-6rkA', 'lDABsoatahM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19060 ['imIFtW4O5S0', '6vM7Kv42Uv0', '0Wdh45yt7tY', 'M4rXhyyvERM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19061 ['JtLNRHVGQuw', 'jhQpTVVUQ9E', 'xl4FJzeU0YA', 'zD4PXuUkwsc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19062 ['CN2QSmhP-HI', 'cnvmLwFZr28', 'E16FgDFQI_w', 'TTytcT_1dmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19063 ['E_kgtQ93Q1s', 'Kojo5khAAS0', 'jQYSfy4DzIc', 'DpS_TigOHWo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19064 ['Pk5NZe-ah4U', 'A_Yd5huF2Pg', '-hYRFCQdbLg', 'BlhUt8AJJO8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19065 ['coG_EznBmzE', 'Z0OTDXtjK9M', 'C33WdI64FiY', 'M_s-49rNCdw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19066 ['sd1gAgsXMsc', 'mLm8upEhc_s', 'qDjeY72KaSo', 'LbQ4zHxhoSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19067 ['by57LpTlGbs', 'bqvl7IbPteU', 'xKc_9B3RiOc', '-0Gj8-vB1q4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19068 ['SSO7F_Ex0s4', 'dvDSgmqbrM0', 'J2R8Ab25reU', 'mCjsuxzcl2k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19069 ['NX3KJ-tVdMI', 'TZGDukKAVS8', 'mzDq-abtAKs', 'TabaOeYq2ek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19070 ['bkzGHRpx5MM', '5z60cbPEEaY', 'G6A9NKeK8ko', '-CUp_Tmg2Y0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19071 ['8kH-dzSBthI', 'oOiwmRV1PBk', 'XXdPZMsrBd4', 'axqtExFY5-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19072 ['ogOTksL2Vas', 'tAdNaRRFFXg', '3u9OO9Og0Gc', 'ItLWKIhe58c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19073 ['YBbvQ0RPrG8', 'Ls6qMcgpdlM', 'tQ1Nl4Dy2aI', 'vEt13GxzDKk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19074 ['MocXmVbat3s', 'sH_nDqYVq5E', 'cf-IIqhveKw', 'ScAlKYCgHV0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19075 ['sm7eBFHtdeA', '2G5bSYHcJSM', 'rLtXML8Y5wo', 'U8yqYlErUz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19076 ['v582kPp43Mg', '0J_TdiZ3TKA', 'JOkuwbhMxbQ', 'Hij_QxDkIJI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19077 ['puAclKsCbes', 'hoPnrbKOEl8', 'gHWMKew9Xq0', '0ONdm4sW47c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19078 ['BSe5J0KlN3k', 'HrPnGYGrvm0', '8HHrlxQuZKE', '_JTHtcRHxnw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19079 ['S2yXmXUJ5xU', 'Jj9orXFko0Y', 'xsLJe043ar4', 'ZocCGcJcGJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19080 ['7DIPyJB4osY', '5jQIuYPAODg', 'PpJKo-JPVU0', 'WEXJSNm_T0o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19081 ['8FZb_R2UANY', 'x14jW4c8YnQ', 'cQX-WgT0ACQ', 'xJMTA3Ay5FI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19082 ['TqIptTnXb20', 'tz2TlSMmTp4', '4vWChPYkuwA', 'v0tYHz5mk4I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19083 ['Wvg5rlMbjJc', 'B7V_grbxflg', 'F8wGRd9332s', 'cp8t27oT_ww']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19084 ['7YtKrL6ScXA', 'ULHPhjaJ6p0', 'z2kTJ6pQ4Uo', 'rS8oECcQBCk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19085 ['n3QsFeGadEE', 'CgK0DU3KFBc', '2hgvuYGc95o', 'hH6thMA3640']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19086 ['AjLuenrAsbE', 'H18aK9HhNSM', 'rPAB0ymJGco', 'duMRKOb4E2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19087 ['1o7iTDLNTFk', '_kPmYc1nXuQ', '7yK4-hsVX1o', '-r7iz-9v9bA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19088 ['wRWxsKN394Q', 'kaabXWuPWRg', 'Fsv_syCvzsc', '7y9RfZXJZsk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19089 ['00M9FhCet6s', 'Qj4r_MCC0mc', 'ad6UhYwTXXQ', '9nVpyqfyBSE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19090 ['QyMcSnNsAPw', 'DKflAAykh6A', 'nJ3tuDmcdTs', 'CAbNGe1PWoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19091 ['Lq0LMMZfHCU', 'WYbD9YUrf_4', 'ECP7EJka6N8', 'jPOWgfA0zAo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19092 ['8Bu8CkR1xZY', 'oYECB7KFJgU', 'p7VmMa6cpSo', 'Aro-HcWNsHI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19093 ['m3uiITzeM70', 'joLyjgORwDo', 'GMFWnMRtfNI', 'hHS5C0RKa8A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19094 ['1JpeDWbgUO8', '769EHEG4Mqc', 'ZPK1hSPI540', 'dqQgzsNpwoQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19095 ['nXfqAzdu8IY', 'QrKJs6lBfmM', 'fDMbNCdGXBc', 'AU1l1i0H0j0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19096 ['WE0JqjuhaQI', '1yWGmdevTuM', 'snJDZAnTMwQ', 'xJYBA7VTkHA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19097 ['1ls3ectO1F4', 'O25IKwo2HkE', 'pejDm3j4Y-I', 'kcTwJwdLTSo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19098 ['MkPhe7TLLZ0', '8kx5ST65Fog', 'cXEJWtj2kT8', '-taO6N-rxv4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19099 ['q87TmUmVg0Y', 'ywuR9AfpA_E', 'KjMRf4egAyA', 'LH3mAtCou6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19100 ['CphwhKgYHaM', 'wxKtBDKasgM', 'Gc8xf7CJiFY', 'eZ8yopmYtPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19101 ['jjNxc9Zf9s8', 'xx3nnVzGXa0', 'I1wakVlpP6M', 'yCDloqQe65k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19102 ['tV2m7HFJprU', 'QiD3AkQz17E', 'nxdHojfss_A', '9KK6rg03bC8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19103 ['ktw_J6ZW0MM', '4i9DgH80kDg', '9TkW1M_ZRr0', 'SDTsifbpGMM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19104 ['gjujPd1lP8E', 'ui6ERk-AySw', '5tRNPTLRZqI', 'gXOyw8a4_Xs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19105 ['wMi_0eEIpcM', 'JSqyTVjYY6k', 'WgZ8KAnnTb8', 'aYrjw3gjGuk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19106 ['_Rpn2FUAUgY', '7jWRIjFaoeU', '_2P_EJsnBls', 'JmbrGzgxrJ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19107 ['4Bc9OoagYmo', 'OZjpYGdvMX0', 'KikHXfUanJk', 'OEpMpYMjO9Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19108 ['-8cgbhIR_pw', 'rE7S4nLrThs', 'dS8AZdmn8Wk', 'hu5pjj1KzK8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19109 ['NhVkzcCL0SA', '3w_LsKl-3Pk', '-6HBGg1cAI0', 'B9K58KYq-Cs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19110 ['PN3Lx8RutmI', 'kg8FwhL_fqs', 'rrAIuGMTqtA', 'wBozBh7BR6k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19111 ['x-ob6_6f4jQ', 'qh-4EDX4agQ', 'NZYDLDIyZr8', 'ODOrls3MuZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19112 ['Ie5FO_BetOE', '5a_Qxd4ECTo', 'fxznho_kNPY', 's_LMd1_XN1w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19113 ['kT0KMsfD4d8', '2-K-7T8ZIWA', 'VAqgpoyD2jc', 'a_r8wKJ8ePw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19114 ['3XeMR8lX0dg', '8m-a_6wLTkU', 'xmSMAmnoRug', 'qrzNABqN420']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19115 ['rkapTdi8NTQ', 'SwRjY1-ojAU', 'AVsNJgR_K6w', 'pdOskdFwRPg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19116 ['CRDDdjDinYc', 'JlzlNpttvVM', 'vgpV6F9tge8', '35b9UHjagaI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19117 ['VkXLtUx-RmI', 'NcsYdCbKgcc', 'sYJiHxmQWjo', 'dzPPmuFUicc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19118 ['15z-gbPxdXg', '9ZAmdxKLnhs', 'hnlVKC7rxdg', 'w-YAUcPl-HU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19119 ['g2H8i_TuhgI', 'mfZMcNmLxWM', 'l8P2wU-JyI8', 'yRU7DifuAXY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19120 ['UCBocxMCdck', 'zgI-Lr6Pbcs', 'P8nK4i8XscM', 'em7akjDUsWk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19121 ['1Is1xfDjZrw', 'W3DwueAy65k', 'J_Raltj-6dk', 'YWf3I4jKusI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19122 ['BEwNrjvNiYs', 'gW33LYEvoaw', '3nfiGGQykxk', '1j3pXUr8R4M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19123 ['5XNalwqtkFg', 'lwQVcLxFBIQ', 'dcgwxlK3VVk', 's72505MIhz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19124 ['XJXn88r9ys8', '_cf0WYQcNvk', 'drJaSu3AWhQ', 'w8c7JFU6by4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19125 ['0-7PyzhzuYQ', 'pwX5SArqGKU', 'vBw99ghST1g', 'R60qQ3ag8y8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19126 ['KurvLmoKCog', 'o6ZQNr0Tpz4', 'Zc4rX7nbRW4', '2dyEnOo3yJ8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19127 ['hkWcUtga1lw', 'SGFYFPs3Fic', 'yScg02DM-jY', 'tRA-5inwlMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19128 ['RV05BW-2WIc', 'TKSFbf-wQ8I', '2xtOqrNKH5s', '0QYNC7J05XI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19129 ['Py8Vd0-qxYU', '6u1ckcErgcQ', '9UOPRQhNzQ8', 'iDvva_WCo-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19130 ['2ZB7DUGOdZw', 'opu2tXoVNKU', 'JDWPJ1AiDKc', 'LGW99kSaf6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19131 ['p2NPfU5QARc', 'OOik9i9wrU8', '4GlH0-KhInI', '3tK7PpCo0PQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19132 ['fESsP6ZnVKA', 'ZUkh168Nyus', 'MM0seezR2F4', 'loyHHBilYPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19133 ['2RMOegT2Jn8', '3PwR0D7CuwM', 'a4jcJ7QZ-OQ', 'CVLqZyUwqv8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19134 ['uRA5Ue30fsY', 'AYln23c8g6w', 'Ximk6BHj9nE', 'RD-oizm_35M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19135 ['lOIzOWKd47E', '_oNLyxk08oA', 'KChjW89XOF0', 'uqAY4lCUcRY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19136 ['oswsd_r-GI8', 'IbD0zpcimgM', 'fjj9NJX8GB0', 'FDYIdBZUl2Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19137 ['PpamaOkNqoI', 'liuCTk2nPG8', 'dqJSTTS7HTY', '1hWAOReJehw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19138 ['QzO6ylLrTGg', 'argBwTHDDVI', 'X0MN34Us6eE', 'CyFsI_EYFQQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19139 ['Ob9iaGon5ak', 'uZHE9b1WDuM', 'iCHskFoUvbw', 'xtGmrLOsjHk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19140 ['s2GctT6NuyQ', 'pG6yeC3yUY4', 'AD3aI9avJ8Q', 'HzXWXYxXyYA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19141 ['sl37XQfkJCQ', '1KN3GrwhY8c', 'UFyOGqmITjM', 'vNZ3JS1LjDc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19142 ['LQYd-dsz62M', 'PrMKUjFxrvQ', 'IYumekd1VMg', 'ByF0pp-dVEo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19143 ['Le4aGNS8e0c', 'MFxMPOAbUPA', 'mixc4NV5IBE', '9UCLvFqkFxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19144 ['KPG9s_s8siA', '1KmsVHx7E2c', 'OBJM1TqPvu4', '3KdyWJ6wTOw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19145 ['tdTT6rmkk9M', 'nT_R3O0OK6U', '-i9uQMysy_A', 'qAgZ__fk9LY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19146 ['ojwVhlh-P1U', 'TX9PGFdqRak', 'TObYoD2pGb0', 'T0OFKHj6878']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19147 ['cmJj7SxQEp8', '-lPXTBXa0tE', 'iS-iTbHndw8', 'y516mYOT_9c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19148 ['cF7317DK0NQ', 'nUs5SJyQPnM', 'ExghbCGRBx0', 'Mf6Ql55o7Es']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19149 ['92sRFZvCnWo', 'qbIPQGY8RRA', 'OoJGMj5H7Wk', 'hCELSy7hVKE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19150 ['ZFimyfPWltk', 'jWQu301CEp8', 'AAoqx07aTRI', 'IIK0EuHyb6w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.7918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19151 ['JaGUY5ULTok', 'zVA66aZOBH4', 'TcJ7rdYMHiQ', 'PKsdjH0RmsU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19152 ['N4tTZn8WlDM', 'D0L-M4trkpw', 'ViF7A7XODiw', 'BT4env-Tw2o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19153 ['ARXTRdKCupM', 'TWm_2QncYXg', 'MVAXHT67Na4', 'tw0BGErgupk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19154 ['yZRTQX8pcMY', 'qFTMEVccUMg', '7pYavsK9sPg', 'OdLCoLVRCmk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19155 ['V3Vvp5HS90k', 'vpcEBryyej4', 'NBnz0xV9nb4', 'I4Jp0kB2Ns0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19156 ['xUMzNtC2ITA', 'OjvWDzPGeic', 'qjH068GOmQ4', 'zU4mwg-HHoQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19157 ['QfM5-WqvquQ', 'nr9oLIsbDyQ', 'L_nC2BvhRdQ', 'PTCsH-ffeq4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19158 ['AAFsg91kje4', 'wQhycJsKSPE', 'ZYUAY6EN05Q', 'FscE_AHEmFk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19159 ['MV4tgzc9X6s', 'oh5XmtSAOuM', 'YDh36ZdneAU', 'oZF73R89bk0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19160 ['fmHbWq-7-iQ', 'mcAsO331Z9s', 'ZHzhdhKEjMc', 'zixIuxzCCvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19161 ['on18CWdmxn8', 'mZNNWTrvGoA', 'i70a79YhlMk', '0c1YU_VtFRE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19162 ['P2UqnWU8d8o', 'ROA6DMBPlNM', 'U6aLiMIlqCc', 'uARzr9CAemI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19163 ['GjE_iD2BbFg', '17AtKbQ7glU', 'xlxxWFENWr8', 'ROM--1yVra8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19164 ['O1RmrE_HfpE', 'wEHRmd84Dwc', 'W5eOW25vvbw', 'L_KkjB0Wt_Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19165 ['8ynjAtF5VnA', 'QVpsAY9oR_4', 'ER1fTL9-pQw', 'KoP8T0QqzeM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19166 ['vmz9kAEiTSc', 'A-oSBMP-Zy4', 'MpWGx5odhh8', 'GBLKj2d0iC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19167 ['UtCRBs5p4EQ', 'Bd9TjPP31U0', 'HfBh3lZZi8Q', 'DU5pD63Pv30']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19168 ['_h2rFVPCSPE', '2M-CFCo-rkY', 'OVNVaXZ9D0E', 'Orge4_UlvNI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19169 ['fiAcNMpd2vM', '_XrolyeJXDw', 'Cchf2QH63bI', '4hulNRgH6cI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19170 ['EZJzzWEDtQo', 'uGfd3xanwro', 'IYiHhVWrh0w', 'JN_VJCJhC4Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19171 ['aBXntqgPo6Q', 'qKXhSGaudtk', '_KGUrOb1qgU', 'D9TuP8PKD6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19172 ['Ae8o_FMI0Xs', '2JnlmS1zzls', 'vZUup6rK728', 'ZMd8mAKe-k8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19173 ['MiWskwqOMrg', 'W_zgEkvp4xU', 'U0sjbOT6hY4', 'g-ZOluGhMoA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19174 ['7xD_Ib3VS_w', 'ot6SpwD1hzk', 'HkCYA4ax4jI', 'aHZdDmYFZN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19175 ['CVgLrsBPt4o', 'VfEJHqtsuIo', 'PFX2OO75sRQ', 'e_W17jp40G4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19176 ['AY_yCk4eTTI', '7IllUjk5fk0', 'oTXKGrB3bCA', 'K6KbEnGnymk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19177 ['19Pp9QEw17U', 'CAL5CgkKkR4', 'm8poFnEbvW8', 'n1fY-23ffl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19178 ['bQ9vpp_yXvk', 'ZhafwFYgltI', 'Cy3HWnwMLyI', 'AGsMCWB1tTk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.8243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19179 ['XWVGQbfpA0k', 'MP7KPlqoQW0', 'nvrMO6TDu2g', 'ITYv4126yhk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19180 ['WRZGYDh7qRo', 'QUtyeIooCy4', 'PemDZNVE370', 'gz-4W-uEzhc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19181 ['wsdH6cv4YkA', 'zRpPf62Zvto', 'Byk9p21g51g', 'BSLriWJ7hn8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19182 ['0trWdhSvab4', 'Vbcy6KBJsAA', 'O0sDg-yLvlE', 'oZrMoZeJ8Ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19183 ['2VFVe0RCn7g', 'e7WPFeDPFB4', 'wg_kYW4xvz4', 'RGTWqZoswAo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19184 ['6jZ8VNANHwM', 'cbq6Q2htPRM', 'B9IAl-ygE2k', '3Z74i_FWs3o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19185 ['1IMi7yfZVVM', 'myGef3nriL8', 'ojdqgnmcgYM', 'FzG8ZQAhKrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19186 ['GwTXkfuc5v8', 'eW8se7t0s-U', 'MtVLmOvQopM', 'cOsm3r-xKEE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19187 ['6xxu6f0f0e4', 'Ztlcnd14Kn4', '-0xzrMun0Rs', '7nrOZXbpXBo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19188 ['Jsk3ZUGvP-o', 'JDBu-3VCyWc', '3IYd8cCmUkQ', '0vFPs6XsU_Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19189 ['1j4rFfU5XKQ', 'gTO00a-LFYs', 'OmjfHQB_lcs', 'j0UMI2DrnMA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19190 ['92QYLjfo68Q', '8iPpgyEh8WM', '2cxs73i3l1M', 'Lwvf17xUxhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19191 ['szWQPoOH2Rw', 'OHZZuO2vY50', 'cm62raVagEE', 'J0RzvGnQxD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19192 ['wXWpkfGfZD8', 'Zt8x7tvP9Qs', 'Qt8Ze-k2h2o', 'tWexzTJPxQs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19193 ['-Bu7YaslRW0', 'nyjXFx0GSX8', 'oRHKVmQ138Q', '0TV9zvfwFhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19194 ['a2QxlP5DAYQ', 'bmVd2Zj8_Cc', 'WBBKiXYVEdM', 'p_dE26TA8ig']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19195 ['MkTQQ0m8Ys8', 'acEHGV7Gq6U', 'lPFsijo8xYs', 'mu0dlj8ibA4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19196 ['ABSLnckbB8w', 'T0uoYE12cnI', 'JWNWCKdfpzM', 'QZoclbefgak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19197 ['y3Pqe5DLvok', '8pit9UV69S8', '5hyRWertUbI', 'qmR9O2oZCWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19198 ['8OsmFmhNjoA', 'GrbrWNohr6Y', 'HSrzR9hhEe8', 'IT5hcf0KhYE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19199 ['mWL9_WIbykw', 'Q8f6y2IcVg0', 'ZZrvO__SNtA', 'dsf3agfkJDY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19200 ['YOG_PPvTvW0', 'zbCqre50eLM', 'cd5BIQoHyPI', 'Qy77eJc72UQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19201 ['hheF-AgCqIg', '-pUfYFcsgG4', 'qKOsbyT8GCU', 'WrpWb-Zumnc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19202 ['xt6V3Ic72nE', 'Nuks8XFdGMk', 'ESbtW0CUmp4', 'g_bgmnJ1b_g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19203 ['WhNun_U3cRU', 'h0-6U948u7Y', '7_0g3tEcM0w', 'uAgizG1hYw0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19204 ['qFo_gRhW6dQ', 'NWL-P08eM-U', 'cT-KZPVpU9M', 'IpYw4nKPx5o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19205 ['GRdzFvQezUE', 'SW4cW2oU07U', 'fWwV7o4VjEQ', 'jjYXRmE19lQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19206 ['WsaOJT2SsPg', '8yiJOImd6k0', 'DMwvY--3XD0', 'oRUdvu3Qo-E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19207 ['CKEPPcaCjbw', '0rNr_qnoPQ4', 'Aak-VLHtFPM', '8MF6nFj02sM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19208 ['9zW-E0XdWdw', 'w41gqTFYh08', 'tDVOUsG52Jw', 'bxZeGrM_0ac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19209 ['KB4e9v_5uTE', 'pCW5ab3SNcQ', 'FLFmcZiRuzU', 'lZavPVn7O4Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19210 ['-bgHkxwoliw', 'tjQTZM-sqS0', 'ZLXW4ewrVpQ', 'RxmGtt0YzYY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19211 ['FHC7gN3NnX8', 'kAAGkKPVgZ8', 'CRIFRYhiKUA', 'b4FomUpNaJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19212 ['M9mc3HYL_GM', '8tY6nioUQIw', '2MZUbxulAI4', '0Ubu4BqSWmU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19213 ['RF3rog2YjYw', '0_XItMAYkwc', 'lnYOC9tKUBs', 'j8FYy5YfK7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19214 ['XzRxO8n3WRE', '6Yh7Cdm2GgY', 't5P_HJrrD64', 'nkSRzaqpOCQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19215 ['bkQrvXXIRng', 'A2WdjyKQ57A', '4ymXDU-48EE', 'KKgYvcfrxj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19216 ['kmZFn-CQ19A', '9InBmD_Miek', 'Gde1fn1Y1uM', 'h8JS_FEF_fY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19217 ['n1HBKct6rto', 'E_34BmDVnOI', 'OMcoFfaCaGM', 'AVG-Wmdd2yU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19218 ['VMWW9OX1EJM', 'K_ZuxYxxT60', 'chwqnnaiYXw', '4X2aUZFZlzc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19219 ['Z19W44ZI15Q', 'Fy51z2RwH3E', 'YB_PzRgHOeo', 'f_NR19LpA_E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19220 ['xBDcJKb-9vk', 'LjihfG0fit0', 'I4Rhe1XViYg', '-_OzT7Xyvok']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19221 ['9Kut4r8hswE', 'xeHt-R5ScmI', 'JFJuEOZx1K4', '0Olm321vgk8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19222 ['Yd8JBTdUvrw', 'm-S-yqzlOj4', 'E7D42u8a5gc', 'OFJG5Wo_knI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19223 ['4CkJjhuYRmY', 'LyTwxJiSt7A', 'MrMXYO2fzJ4', 'gAQiARaliPA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19224 ['icomsHXY8YA', 'jbyVJdDlo2Q', 'ue1sgGEvkwE', 'uDqVzJtaxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19225 ['VCusyLPrFCo', 'K-zkbbliQcI', 'bl-eQ8XD5CY', '7ITwarmdyfI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19226 ['CLx4iYWSB1c', 'vispMqNJ1j8', '-tpq_bzSKes', '7KCikXm6hic']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19227 ['SU9ZP2pbqyU', '_IkLUOsNHAA', 'Z-G7nL9tiws', 'LCMQXFKMLIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19228 ['7kEeYQx2VLE', 'WI2d5vDJeLo', 'v2Ng8iGwf40', 'mBRr_TqLDf4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19229 ['qV_VxEAXXDU', 'EsHXnkZ_W2c', 'bcybO-SMY5E', '30tNWUyJCog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19230 ['Bx726MYz6Uo', 'T0oF8MyYhBM', 'VwkRHbqpHqk', 'SrLhnoBMyWM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19231 ['y8gB3-yw3tE', 'nVSDv46ARvY', '10dur7jhFQM', 'bf8JlTKzOs8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19232 ['IyJ3a5uuCOs', 'Ovk5EfFj7Ws', '8y36aT4C_c0', '-OUIEnuNd1I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19233 ['JSdALuTneBM', '3VTinB14Pmw', 'hgitRq_0410', 'TSl5LrM6LcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19234 ['fxdWwzdeY_o', 'jx27p7k2lSw', 'GX-QhoihLeI', 'nu_Bl8Pz6PE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19235 ['cWvkOY6OKss', 'zayC5mUo7sY', 'HfzEa06vDLg', '1Ccis4FDGwY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19236 ['LRz6Y6oltQ4', 'XUD-9HkQuTE', '_b-7P-XsnUI', 'iX53Jb72Nwk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19237 ['r5xTmK2Fq1w', 'RIe1omxr7nc', 'XOLVI1bgxqk', '-_6RxZyi30Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19238 ['752bW5cjXzw', 'eSsadT6mh7g', 'dkGXJ6BlCd4', 'PAX2PMha2dU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19239 ['dAAwzwexvUQ', 'UjDh1OlOwuE', 'm--xEFqqrLc', 'euAQCWBX6ns']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19240 ['vDrbslhtX8o', 'bqPCtwibgPg', 'AJj6GGLaIfI', 'f8nysknTFUo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19241 ['nL4zx0-mi14', 'SKQbQXPjmvE', 'TgCv5a22YUU', '4S4NDnNTptY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19242 ['rsvHQCTgHvg', 'KlVO3gu-j70', 'aryufzYGhbM', '25RWrqQol7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19243 ['SGcjdZ19R1k', 'IwqD859w2_E', 'sHbGsZUsisE', 'UcS5U1mpbAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19244 ['zNgRUFOj3HI', 'Qe71m678qEU', 'D7z2Q-hH25s', '_n9boKzVRhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19245 ['fvpDYGzdRmo', 'J4DrdTy52kg', 'M7fsgHyiicM', 'DpAfyjjQJyk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19246 ['oNggxSyyyq8', 'L47F51OmZXo', 'ggBivmG6yHQ', 'oMgSuyPBINs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19247 ['4M_k01zIbVM', 'TLMEsc_42Gw', 'Y0_Ixl1d7oQ', 'uE3BHXXiCFs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19248 ['HtRjRuKnvjI', '-cLzki-B06o', 'WAxDN-FyPn8', 'P9fh7rOIKcM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19249 ['3obJKn19jTE', 'CfRzy-RtqnQ', 'w4Z1QuBOMWU', 'oTzTZqDOIt0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19250 ['3_M9ZMo5TiU', 'hlquKjPgxmY', 'WO_Y7djT2k4', 'Ypuv3htJlpg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19251 ['MKikHxKeodA', 'XnHAH2aPHk0', 'Pzp_oTEn0Yk', '3R8xDvhJk54']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19252 ['PIIAyM4H1UE', 'cLIump75aC0', 'xKrdOZAp2w0', 'mwLrABPxvgA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19253 ['h9zF09TMgLU', 'hIEj8msjg8E', 'r4nPBNL3D0E', 'gWRfk8nCcPs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19254 ['VdYakZ4Yciw', '0x6chChxzV0', '81SgTHg66QY', 'sU08gu2zJ4c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19255 ['3NAqH9LYDyU', 'GBMlv6j0WJ8', 'fX8A5Uxc8R0', '-UuEBhule84']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19256 ['oag3I4VRXyM', '9ohu45KlgYA', 'PkkhCW04O9k', 'b0dVykd2i6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19257 ['14hTDUjCr_g', '63jbksEqycQ', 'IKq2OF8jq1c', 'zmbwvsdXlBU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19258 ['iaonijK95qA', 'ao-TFiShaWU', 'YrGQKTbiG1g', 'hgGCfJoYDUU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19259 ['J48F0e0guSQ', 'CXCbBSUuugs', 'Ck_bvV8Aa-k', 'NxdQtpceXaI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19260 ['TPdqEmS1Dr0', 'nsxaoH9DjDo', 'B1va1NqaA4o', 'XykUpCigu4w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19261 ['CYuYfvQv4eo', 'VCIN1OJkNbg', 'TokHdpvX7Es', 'gp7j9o2x9co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19262 ['zPMiMXCazAI', 'BlsbeyimUDE', '1DNoynuGLV4', 'Hp-lgcs4VXY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19263 ['nbb8vmfjHJs', 'tc7crRl2JqA', 'guRyU4B5LlA', 'Zbmm_hXcrA0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19264 ['xuxKtxzq2Cs', 'tlDBOenCGV4', 'afb7pI_01O4', '_2wFjBoreaY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19265 ['_vwBe9ZXWXE', 'UfZP677y3Dc', 'n16ZUTfZtDM', 'd1nz5tZckSA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19266 ['Ou7vteWmqfw', 'bZXQlQnleL4', '40D4L5Ndi6k', '5MOJnA715fA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19267 ['y9hdu9iMBG8', 'aCA4yiPfFIg', '09lQmg2wvsY', 'B5XTBvnpwqU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19268 ['n_REM0fSVrA', 'tPVsTFGWU5Q', '7-mNJ4IUY5Q', 'l6LUPlmua6I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19269 ['wraN7rWUsfI', '4Vg0PQuHTk0', 'AF7sah5a_DE', 'tju-t_Bz_W8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19270 ['OseeYF_ud7g', '5mmUQUwr6tI', 'qlk02ytcnPU', 'Ex0ukzO5z9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19271 ['-6pcgdLfb_A', 'FGoDfNZezh0', 'ZLxhZcS3Ppw', '0nNmbkU8GBI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19272 ['ABr4Q_ecoPw', 'CKkbZCb9Y18', '5F8zpfwFKl0', '9ZUzftiN2uw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19273 ['nBiHncFD0dM', '5nJr7iar6ZM', 'D-PxXM2I5gY', 'KzzKguqINa8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19274 ['bLjOJRg2P_Q', 'Hl8OrRlMwi4', 'KCs_VPmsnKo', '_pU2KbHMN4Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19275 ['O8EMm4QJjeo', 'GAoGADilmV8', 'W3lKc2hj4XU', '_nrz_BawPMY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19276 ['sRxUm-ziCBo', '6HQqly6duac', 'tuoBmxts5Xo', 'g-9SK0or81c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19277 ['X28GWrn9LlI', '_RrA-0lfIiU', 'JFGNmPzPXeA', 'WmTDKYYH5OU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19278 ['yl6LJDi0gi0', 'X7qFgrAl3OU', 'Vx_vqfpRdUU', '9mqA4YdX444']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19279 ['MeA8CSKAuvw', 'WWIT13tTW7c', '95ThRxhl-ug', '11D0JdB7_4k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19280 ['iePMcLYozYY', 'CnTMm-bzssM', 'Hc_UM8l_sTg', 'c9tRbWSk7c4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19281 ['UVMBRVJTvzg', 'gDm4IphrlYg', 'eiyyoUt64Zc', '-zA6LL78KYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19282 ['WoWF7gGzGVY', '7_Sr2zv1sQc', 'kMNL4Y4XMhc', 'pz8P96myUZk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19283 ['HWe3TSUcvHc', 'cdUk-F-5NCI', '50fuQm8B2Yg', 'BC7dI3lQ2Cg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19284 ['vyNstX5b1V8', 'sDX_95H0f9Q', 'DhnNZn8JjEQ', 'DUNOn71oGCw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19285 ['nSLxQLYYoNE', '1FU5odlgLmo', 'AuZNuyR2OJs', 'dSJpZQ8u_xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19286 ['i6k1yiyO5jQ', 'KCytKo5LzCc', '_Slo8QXYOp8', 'zu_1zpF--Zg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19287 ['r7Ve8ExE8YY', 'S29WiN-bTWo', 'Uvn7waPvseo', 'GuQFhmGqdog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19288 ['gxzU5EqNL14', '_WYwB1qRgLM', 'lRC2lurjPBw', 'Nep_3Y81E_w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19289 ['mMT1kEejAG8', 'iSw-5EjXgXc', 'hFqZZrj0rnM', 'w62KGC7um_Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19290 ['9Qd6AdTq3Ls', 'Ts3ZcUaELzA', 'Ofry7lyQZDA', 'Guu30szkA-0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19291 ['1nUqhH8bAPk', 'sgVqMKtUMsA', 'e5SK6olIYcY', 'CrbZHPkHeV4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19292 ['HuVgc2jf0Ec', 'VZfrDZhI7BU', 'KY5TY6ovKQg', 'CwImmV7q1MY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19293 ['l1coM570kVw', 'itT0_RhSipQ', 'xCLzxuZE3yg', '2zjtZYqg3Ow']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19294 ['q9Gh-zh-5Ig', 'wKoFJHb2BoI', 'ZleHXDirD58', 'KE-TVQhdCbs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19295 ['dalyCstquy8', 'GWxiiDBK5s8', 'rNKJXwMz9XQ', 'NwfEO8cjSK0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19296 ['UJAk1nNdo1I', 'YwUa3OS92ZQ', 'WiAFUo2nxIk', 'SGF4N3JHF7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19297 ['b8cgQBzBXi8', 'lFv1MJSSWNs', '6k6tF0s0lNs', 'AaVUuKl8294']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19298 ['pnh_C1w4yGc', 'tEZU-ZRhSoY', 'RDCXvJPzT5k', 'HhQTvaZtURY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19299 ['15Mw2jyyHk0', 'XjUmXwVlDDo', '8BJljuSm2Aw', 'D3f5VIJYR7M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19300 ['d9Oa-2_r2j0', 'LybSS4amIS0', 'S_Z7o4OmU30', 'evscfdO-oSY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19301 ['AkHaDKuiE_s', 'fAHYe-qmFnU', 'TArWNq2retM', 'tJHFSRTPyew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19302 ['uoZ9Rs4E-6Y', 'IUD_ZYOh2MM', 'V5HMIxuAtv8', 'hk-1KRWTM-4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19303 ['qEJ_jxZzt7k', 'Vwekk3EOa-U', 'wR7n4Gg-_ac', 'VNjYW4OXqTs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19304 ['0K-zyeLuKho', 'Yt1czlnCUCg', 'DysXetu2I0E', 'aKhM6zyL--k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19305 ['oJyyNWuyig4', 'WCifI6rwOoM', 'HJuR9WJ1iRY', 'r2gYE6-cGx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19306 ['gVMoI2ukbtc', 'm1ov6te6jK8', 'S2u5IE0n1ws', 'vG0FGgJlDGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19307 ['JCsuOzlwJqA', 'AkbCw7oVkw0', 'lAMiOhScSPg', '-v5hgCh3M2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19308 ['5bn7PPKcqSA', 'QJzveo6IBsU', '0wYi8B9PXDY', 'qIxpfaeZ-zs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19309 ['OgqDO1wxQ8E', 'CM7jMnBXw2Y', 'He63KV_9Pwg', 'qI-Ji4gtBPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19310 ['KnZeEWVHaLc', 'WjPHxUtF9go', 'P2F4iNqJmNU', 'dSs4xfvATjc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19311 ['SvsCM0fLM5g', 'gNjeps3EbJA', 'xiN6XwZNEJo', '8zCZzzAaC4I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19312 ['bTLgeqCaYMY', '1heMbyumHAo', 'EkMgPJfSL04', 'E4To9BC2jx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19313 ['2ZgEbNi--8Q', '_9OUh0uwDec', '2T1P9ovsl4A', 'R4b_-IT43P4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19314 ['HtXtfCR-MUg', 'PdgswSjYhMw', 'BYnYTgeM6Go', 'O6QyYC7Tt2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19315 ['BXv69uAoHk4', '4HfU5OQUqq0', 'WT_wvvEvkw4', 'odzi_VK8m3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19316 ['RPqz3vJYMLQ', 'dMfKImuNJjA', 'Emc18GpAeRY', 'CudxWnS7ukw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19317 ['5DNl3DX4rr0', 'ItSLkF6O3Mk', 'UvCY9FHpKC8', 'dHDosntsNho']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19318 ['55qucu8Zs_I', 'Jcd63Ev7JXA', 'HYjSrwSm0T4', 'kUQ1xfK82Q0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19319 ['0F-Z0zF1504', 'kgf4GdKlSWs', 'FMjUGdTn7lU', 'yIOUPSGFqoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19320 ['BkSCfcTBMRY', 'u_TfWvyYY0Y', 'UPPHkyd7lwE', 'LWIHz5kao3g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19321 ['qlklggFvAZs', 'JzJCn-puzS4', 'ClK_qf_Twm8', '59Mt7J_0KT4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19322 ['ib8pMT_ug7o', 'KzvdKLdBw3s', '1_YHHL_t2GI', 'fEfe8jznp5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19323 ['WyGJdstaxK4', '7chwYGGSkmE', 'vqRFzhWik2c', '6Kb0q9J8lPA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19324 ['OTu_vWZV4QA', 'MSHbLrVlrQc', 'yi4-kGV30qs', 'qrY7PW5guxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19325 ['t9aSL2MwEDM', 'zOvFaef41iw', 'lHlOSsnP48c', 'S7igso5_MBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19326 ['LFW4yPH1z3M', 'c3T1gWSVp6c', 'xuepy6SFOf8', 'qyCea2TuUV4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19327 ['BZyf8LPltYs', 'eJFZuX0WHgk', 'WKL40jfQD3g', 'Ss1bubMNPQE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19328 ['liagR7x12O4', 'i_G_0vgEYJg', 'DU3Vlaa8rU0', 'MdYXznF3Eac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19329 ['cnmedj0fYTQ', '-jpbCWcz2pk', 'ULXbXpLcoVA', 'OiNlYrlJE4g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19330 ['N6YT8_jlt0E', 'fPIG7nrpgec', 'QIjShFhrp6w', 'rnOIXOGfSUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19331 ['YZx0_GRtvJk', 'CEJXvm2vH_4', 'rG_6MS6_K6g', 'A_NkQM85g6Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19332 ['XjGm3Bn4j5k', 'BojCkFK3pNg', 'Jdy08IPLKdw', 'aPafZ1Mx-BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19333 ['e8xkukid_2o', '2xQuWif8axE', 'jXi1dFAB0n8', 'fQiSoVDFRjo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19334 ['dwAo0dKCyBI', '2o1p83UjJFA', 'CRxIJ7YbcZA', '8nJ2MhvhnJ0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19335 ['4ufDENm_ECk', 'mOn13E68Td0', 'brEMnFXsTqo', 'uQE3fLdzpKs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19336 ['SyJT8XsFsmE', 'W0aT3SdtnfY', 'gIFg6jvXgb4', '1GCOnj53QYM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19337 ['yVWk3yq3Abc', 'kH-F9JzC7eE', 'en0haa37gnk', '1ILLsA6gqHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19338 ['AgVUGzrzJ20', 'Pn8HqUbNQAc', 'VpIhbDN58mA', 'QBMM1ocXkhY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19339 ['WvaIypMvAHY', '8CY7G2NrlxY', 'KjJj5-HvSvQ', 'jR_wBfxgZwE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19340 ['yTq3Kr3jkvs', 'MZhaDGgULtc', 'ksImihlU3qM', '9mIDP_OT1uM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19341 ['Yk2ZrS0ZS6g', 'pL71P2hVjMc', 'lDnYXLGEEFQ', 'kw2wPVxUgQY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19342 ['5LX2Unga1p4', 'NJGo2fmUAII', 'AgCSBCsHkMk', 'LHTA8VZGoMs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19343 ['Arqvnp6yUCg', 'Fg8yzA7zifw', '4mC6K77Y_Ho', 'Pln4GLIMqKY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19344 ['UsHtZ7Bzi0s', 'Pv8ZWvM8bhw', 'pHFHsubQVpg', 'Gw0KmZ3kbjs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19345 ['BxQSEvHdyjQ', '9Rx57dlJtIA', 'RIiN9Ed1fqU', 'bJ6e9Ja1ahQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19346 ['zyXa2tdBTGc', 'ztfegVzqeCI', 'VpikuLP_9qQ', '-sRFfU8k0Zs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19347 ['zaEdWwSamS0', '6yB6plsrjO0', 'Z31gI08SMzI', 'IOzWDVGWRng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19348 ['LPA8RDzl-Ss', 'asT8yaJPP1s', 'bg_QoesbfOA', '69oU6LfyQ_4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19349 ['nb_7c2xPKYA', 'mx7kjFY7ALs', '5FbQu7QTme0', '79tuMIiWMZ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19350 ['E3F9bzeCgTQ', 'w-qG-P9E1U4', '_yzcCFe-uo0', 'yKx_RFUTPfI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19351 ['XkBXsaSXDJ0', 'GopccU3Am1w', 'zwfo7wnXdjs', 'ciJOulWFhfA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19352 ['POOu05eUvqE', 'b-Y-AjW6MJ0', 'ZNGJN30LCwM', 'khQN5ylb3H0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19353 ['bciw4Tqp6h4', '1uHF1-8TcEk', '0LE6Ll1rVlg', 'cabjr3xtcR4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19354 ['VCozi4GDpxQ', 'qOTk01gmrRo', 'sZQ4TeLueSs', 'bBy0NCoCEHc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19355 ['T78nMdsJMmk', 'iMmYVLSb1IY', '2ZogsGp-T4o', 'GMtb7U-8IYM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19356 ['91AmOKytRUM', 'CrjSYvGWusQ', 'RXk0lQJ7ttc', 'mhqHHQ1gSvM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19357 ['3KQy3Cajo4E', '3pU34vUoO9g', 'Dv21JlCT4_k', '31O2j4aAgYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19358 ['qwGT6wvYdLo', 'diSfkEkTVkE', '940MNbCeobw', 'vfMEPOl1Wqw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19359 ['3JYQgXudiH8', 'EmSZKb0LdVM', 'NeSIT6sqLRA', 'Hob0LAu8afQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19360 ['fow1TC_MpHs', 'Sa3Ky5sJshU', 'SkZ7mGbs3SI', 'ItstzW7xuDU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19361 ['yhS-6Y8ToR8', 'OAl2EjbdQG8', 'm-xxD1fGPnU', 'AuvFmMpgj70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19362 ['WNmAlKrAPjQ', 'j9UZv0GOJ_I', 'ow7xqVk8Wjs', 'afavVsmFWds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19363 ['W00eTCOgUNs', 'CRHEuoCnI74', '42QgE4mM55I', 'Q75y0TIp7Ds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19364 ['WZd2nT2Afds', '_94ra2KoZGo', '71KE7B1vvdI', 'TWnrcjA6VTk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19365 ['eYngZ5It0b8', 'NP5iO_HB-f0', 'WoXgPQQjcJU', 'erHadqauC8A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19366 ['An-4jPvUT14', 'tV3rvUSlVnY', 'AAWe4zRLVVU', 'ZSItez9gTyY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19367 ['AHrUfa2H_5s', 'r-PBeJiE5sc', 'EQHrQIaQNv8', 'G_iJif-fC6E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19368 ['BMPmavj4keA', 'DZ3EShJzOOc', 'wL4HaT8rEVU', 'GcOOmVSM8Uw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19369 ['PqN7aT4dVN4', 'm4bBsvuS4EU', 'GW6pti04qIo', 'PBqNpMpD76k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19370 ['Q1LJotkUbUY', '7NnvEryyYdo', 'BjqhHeJD28U', '6ragcEJVErI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19371 ['yx7BZ_djE-U', '4dilYyxYLmM', '6PWiDlWmPs0', '7FkuqqdWRhw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19372 ['Or4CALipjig', 'HDSV7Pzq8CA', '3w3fD54bNvU', 'ac_8oRMgDz0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19373 ['476vNb6thyM', 'Ld5G00HlbQs', '577NM64YL18', 'D4GVgBX1eYc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19374 ['D3ht_xXl5S0', 'EO_tdzbN75Q', 'vQcB6NI7cMo', '1PSzSTilu_s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19375 ['rQcecqZtGvE', 'q6GBCmLxNIk', 'SwaqANBpZGY', 'XgOA5oRkL2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19376 ['iQAXwX28LLw', '1tz4xNRRR4M', '5at69yM1PoU', '-cQ-jUTEgck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19377 ['ZOGMpGQQ3FI', 'ZFG9jHrLtBE', '0kQjfwXjFuY', 'VtHkxrta5xQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19378 ['AVPm96vrUQw', '1cwGW0cBdRs', 'EQVZLtlDkHw', 'j43Dwqzd8w8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19379 ['UhwJrftWAFg', 'LP1yZRsRllQ', 'BurGML_ZqSA', 'BHDhHO7J-Oo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19380 ['EKt_KEbqQfQ', '9ZinCW4jTeE', 'muwIU0BHXE0', 'C3o8pEsAu5U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19381 ['0OhtODbKajw', 'aq3vov8-fw8', 'Kqo7am5oq0U', 'D2w3qHmJrdU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19382 ['as7MhTe961k', 'KEp2NhraIZI', 'HXG8DnTpyPc', '7NF2kcEfMBI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19383 ['AJTU5RhF3S4', 'WW4_c2J79QA', 'vrMmkVV4SOE', 'ndjLkbP6Y9Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19384 ['iqOPJWWKo90', '_mQ6KuA2p6k', '8oUI02eK3SM', 'UDN11Q90Fa4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19385 ['7Ht_Vu1D8nc', 'VzFpg271sm8', 'i8PFu7AiwaE', 'SLcIv8CNk20']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19386 ['chfTjqlrFQQ', 'sQMzHk9MRAI', 'Uu8m1oOWkiE', '7uKkUTml-DA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19387 ['WKYUiLace9Y', 'Hrgl_1rGGU4', 'QutCXtWmzIs', '3HtfWSbmuAc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19388 ['3rbWoeUg9yo', 'M9MgZXkYRBs', 'gpEU6RafUf0', 'oSoP9Is0UH4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19389 ['HCCGZh-TxK0', '75_dMqpSM4o', '6o6DsSnbpxE', 'XhV4zf-Xlmk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19390 ['yfXvz2FyZ_U', '-i9gpG3vPwA', 'ymGg5TA2YfM', '-SD43H5B5hE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19391 ['YbLR6dgY-K4', 'hKSg3zFB2dE', 'JHvLuYk6TfI', 'Ime3FHuQG4k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19392 ['PduP4CpaDtY', '3rvqiSZB4pA', 'qwz7oLASJqg', 'rKRI5UcIICI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19393 ['P3ZPbGjHFXE', 'g0AXzsecS5M', 'nEOPm7TeydY', 'A2pgKzeDRqg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19394 ['SOzuJU25uGc', 'nvRd4xgEWbw', 'hbqdthlv6CU', '68XchGI6H-4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19395 ['2f1UXGix_Cw', 'vp6p45b-038', 'r4JRDHYukZ4', 'TIASpLtI8ks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19396 ['5ieMy-PAKA0', 'KlD1u-EDx_g', 'yn4-OtUmyWo', '3B-YYTbpFZE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19397 ['_1woPC5HWSg', 'S7TYAcOEPt4', 'flLjMZMydXc', 'uKGo4phKqLM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19398 ['QBhhtVMiQBQ', 'NlCfScKw_Mk', 'y6iMm7Pltq0', 's1JHUf3Q_F0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19399 ['C-1i2GlbiIY', 'Bl-lCgr5hGY', 'JCfZpSEH77Y', 'hBQFoDI3NMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19400 ['9IdAIIywBfY', 'ByOqw8M2U-Q', 'D644BWAUOXo', 'gigxzYegRqM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19401 ['5DDg2CzAmgE', '5-aS_pyXesM', 'DEnayQZiPGc', 'Wil8e6kBxe8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19402 ['PbUyPbafFh0', 'sUjAb0SfppQ', 'CwHSb1NOi4c', 'AUPmWhim37Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19403 ['614LdgrE13A', 'XzwhTltRQcM', 'd61plJ66vE8', 'D7Cvisf3jf8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19404 ['vKNGqQ3GRB8', '-f6s6kQEHFY', 'qMbGFWz9who', 'hTAWbHXCJ2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19405 ['uNUx8rqcy0M', '2umjh27MkjU', 'KV4noVyGHa4', 'bl8PgmZ9iOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19406 ['KabP9iNokps', 'MyH8zQw9csc', 'm9tnNkon_iw', 'YFXSbPFaxcA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19407 ['u3pYqyLM0f4', 'xLQF7S41XLE', 'ZkfKOLp5SxU', 'H_He9_zHk8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19408 ['-zOybsEdM5E', '7_q36NyJtQY', 'QHmGUrpOgAU', 'nT1YAP4Vy9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19409 ['s1l4Zjqoqdg', 'dh9XweTn6rI', 'xzU6sJot-Gk', '52GYcHTcCgs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19410 ['lI8aGjIb8Jg', 'ew-7SwLcHBg', '1MwaXCfUvX8', 'P996TZp25PM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19411 ['GF8QWSW0UbY', '4W3Ql8JbEN8', 'r_TgaHCsYB0', '1WlvXneu6oY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19412 ['UkTWmyy7ia8', 'DdxW_JziHTA', '3XL825fK6UM', 'Ehks1uuwR3s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19413 ['vsDriIwNAmU', 'swIXVQtP_TI', '3w4nFQrUQ8k', 'ZfR3_QJF8f4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19414 ['VlgOLOoctm0', 'Ir82jewhXCo', 'YnE5ONaXtLY', 'DLDZrtwyY_Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19415 ['5n8I-br2n1U', 'cn-SilfYLZo', 'W7i4LkdSfjw', 'sL01xTmV_Fc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19416 ['cY3g6N5Sokk', 'feC0L9MtghM', '-Umconw-CRE', 'A6HJBIU1rD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19417 ['YE2rN3xknlk', 'B_kAtTBUDIA', 'EkmHGd0U8yE', 'BVt8RgNrwbQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19418 ['A5fPSkTvjmY', 'PlQibWaPAcM', 'ymuRKv9iJm4', 'LAHWV6fZwUk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19419 ['X-uVubaJ3II', '244y56-vLWE', 'nU7x170OvJ4', 'paeNnR33i5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19420 ['cG1dpyC8gV4', 'n3X8RGZsGg4', 'sDoV3sMgDhE', 'lSb7Y-_3to8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19421 ['iqEQBCrOLWc', 'XYOnq7ju7o0', '8jDanS4ZzRc', '-0vPFx-wRRI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19422 ['-1UWSisR2zo', 'EGIeykrN4eg', '8Ha5qGnT7lg', 'sYIymaJi6tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19423 ['Tt3BnoJw8ds', '9K8EePrEDdo', 'iUxy2s5d60o', '-VI2IRq17rs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19424 ['7JE2eBK1f9M', 'hRbukCd6N68', 'WmyhSRhWh3k', 'OEjgIDubFbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19425 ['Ca3b8qNUbsk', 'TnJE6W6Z6mM', 'N_LKZjw9DLk', 'U4UtZeTl2DE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19426 ['nqcVA89BD6I', 'SEHE3WGui30', 'xrqDoBor2dk', 'c9JyKnsegog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19427 ['rLQ93N6RJC0', 'BBmXMoI9Qus', 'pte5jvRKwsA', 'uTfLf1Y8hhM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19428 ['1ACn3u5UnBw', 'T9dKp1EN4p8', 'VDYqYuPzW8E', 'ohikUtjUN7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19429 ['OoyxPPoPmt0', 'K9zE9x2ccJk', 'NwA9JSlK_lM', 'n179cK8EubU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19430 ['GUwBLItoJXk', 'cJ80eZY03Yg', 'WditOomsdRU', '9Y8NR6nDxjk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19431 ['vmVOWilkmOA', 'BquHBzP5Ep0', '4TDtUHo5cSE', 'KUE_I30--AY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19432 ['KdNhYvN4Xoo', 'JOhK7oq9KtU', '7_80oVTLkGU', 'iYWvaxU5OXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19433 ['C7WAx3n57Hk', 'jBmP7xTI_TA', '4Gow6qZcNZI', 'iUHqyjf3NcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19434 ['9YnYlDFKn-U', 'zYM0gtd_PRo', '-4NLarMj4xU', '1SO5RJLWKAs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19435 ['qaQjG9SwORU', '7AC9RqECN5k', 'gTX4SG70cEY', '-hSMzrWZCAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19436 ['2vQTq4QLP8U', 'yfZ0z1C3blk', 'sfmAeijj5cM', '28wBrNjHXOM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19437 ['zWJC_qr2610', 'DTkKGYCRMlc', 'OzaVvthCvtk', 'YAYp2E5vMNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19438 ['UQKLBsZJsww', 'UxT3KG4AHAI', 'echeYDYFhlY', '4QES-SJ7mP0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19439 ['ZM0imDMXuw8', 'SEDfsU63w8I', 'tUZB_Xf1m6k', 'YcWJUHWt-64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19440 ['GWcMqKYOJR4', 'xzgnLpKkvdg', 'qW4kBJsudLI', 'L5UDz2PJ9sk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19441 ['_78P-0zWJtg', 'BEZdszHKGTQ', 'n_boIyhZqWc', 'HwGK5RvNOFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19442 ['RDNatVYvpeA', 'YNoR-SR5t1s', 'w9EGDo9Yybc', '6lPgzqrvHHw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19443 ['L0oun9F67tg', 'e2tZmQI8ICw', 'hBT0bbJl1dU', 'TA-O_bVnvLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19444 ['WMtztIW1f6k', 'QUB_vpjogmo', 'AzWIKyRnhG8', 'GG6XkHATIyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.8097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19445 ['Ns-iXXKmzzU', 'l5QPXVIxxwk', 'Wu-Oh9OJIlI', 'MfX7Q0ucts8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19446 ['l0fCHZhKEDA', 'aO0QzRPiEC4', '3sIlpn9nvKU', '6YXjJ6ABnZU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19447 ['zdtVT2xwrHU', '3EXXs3x4Ius', 'DC0C-KO9EJk', 'Lc6OfmzV7Pk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19448 ['54yI3In3DrU', 'LSaLPObrnZw', 'RdKQGIzKZ_c', 'L9GXrmmlYhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19449 ['CxTFgimfNfA', 'grisjVTZeTk', '1JqNiV03kog', 'BL181hSAG60']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19450 ['9gkppwB5CXA', 'RFKTlhbnfXA', 'SUclDZHax0w', 'B_ohqOgK6T8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19451 ['xUVvBF9BWdg', '6-CMq6xw0fg', 'hlHb9HwNxk8', '-qcTD2o6I9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19452 ['j-TVVmVmygg', 'D3FyfFIKLVc', 'KLFoZA8btu4', 'TCRxCAYyduo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19453 ['-YATTKBtmRA', 'XdBf_omYIO4', 'kdxW11WBlQE', 'HQb2jhmw1BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19454 ['_u2cNlW5DxQ', 'hTlIqICkbW8', '3OLeJZF4oI0', 'TPYNIc_M1ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19455 ['2z1elo4ucis', 'KoAGZ_dB8MM', 'ikEuQPSBY-0', 'Pgpd1yxLcLI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19456 ['HY1KdNS19CM', 'j0FynYzQvcM', 'oGbNzR_lpSk', 'MHkfPjW0aRg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19457 ['YW4AKwkpYxs', 'yO7MWuJ7zLA', 'hrCf8rMBtA8', 'c6Fiz5IznkU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19458 ['lNg2y6SRZPo', 'WCiS9IDILQg', 'G7pD1K3jYg4', 'ATDi-irUEWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19459 ['h-3DrDQC62k', 'R5KBk76b9HE', 'YxkYVsE0UdQ', 'AVVfOYSmexM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19460 ['67S7s_jFXhc', 'lYtoy8sa-Q0', 'GwxSvUoYSZg', 'cOgNXgF21u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19461 ['19-GI2LzOtc', 'Qz2PIXM60iE', 'B-1QW7g81gA', 'Gow0TlxIx7U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19462 ['4gEmWJCPZGo', 'sgJT5lIFttM', 'CM2rKZmcR0I', 'bTlp5Qr99RY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19463 ['2zrPFxxT1VM', 'Xm2ciX0_UP8', '2IpapScfsT4', 'Y8ULUSXWTcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19464 ['ksYM8YzzWXo', 's3Q8pVDY7ZI', 'fU9woCZqemw', 'KDzy3ZL626U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19465 ['F2ekiX14ID4', 'M-RX7LqL50A', '2qO-OQtOBK0', '6cQjwXNY4sc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19466 ['9kt7rsziUVQ', 'XUzaEsoOlWQ', 't8uF3PZ3KGQ', 'EZAwPnGOJPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19467 ['nBSMh7pgn2o', 'aWK9CcvOK9w', 'gkMbHlNAFig', 'bqeVxA97TQU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19468 ['15CZ2h5VL-A', 'BdhaR2QUGqY', 'A2NtJ12KIuU', 'lV0-LMVpZLg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19469 ['ql7aH8wF6JM', '2y1QnNBaxAU', 'LK6zk03lPlM', 'mQ1E8rx2dnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19470 ['qtnE1hnCD0M', 'eISYX9koocM', 'CD3OyaDW348', 'B00nfVc4FPI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19471 ['AmAThmRphk0', 'tmabzx6yxqs', 'qeoYWM1uYPI', 'R5JRh08zgMo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19472 ['_KYo_89lgf0', 'nnc6m1pBJ4c', 'Fa1KdG8niq0', 'smU92Nu0FmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19473 ['eUZ-v8GEcNk', 'UR3k09hOxI4', 'C6m_OWe-JE4', 'hwSOjoHFLn4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19474 ['evG8CQRCdV8', 'FFQVVwFjy7s', '0oIFGARD9xE', 'CZuH43NPynA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19475 ['frqnZb8Ssjo', 'gCSShNsw-_A', 'BsLFQV8HVZE', 'hvmCuosF0Xo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19476 ['qcjzfHmQvxg', '0a6uLBmqZgA', 'fAfk9yrGhWw', '5pIdH6p3kuo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19477 ['WTVC7ZI9WtY', 'O28kY0aN8VI', 'Q2Omtt4A8ls', 'VHyXvbg6y9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19478 ['Inuq5W98ktA', 'XjoRxeEyjz4', 'mRKud6yP4iU', '8pYHLfKqHL4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19479 ['91Qp8XUskXo', '6nWWTNVRDjw', '23xC7lTBikU', 'GuHDy--gWiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19480 ['fXhN3_gGpQw', '3e6GleQ9sl0', 'S8WTaKLpmmg', '7RtQpW2dSU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19481 ['4Mm5mBgktG0', 'A_oaLt-n4fQ', 't7oAteGa55g', '6jdeSAmkzEU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19482 ['kMK10SknFAI', '3bg0iy-ypcw', 'R6k2BkwZt1Y', 'UO9HtZMrbBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19483 ['yBYd03Hr2kQ', 'YddV91xnUz4', 'O2HttJtcec4', 'R6lRMU-zBLA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19484 ['VSf3_XpiPkQ', 'FXVu-YwjhxM', 'nY4tpb8O_Rg', 'VlXi2TxMXbc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19485 ['AzhfZ8rNhRk', 'pKFXFu8st9I', 'HyJ2YaNrA3U', 'Brc_nOquNbY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19486 ['65KYS3lIRII', 'UhcoWyEQwBI', 'd-KxsdWX9xE', 't3758pixHZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19487 ['1xhwyUVSRQk', 'svNayU6q3Dg', 'HFVM5pVTwkM', '9ZeoYezrI7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19488 ['5xAzHL8Zlcs', '3sRO6iwfUxo', 'ihJT65fZaHY', '0a91szM1Ivw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19489 ['XWhmLbnrtd0', 'fhWzjWZqzvs', '2juYRZnhF3g', 'ZVMIk3xYaYo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19490 ['NSyqj1DXZKg', 'UinQGYfmZhE', 'pcOPueObfWs', 'f7OQTtTdgrA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19491 ['3TQmts_MxyQ', 'RS43EP1EXz4', 'lfCWGQ6URds', '-wymN80CiYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19492 ['4jzr88nEdCM', 'u3n2OcpEC48', 'UEOUXjX5R2I', 'mqyeBqaUeN8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19493 ['entThp930cw', 'BsVsoZ4ojp0', 'QqRrZzOY2xw', 'UxrAsZ7Z09Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19494 ['0hfU27A6tus', '1RhYdQnZ_hw', 'DYp8940tHso', 'zTuxNA1y6Os']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19495 ['UOC4VWQpnDM', '4M0njWKFsME', 'tMMjurLqYJQ', 'vnwKpQeza3A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19496 ['IiBgER0W8iA', 'dzW5M4sCphI', 'p2fXNAPYD20', 'Ux3YosKD-9I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19497 ['Vx4aO4-nr0c', 'gEYTdeQiFv8', 'I368EWBLIs4', '9aE33JEIGOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19498 ['VuWr1HXHoZg', 'mMf4vJFT8Fw', 'thHSYzhoLo4', 'woyCm7d2UIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19499 ['CdFutCUKTXI', 'fUC45bzOOJw', 'O5IulN0n6d0', 'SSVlD_ZDb70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19500 ['YFhbrSUb0JQ', '8MbxazeMw2E', '4CrPPlHN9_s', 'Pf9AaTV4-yw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19501 ['1ypKEH2kd7g', 'W7KbboEOmeM', 'ODRAYQE9GXs', 'b12xqPnM0So']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19502 ['ua0hgl8fi0I', '5qVc9y3TNnY', 'NdiSW-p2I0c', '-BIMKnb3tlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19503 ['vBkDLBO-Aok', '-T4GeTHKtJQ', 'tUBTRs7Avk0', 'oBBTqXQFTiA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19504 ['8hO1S9VIfPY', 'p4T1pddBia0', 'Y02VBGoTi9w', 'x1S2oreZBWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19505 ['Zmtw8tP-KFo', 'IhNPDueFVSo', 'I-Z3gB6pfIA', 'qtNTHnXOQew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19506 ['IC_Wpalzzm8', 'IcPbxJRbe5g', 'bxF2vxTzlvo', 'p2yedR_jMTU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19507 ['qDiTICmdUQg', '4LZSSya3ZZQ', '7avMUhHOCR8', 'e1KHGfMekek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19508 ['4ueN2gGsH5Y', '1FnT0RrfMEA', 'TZlFTbvfKPE', 'u6tgeRXOxnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19509 ['AVuh8-CucrE', 'w3QIsHxQfPE', 's1eMgmzCMDM', 'Xxe6vTEwFvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19510 ['FXQxobF8FWw', 'J7d3nuS9wqg', 'OwukabRF7I4', 'W2EJai-3k2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19511 ['P5IxlG4-CY8', 'OiAJB9uydS8', 'HTQySJM4Jhg', 'u0CgRmXMXNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19512 ['ikJKSqnTylI', 'uJPW9BEhU6Y', 'mJuJfKbcJcw', 'D_QEW1Lnl2Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19513 ['I5CBPhpimtg', '58f4AsxOYhU', 'lRTeWmoeen4', 'ZFg6KpT5ehU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19514 ['Pm6vRblouxc', 'xseL3oZc7pY', 'ZahBai58_Ec', 'PE1ges9nn6A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19515 ['m9MQdg0k1t0', 'RoDS0k7qrIo', 'QtjMlA_7dds', 'bTuKGXDrqdQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19516 ['pIE-3sIPlvY', '3tlaELkmRqs', 'iTWZsfVCyBs', 'N_Wx35sNqdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19517 ['d352jaSSiFw', 'FkpJaXzgMBQ', 'macnXLRXbHU', 'q-sJu8CoZts']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19518 ['sbOBTkrivXM', 'nvvXOfLs-ng', '-m9pH0WXQto', 'F1X7egd8Us0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19519 ['MMGAKKhqxKg', '8Z5xnSxUmGE', '1LA64TXatWk', 'oynXCFZWxnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19520 ['E6B81rrUlnE', '2Ui85-AOLyo', 'xx1RccwlF5g', 'zj2G-KVw4N4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19521 ['4q-eGdrqiIw', 'yPou7kokTgA', 'RFNRR78dh-8', 'chw8sAKOM5k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19522 ['lymmNwQA0WA', 'Vo6eT8eMMfQ', 'YqZNMFyPJOQ', 'P97w3AdePgQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19523 ['3zntWbS9XeI', 'UY2_Q830lqo', 'Wu3LKQG1fwU', '4b8gTARnmVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19524 ['7FHzw4HV75Y', 'y6NS77HLjEE', 'qfVIeq7s6tw', 'dO3VsX4rKNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19525 ['HOIIp5NyFx0', 'bAJrcYJgllE', 'sxMYFYDNF_g', 'f8QGA4vN6HY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19526 ['X7LrhZX4rdU', '1BVSYfNCcv0', 'TkHZdMJPwKc', 'hVPQu1UJ2N8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19527 ['4Yc71_dU3m4', 'weJKl-6TiDQ', '2CzfBZ1mYBs', '9ZWmZdgrE78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19528 ['iQ7qeIrssds', 'IJcLW4arT6s', 's25X6KwBpxw', 'BN6W6OQnVoE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19529 ['QCbUlDMu7Hk', 'MdsRmMxkF4k', 'yaUK4XvVGTg', 'TiDdR-6bIcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19530 ['VzHL56yq8bI', 'vx5iuWuE2Ng', '4l441DdEJfU', '1rhsnmWLeGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19531 ['VswY2mI7Wbo', 'jHEBYrI8zHE', 'FsnRM2irjvI', 'ZqnbgQeeRbM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19532 ['APSbmhJam74', '6L8066DGqcA', 'q7s7C4oNlFo', '6Q5N1DfzGj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19533 ['c-85TtcfVSI', '5r4jLwjj_Ik', 'sUh43prJYMM', 'YvFY7xU2kGk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19534 ['Hxf1seOpijE', 'oVhhEku6ECA', '50QEapyTPD4', 'kSdH9z8snac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19535 ['-mB_XLq6g1g', 'wwHi10qX8u8', 'N8Fg3L1Cc5E', '3b3s0TvjGwA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19536 ['5ZX1-GAb7IM', 'lIBsL97sUmY', 'AiGGDpbgp6I', 'b2XAPiRUoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19537 ['cTJqIkSuf6s', 'xGHN0kphhWM', 'xhOsZuB_Zqc', 'JC41M7RPSec']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19538 ['UsdoUjuczY4', 'n7yLkcSfiuM', 'OR_YbeqV5tA', '_qf0UiKtB3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19539 ['cqolOXDF86g', '7TmKzUgWiRU', 'MNlzpCwdh4g', 'Xaq-segSEsQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19540 ['GcbCOmNiVm8', 'HLsRePLObfI', '_Ra1Y6K7nSs', 'knQuxZj9rTA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19541 ['tEdeb9eSKDI', '669Fk7afszw', 'tOb0M2k3deo', 'ba5xPgcHN_0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19542 ['vf3n40mDLHw', 't-CMJ6RsZzY', 'ALcCb2HJmG8', 'UrgzGbGVV8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19543 ['7dmT4SgS_EM', 'dW4eW0Xreik', 'I0q3IGmTkRo', 'U-L9YCIdLbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19544 ['HRxTN4TH-80', '9iYxf1hS4Yk', '4i1aizhCnfg', 'vhTWW5Bx15Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19545 ['vrNQbCbBlLY', '6CaZAITdAsk', '-ZHpNr_KRXU', '6QAZJ4H_5rA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19546 ['KyRJP_fDrbk', 'ppAT0f2YCyM', 'stobfk1Mfjk', 'm0FhT3UnXjA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19547 ['x85BtdoxRek', 'GmGWvBNO8JI', 'M0ygCD6WyXw', 'FiKY19GK6-8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19548 ['colnyHv9CAA', 'bKS_m7JObxg', 'vEN9szBPBkw', 'nB2Lf5TTmBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19549 ['6pHo6fPdPvM', 'd20qTsF6ll8', 'dUhE6H72Qpg', 'LaaC_q3QDUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19550 ['evy2azZk3kE', 'KXuB62SMFvA', 'zYUZEXCE7gw', 'hhohfEC82JI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19551 ['rez5KDmIZoc', 'xSDkn9PtQm0', 'dj-DWiV1z9g', 'Hnk45Z0EAxg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19552 ['2kcSUBkFbaQ', 'oYEzy8gH6q8', 'LzSWdj4izHM', 'g0WLA0BKxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19553 ['qp4Ubx7WOAQ', 'C0sSgrr5xrQ', '-FEPOSP7ay0', 'yG1bzzXDIak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19554 ['6TSluKI0X54', '9x7jWb4lE7c', 'dwSj0Rr3vFc', 'zopos1B6Elc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19555 ['k4ttuqKjiw0', 'Yj7YyxKyXPU', 'r_KdRKquXsM', 'qHRRWdWvjxI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19556 ['1SqihV_DnEg', 'efTVnvwI2PQ', '89eBh_Djflw', '74p3DLeDCHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19557 ['e6lTl9JIW5Y', 'c-8SLUH5pp4', '5tNOauvQWQQ', 'bYwoYjbPm-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19558 ['05JAmKFVy44', 'bNW18IztiZY', 'XjrVSk0_4vc', 'HEhogaw0vUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19559 ['EzP7PB2x670', '9JlifkCmUOk', 'IGAzIIZRczw', 'uSZQGP_i3gs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19560 ['JsHTGDW5dgw', 'X6Q53uXgaHc', '78S8DnvLQDY', 'K5ilD6nEJ-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19561 ['mtapmFDmImA', 'DG5d4megH8g', 'OPimGlHcSRQ', 'tvcJENqxr1c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19562 ['S0W_zIUYwrE', 'emDU4QvdwVk', 'nvBPPOzcW-A', 'GiTmjE7az74']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19563 ['RFbWkL818XQ', '7eZTmLV9gcY', 'YyYEzAY2e2I', 'lbB2VQYIMo0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19564 ['c7IL4fDqs_I', 'OJuVsBojdvo', 'FvQgVl5IBHw', 'rizanOQM61k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19565 ['_KaRkSyELy4', '02Qntw26enM', 'N4eMppEnPE0', 'DvOA0K-DIFM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19566 ['6BitLl5Bnxw', 'VG6-MlmCgzI', '6II4JGJDyZo', 'YeIXmKPyTVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19567 ['tdrz4EkIsow', 'ASgLbz48BaY', '5xBfKiQcMZQ', '7EvLwfwRrqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19568 ['QrJVAHIkpCo', '2UY_-oF1vqo', '5fPxUI0Fl-4', '64auWicQqZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19569 ['pvxx3aokwCU', '4KqSdK5KM-I', 'nSinUcyFFqg', 'oKab6-syQD4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19570 ['BYwS1dJRTi0', 'tFVvupXoRoM', 'qRgefptkDeo', 'wIP7AqIOU1s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19571 ['UzDVZzIIcy8', 'Z0O2r0Dl2T4', 'UOAv5b6MGxw', 'L9j9fCHHPeg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19572 ['cfeTMVWFHLo', 'nj6N7m8SeK4', '0nk7utNkHOY', 'Q7oWXOByo28']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19573 ['7lV4IvuW2lk', 'Th6Tf6kA8RU', '45iNSkfzOwM', '6iyinlZEgS4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19574 ['76ON0Ixrr9s', '2nsZhXxes68', 'mU6cfEWw5Og', 'RtXe5T7NFrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19575 ['RiqtelZs_2I', '3ZhyXbwFQAM', 'NVo-stvk_QE', 'ylKvglDzBU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19576 ['MWS-Uxf1MRw', '_5w5TVK5B90', 'XYQnMxWnetY', 'uT-S_JC_GzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19577 ['c9h4p6325Xo', 'MwE7REVj8JQ', '-M-6VinyMiY', 'o8FsD7l5er4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19578 ['l3pK8prEnrQ', 'rkQPSAHNoeI', 'K_G_k1WTdoc', 'nqd7mXvHupU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19579 ['J8pkQfYlJA4', 'ba3QPheW8mI', 'A6ilKRqIDH4', '6KXd7l5pThg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19580 ['IUjzBX2Qm4k', 'qlWEAm4AUTU', 'EY8boPZ1hPs', 'DQrdOgRb-oA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19581 ['8zGJ9N7c6pE', 'b-7oO1Rw-fo', 'pWZqzEpygE0', 'zR4ebAuqy8w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19582 ['4_s5vHgfxnw', 'MsjeOXuUYG4', 'N-dzfI3L5ic', 'J1-Qvl7u2TI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19583 ['lXrypwLQO3U', 'qRCjs90-1RQ', '4mtfOkzOvBI', 'A8P5zzHCjJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19584 ['6UJhTZgnVro', 'CIoEXRnAr-Y', 'zx_vcwOsDO4', 'WYxXUBP_XaM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19585 ['YB28WMv7wUE', 'DRU-IFx-7yQ', 'cYSW6Y884dA', 'f1_YKSYgtbI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19586 ['2ShO1jZYZeA', '0u1sk49gAU0', 'u9n4R78UBtA', 'VCrnnx9jTqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19587 ['dEc7tV30KJo', '3zPvfVmL0nE', 'r9AxQfXYLEs', 'XOsHEjo-RSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19588 ['9jeEfi6nDak', '9PQZSLa_A8A', 'BjAL68IMlp0', 'vtVfl5Ff5lw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19589 ['Y_eh6C0EBP8', 'Zq92ED3IvLQ', '4cg3MsrvJqw', 'RQbNC1J4Jfk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19590 ['38R9Vnwt890', '3Wdxjm-h36w', 'WcC9sKxJ1gI', 'wDpz90boBzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19591 ['-mA_bqD1tgU', 'GQz_u0Vc8Os', 'Sj5MQtqDw8Y', 'nSBDyxxscks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19592 ['hRQJgZVxRX0', 't6jlx6jAb-Q', 'RceCfg1FQq4', 'XILyHZyyCik']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19593 ['-EVRXQpt1-8', 'YLlbLSNxdQ4', 'H-bTMbePj0A', 'pqsU95TNNP8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19594 ['-ByoSbgzr4M', 'O3Cvn4yXrao', 'VV85n-ebuUU', 'Al_OdIuqoe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19595 ['msnm_tYXcYw', 'kjmmzA6i5rk', 'KzydTOkZty8', 'lYJAqOpp6RM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19596 ['lTOzGIOIfq0', 'XfdySM4X9Xo', 'r1W1z_31Obw', '92k_81uqMSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19597 ['C25xvcl4YAU', 'RXGDlFry3Vo', 'C8Euv69GR3U', 'nP05Sf4Fgac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19598 ['gFxLnprPgv4', 'eAFKjP7o1as', 'zd3lShuZNmU', 'Ubj0jlheyvk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19599 ['vxIF3B4YqW8', 'XcvY-NdM8WA', 'DyPmDDN8m78', '1ZaxqZMs21M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19600 ['B8pesuUc8Ek', '1PN-bfs2EhY', 'ZmgkpmzvL6c', '682ODyTqKyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19601 ['5JQIsqc8HBc', 'nbIwdOQ7D8A', 'jcZQhxb5lyw', 'KJHqQ5aKu8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19602 ['i3zayf6Hiog', 'qdWTfyysMN8', '6F8qv0JBWkE', 'LRUdmYcXFuM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19603 ['VSAbMy1Rlio', '0S5zWt91Bwo', 'UDS6PrY9ZIM', '-7B9tPuIP-w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19604 ['xVi1wNljxjk', 'AZsupJ68Hp0', 'DA8lw6Mq0DY', 'QRKc90kuAaE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19605 ['rh0vBy1JD8A', 'rNUtYf6EdW8', 'qXgSlhWbWLU', 'kMmjr8deHis']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19606 ['hTNKYJ6suII', 'ryEXhKy1QUI', 'I1fcUe9MoMw', 'uXMMzpgrY2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19607 ['5jT_i7S9QSM', 'DQ_gcdLhAsY', 'PB3i02Cjf1k', 'pKDnn0CBIe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19608 ['qDSvHlHbAqM', 'hYlSisv-VRU', 'L2-EGNKzUAQ', 'B3lq6U4PDZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19609 ['Iz611KubW70', 'LR3U4b_fVBc', '-m5ZlWziIeA', 'UJA5AWbt6HM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19610 ['cHGziT0hrZU', 'ABVYSaLu_VM', 'yHd5DzIbWL8', 'kbCh5HrmgN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19611 ['99ZgIQwLC60', '3OWArQGgmm0', 'wFTlySgdWX4', 'W2KaBnoGxek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19612 ['PJRG2bwphUc', 'TqWmuwAYmnI', '3ZyuBJEbmJM', 'E2gstPe3Im4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19613 ['aVNcweinmEM', '8KIoQ2HZ0Hg', 'TWV3YLscSaw', 'C3Jhu77uffQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19614 ['PTLOLz9YzmM', 'kkjNpwNcMWI', '0EzWmAPwoTs', 'fyLctn3jNUs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19615 ['Xus0LI3QV2A', '1Xtkou9dtyA', 'aBEiuYSSEH0', 'm-eyGzf9Ux4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19616 ['D_usHKfOXCw', 'pyumNmhV4_s', 'R3urUtvSgkU', 'MyjxrBI9k4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19617 ['NlUf1ppoSG4', 'P240GHf9Eq4', 'JYYfw3id3ek', 'KDuusOmEMHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19618 ['ZVvX2-ldhvY', 'eZE0RmJESFU', 's5wdG7xbTNg', 'dztizAgcQ08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19619 ['ZUcHBeueBww', '0H3FAoDgzhI', 'QpX9dSCFxRI', 'kjn6I3AurgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19620 ['9ZryMX2UtAo', 'B4lGhVjoMTk', 'O40E8bpmONQ', 'Js_3Aa214xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19621 ['qwI32Si0ipE', 'AnErEDywInE', 'JUrYWttZJBM', '2SenLjPbGzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19622 ['BRTHyoVgZT0', 'WIVu5PapmX4', 'fHNAxa0QaOM', 'lBtAULJAFp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19623 ['MvnC1TfNiPY', 'CJjyrDGmxIY', 'mBG-st0VUXs', 'aUH12rRIVDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19624 ['OoRUo92emGo', 'fD1xB9lDbPQ', 'Npbs_4DZgEQ', 'VRfi64fecj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19625 ['ySY5J3TDgag', 'nv1hWkBbG0g', 'HtCkwxfAmzw', 'P-eIhvCaK-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19626 ['qni67aUJbw4', 'Nt0U-CXK6O0', 'jFek2xLbEww', 'I-C14nCneBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19627 ['uYCAxX2F6DA', 'Qe_KwKVDgoE', 'I_wT76iYBdQ', 'MpjN21Z93JY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19628 ['O0y-m0pCi5E', '-o0ZtQIkM60', 'GNjsxLdSwHI', 'P4aTFrJws40']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19629 ['6807299U5eg', 'iHYOaGNdweo', 'OMApGp219Zc', 'AaajkQEU3A0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19630 ['7LlnLjZOqVI', 'EIzBD62ja8E', 'BfMKdrK9D8M', 'aURLQXt_6fE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19631 ['BkoCi-IZccI', '2SQxfaWAJJg', 'lBSS2AbA560', 'Euu6zlJQSD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19632 ['h7DOBV43UPQ', 'NsYVaRI6rXg', 'x9bcsYF_by8', 'DVuWm53IlVw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19633 ['Z-Vb1Ay-zNA', '1y1lEOGBcWM', 'J9ZlahUawkg', 'IqGB4nQIAcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19634 ['GYCfrx0ruz4', '2I6pPRWKsCQ', 'H4tyvJJzSDk', 's59pQGs7Q3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19635 ['QQTWFTNy-WA', 'tKawN2sxhYc', 'fvhbI-7e89s', 'hSK405L-DlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19636 ['qMd2DTyF9EE', 'bHNdoIWxXDk', 'HMQfp_qtF-M', 'A446kjocnCg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19637 ['yeu6OEIKwws', 'vTXb8P7sAFY', 'V9jIsOTC1lY', '7OjXHfVoI64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19638 ['3gh1oldZ7Zc', '2wZCoeq9Ppc', 'AgtY6m-b3Gk', 'ura8EjHjGC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19639 ['R0b3pU4AKNc', 'oC0e8GXYy_4', '2uvHgwAljPA', 'JI26wmUPcrM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19640 ['t-yy7v7P0IE', '3C-5_z01Olc', '0M7nETLOsKQ', 'yuWjB3XA8tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19641 ['1QSD-dzEv7Y', '_GxqvILlmAw', 'R_HAtyDbw1M', '8Nrp4jUZeGE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19642 ['PP3kNqPM434', 'XI9CNsX6JSE', '3tbFP_JKzXw', 'Rwt8j_USbWI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19643 ['_miAGxDX5FM', 'st92BzeUzFU', '4lcZkOMhKv8', 'Zz1Bz1a7yPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19644 ['raM8Lp0aGCk', '49nqh7uI9fw', 'ANaaOqwO0Uo', 'SlnjJv305Vg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19645 ['IjP5kKfgBiI', '9Cfs00bZRCg', 'ApDJYsi9UGg', 's1QeDT7jqHQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19646 ['XPGtOugQ69U', '7YWMPBHKdyY', '9Ijpv6e57a4', 'xR2p3UED4VU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19647 ['C0eCERYt4bA', 'R77XPtKgvy4', 'WJIrkvEq4EI', 'hqQvatf1RUY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19648 ['6zgvEiJJrM8', 'e4R2O7XpIXU', 'PwmXO0J-PAA', '1JwoLPCIGhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19649 ['0zolXzR9Oi4', 'zeUEOxTd8IE', 'JPZlyvPNZj4', 'G2uCAwYS6w0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19650 ['1lgqqW5TsJk', 'UHvYrO1IGCc', '3nbB3F-OdSM', 'AFWy1qyyMHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19651 ['jlIbJVfnHB4', 'gMgN50wSnNc', 'd9r_kYpOvW8', 'PRRcVdXsBQg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19652 ['ORikRIu7s1o', 's6U8DtBK3Us', '_yXtw_z2xf4', 'BXcEsM8ykhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19653 ['YIhfk4Zaevk', 'CpHRQ-f4UtA', 'RDW_kz4SXo0', 'aCTm1TcL7z8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19654 ['RtgHU1UMo5o', '4T2KBwRxi_g', 'GFJNgqcX7u0', 'uAYPacrJnyQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19655 ['-1LrH01Ei1w', 'vd1dgdxlA94', '2xGRCsW6-Bk', 'NqDxpJ2uR_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19656 ['BsnjK6DypAg', 'DYpjbiyPUho', 'UNJswfXKJ3s', 'Z9hnLYpypCU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19657 ['UfEGX0rNOvA', '6C0HoQe4Y-Y', 'oFCzd9bJo9A', 'qVdBBOpSoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19658 ['oD0Xp--xxjE', 'LEG7xkYOsWA', 'LM2C1eIUX9M', 'CyiPyjYX6AE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19659 ['EKZvq0dUk50', 'TzPuAqjoL80', 'p9nbp0Oo1U0', 'ZJZxWLYzNh8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19660 ['sC7T0sEG6ek', 'wwbATvWFaLY', 'rUIGOcQMaSE', 'Rf7vygfb7w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19661 ['xZukWGb52BI', '7vC1iriZlX8', '2ZYzviKuq9w', 'si_IAMPOXlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19662 ['Cwbtn_h6TP8', '_y07ENAx2_E', '3TO4C7SiC7I', 'uF1KTW5rT-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19663 ['-7wUQP6G5EQ', 'tpamd6BKYU4', 'uYYpqx0rzok', 'EPvnkbo5wrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19664 ['AJw-x30L46E', '5P5XAclO8ko', 'AwcuLXAPFDs', 'pHzjKCj9INw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19665 ['2gc1L3g1itU', 'RI126_DmGLQ', 'gNpzuFPu6q8', 'PF5LgwJjYuA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19666 ['qsFfUzErXqw', 'dBAeAk7dXnU', 'RI71ebbU0PQ', '2zpITTJiw7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19667 ['Mp1MHSeHa0o', 'Qz8hNRg-7G0', 'UeYmnV-B8so', 'vK9x7UQ9Y7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19668 ['PqTTIfja0y8', 'xxCnmao8FAs', 'F5zDEHggiMg', '1W2Cz2Jj76Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19669 ['W_MZo88gzrA', '07FxCXxknY4', 'aUx0xMF9pwU', 'je96vkMY60c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19670 ['tIRHm8VhK_4', 'YpOHemscGCk', 'z7vNtEcM9Bk', '2_kLD3IbF2c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19671 ['5rsQHo-6DI4', '08mf5GxT820', 'darQBSIlol8', 'IN71kMOAk_k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.5169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19672 ['1l7BjFDQLUM', 'eWNERam16Hg', 'aeDZVfGk7bk', 'QKkhwAAGLIE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19673 ['vOU-qA25xNM', 'too9MtXBwts', 'OKZF0oG1E14', 'D8-x1T8M4gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19674 ['I-xPuRe9vF0', 'eyFBIA_HOmE', '3VEMHWnewuc', 'rccs9c1gteQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19675 ['16TsDMjHzYU', 'rOOBAGxxjBk', 'mq_b6QKVsuc', 'MC0Aeu7RLSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19676 ['F9LJIyqQFe8', '2ctgUIqyaBk', 'ZU6sI1Plq50', 'h2f_CKjQQg8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19677 ['YZH-PZBir3E', 'KkW6ZkmAlEw', 'KmBaE7ozWow', 'THfTLXBLpJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19678 ['gAURHUoIK0M', 'OheHnFixwVk', 'navn7jCBp_o', 'dLUobee5JEs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19679 ['QIzSxE0WlKE', 'nYO8n62Piys', 'MROotmz8a-U', 'qknDM3pcoD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Step 19680\n",
            "Loss tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "batches_per_epoch = int(ds_train.num_rows / batch_size)\n",
        "output = []\n",
        "sentences = []\n",
        "step = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for i in range(batches_per_epoch):\n",
        "    start = i * batch_size\n",
        "    # print(start)\n",
        "    xBatch = ds_train[start:start+batch_size]\n",
        "    # xBatch = ds_train[i]\n",
        "    # print(xBatch)\n",
        "    waveform = xBatch[\"waveform\"]\n",
        "    id = xBatch[\"ytid\"]\n",
        "    print(step, id)\n",
        "    input = torch.tensor(xBatch[\"input_values\"]).squeeze(1).to(device)\n",
        "    # input = torch.tensor(xBatch[\"input_values\"]).to(device)\n",
        "\n",
        "    # captions = xBatch[\"tokenizedCaption\"]\n",
        "    captions = xBatch[\"tokenizedAspectList\"]\n",
        "    maxCaptionLen = 0\n",
        "    # Find max length of caption in batch\n",
        "    for item in range(batch_size):\n",
        "      if(len(captions[item]) > maxCaptionLen):\n",
        "        maxCaptionLen = len(captions[item])\n",
        "\n",
        "  # Add padding to the captions based on max len\n",
        "    for j in range(batch_size):\n",
        "      if(len(captions[j]) < maxCaptionLen):\n",
        "        for k in range(len(captions[j]), maxCaptionLen):\n",
        "          captions[j].append(2)\n",
        "\n",
        "    # target = torch.tensor(xBatch[\"tokenizedCaption\"]).to(device)\n",
        "    target = torch.tensor(xBatch[\"tokenizedAspectList\"]).to(device)\n",
        "    # target = target.unsqueeze(0)\n",
        "    print(input.shape)\n",
        "    print(target.shape)\n",
        "    currOutput = newModel(input, target[:, :-1])\n",
        "    # currOutput = newModel(input, target)\n",
        "    # print(currOutput)\n",
        "    pred = currOutput[0].argmax(1)\n",
        "    pred2 = currOutput[1].argmax(1)\n",
        "    # print(predIdx)\n",
        "    # output.append(currOutput)\n",
        "    # print(target[0])\n",
        "\n",
        "    # for j in range(len(pred)):\n",
        "    #   if(pred[j] == 1):\n",
        "    #     tempOutput = currOutput[0][:j]\n",
        "    #     print(tempOutput.shape)\n",
        "        # for k in range(j+1, len(pred)):\n",
        "        #   currOutput[0][k][2] = 100\n",
        "\n",
        "    # for j in range(len(pred2)):\n",
        "    #   if(pred2[j] == 1):\n",
        "    #     # for k in range(j+1, len(pred2)):\n",
        "    #     #   currOutput[1][k][2] = 100\n",
        "\n",
        "    # newMax = lossOutput.argmax(1)\n",
        "    # print(newMax)\n",
        "\n",
        "    # loss = bleu_score(predSen, targetSen)\n",
        "    # loss = criterion(currOutput[0], target[0])\n",
        "    # loss = criterion(currOutput.reshape(-1, currOutput.shape[2]), target[0].reshape(-1))\n",
        "    currOutput = currOutput.view(-1, currOutput.shape[2])\n",
        "    targetInput = target[:,1:].reshape(-1)\n",
        "\n",
        "    # targetInput = target.contiguous().view(-1)\n",
        "    # loss = criterion(currOutput, targetInput)\n",
        "    loss = custom_loss(currOutput, targetInput)\n",
        "    print(\"Loss\", loss)\n",
        "\n",
        "    step += 1\n",
        "    # for name, param in newModel.named_parameters():\n",
        "    #   if param.grad is not None:\n",
        "    #     print(name, param.grad)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(loss)\n",
        "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Step\", step)\n",
        "  print(\"Loss\", loss)\n",
        "  torch.save(newModel.state_dict(), 'newModelCheckpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "LUjKCZahqDfX",
        "outputId": "cc987093-0088-46a0-ac6a-fec5f74e464d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 ['zjZV0tvur2I', 'XaUXJG0BZuk']\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-755781c15cba>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mytid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ytid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokenzedCaption\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "batches_per_epoch = int(ds_train.num_rows / batch_size)\n",
        "output = []\n",
        "sentences = []\n",
        "step = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    ytid = data[\"ytid\"]\n",
        "    print(step, ytid)\n",
        "    input = torch.tensor(data[\"input_values\"]).squeeze(1).to(device)\n",
        "    print(\"Input shape\", input.shape)\n",
        "    target = torch.tensor(data[\"tokenzedCaption\"]).to(device)\n",
        "    print(\"Target shape\", target.shape)\n",
        "    modelOutput = newModel(input, target[:, :-1])\n",
        "    lossInput = modelOutput.view(-1, modelOutput.shape[2])\n",
        "    lossTarget = target[:,1:].reshape(-1)\n",
        "    loss = criterion(lossInput, lossTarget)\n",
        "    print(\"Loss\", loss)\n",
        "    step += 1\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(loss)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqITETAPmOCC"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpTzbMML5qQz"
      },
      "outputs": [],
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in newModel.state_dict():\n",
        "    print(param_tensor, \"\\t\", newModel.state_dict()[param_tensor].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_OopVyHJpi"
      },
      "outputs": [],
      "source": [
        "loaded_model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, model).to(device)\n",
        "loaded_model.load_state_dict(torch.load(\"newModelCheckpoint.pth\"))\n",
        "loaded_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjyA9l9AFsjN"
      },
      "outputs": [],
      "source": [
        "# def dynamicPadding(batch):\n",
        "#   captions = batch[\"tokenizedCaption\"]\n",
        "#   maxCaptionLen = 0\n",
        "#   for i in range(batch_size):\n",
        "#     if(len(captions[i]) > maxCaptionLen):\n",
        "#       maxCaptionLen = len(captions[i])\n",
        "\n",
        "#   for j in range(batch_size):\n",
        "#     if(len(captions[j]) < maxCaptionLen):\n",
        "#       for k in range(len(captions[j]), maxCaptionLen):\n",
        "#         captions[j].append(2)\n",
        "\n",
        "#   return batch\n",
        "\n",
        "\n",
        "def dynamicPadding(batch):\n",
        "  captions = batch[\"tokenizedAspectList\"]\n",
        "  maxCaptionLen = 0\n",
        "  for i in range(batch_size):\n",
        "    if(len(captions[i]) > maxCaptionLen):\n",
        "      maxCaptionLen = len(captions[i])\n",
        "\n",
        "  for j in range(batch_size):\n",
        "    if(len(captions[j]) < maxCaptionLen):\n",
        "      for k in range(len(captions[j]), maxCaptionLen):\n",
        "        captions[j].append(2)\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h-I-B80NIqC",
        "outputId": "89981c5b-fc65-4edc-ed56-01c88e605fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1024, 128])\n",
            "torch.Size([1, 14])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor(ds_test[0:1][\"input_values\"]).squeeze(1).to(device)\n",
        "\n",
        "batch = ds_test[0:1]\n",
        "# captions = batch[\"tokenizedCaption\"]\n",
        "# maxCaptionLen = 0\n",
        "\n",
        "# for i in range(batch_size):\n",
        "#   if(len(captions[i]) > maxCaptionLen):\n",
        "#     maxCaptionLen = len(captions[i])\n",
        "\n",
        "# for j in range(batch_size):\n",
        "#   if(len(captions[j]) < maxCaptionLen):\n",
        "#     for k in range(len(captions[j]), maxCaptionLen):\n",
        "#       captions[j].append(2)\n",
        "\n",
        "# dynamicPadding(batch)\n",
        "\n",
        "# target = torch.tensor(batch[\"tokenizedCaption\"]).to(device)\n",
        "target = torch.tensor(batch[\"tokenizedAspectList\"]).to(device)\n",
        "# target = target.unsqueeze(0)\n",
        "print(input.shape)\n",
        "print(target.shape)\n",
        "modelOutput = newModel(input, target)\n",
        "# loadedOutput = loaded_model(input, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1xlz2072wXa",
        "outputId": "007d6ade-b9f9-43ab-d225-1203a8c07d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([88, 5475])\n"
          ]
        }
      ],
      "source": [
        "tempOutput = modelOutput.view(-1, modelOutput.shape[2])\n",
        "print(tempOutput.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tYxn0JD-YI",
        "outputId": "611793e6-ba44-4fe0-e35d-b6acf02ac4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-2.5003,  1.9018, -2.6463,  ..., -3.2833, -3.7127, -3.0394],\n",
            "         [-2.3698,  3.4217, -1.9702,  ..., -3.4956, -2.8221, -2.8570],\n",
            "         [-1.3004,  1.9933, -0.7634,  ..., -2.0791, -1.3730, -1.9847],\n",
            "         ...,\n",
            "         [-0.5852,  2.4742,  0.2530,  ..., -1.0860, -1.1115, -0.5978],\n",
            "         [-2.2533,  5.3062, -1.8107,  ..., -2.6317, -3.4494, -3.4386],\n",
            "         [-1.3028,  2.9477, -0.4578,  ..., -2.1496, -1.6670, -1.1011]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([  4, 229, 783, 132, 571,  46, 200,  38, 229,  24, 313,  24,   1, 226],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(modelOutput)\n",
        "max = modelOutput[0].argmax(1)\n",
        "print(max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3KIkZKb0ecD",
        "outputId": "f38ce99f-9154-4f7c-ee62-9f7a11e706b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([  0,   9,  94, 299,  40,  39, 416, 334,  11,  27,   4,  11,  87, 154,\n",
            "        321,  96,  82,   4,  16, 170,  72,  42,  16,  91,  41,  42,  96,  20,\n",
            "        156, 190,  16,  96, 534,  16,  87,  31, 180,  27,   4,  11,  87,  11,\n",
            "         16, 416,  16,  42,  16,  20,  16,  11,  20, 219,  27,  39,  11,  87,\n",
            "         27,   1,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "lossOutput = modelOutput[0]\n",
        "for i in range(len(max)):\n",
        "  if(max[i] == 1):\n",
        "    for j in range(i+1, len(max)):\n",
        "      lossOutput[j][2] = 100\n",
        "\n",
        "newMax = lossOutput.argmax(1)\n",
        "print(newMax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am69qnV7DBlK"
      },
      "outputs": [],
      "source": [
        "def createSentence(input):\n",
        "  sentence = []\n",
        "  for i in range(len(input)):\n",
        "    sentence.append(vocab_list[input[i]])\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKUMcxbfIhWW",
        "outputId": "28ec6f2a-8c44-46c1-f381-5a9073d9d16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['low', 'classical', 'hypnotic', 'music', 'elements', 'acoustic', 'bansuri', 'singing', 'classical', 'tempo', 'uptempo', 'tempo', '<EOS>', 'easygoing']\n",
            "['oriental', 'meditative', 'zitar', 'percussive', 'sounds', 'shrutibox', 'voices', 'chanting', 'slow', 'to', 'medium', 'tempo']\n"
          ]
        }
      ],
      "source": [
        "outputSentence = createSentence(max)\n",
        "print(outputSentence)\n",
        "print(ds_test[0][\"aspect_list\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEZpRmaV83b2",
        "outputId": "e0ed6cd4-56ed-4e22-d9a6-2e49ba0b5afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 39,  87,   9,   9, 238,   9,  96,   9,  27,   9,  27,   9,  96,  27,\n",
            "          4,  94,  23,  87,   9,  20,   4,  94,  27,  20,   1,  11,  40, 238,\n",
            "         77,   8,   3,   4,  27,  87,   4,  11,  87,  90,  91,  49,   4,   3,\n",
            "        223,  27,   1,  27], device='cuda:0')\n",
            "torch.Size([24, 5475])\n",
            "tensor([ 39,  11,   6,   7,   8,   9,  96,  27,  87, 285,  77,   9,  96,   6,\n",
            "         27,  20,   4,  87,  20,  20,   3,  27,  27,  20,  27,  27,  20,   9,\n",
            "          4,   4,  27,   4,  11,  87,   9,  27,   4,  90,  91,  27,  27,   3,\n",
            "         11,  27,  20,  27], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "pred1 = modelOutput[0].argmax(1)\n",
        "print(pred1)\n",
        "for i in range(len(pred1)):\n",
        "  if(pred1[i] == 1):\n",
        "    tempOutput = modelOutput[0][:i]\n",
        "    print(tempOutput.shape)\n",
        "    break\n",
        "\n",
        "pred2 = modelOutput[1].argmax(1)\n",
        "print(pred2)\n",
        "\n",
        "for j in range(len(pred2)):\n",
        "  if(pred2[j] == 1):\n",
        "    tempOutput2 = modelOutput[1][:j]\n",
        "    print(tempOutput2.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "AGkeNdHC0K4Y",
        "outputId": "d8d9a158-dbc0-45d1-c9ce-334daac29af4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-4bc71509be35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewTempOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempOutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewTempOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# currOutput = currOutput.view(-1, currOutput.shape[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# targetInput = target[:,1:].reshape(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tempOutput2' is not defined"
          ]
        }
      ],
      "source": [
        "newTempOutput = torch.cat((tempOutput, tempOutput2))\n",
        "print(newTempOutput.shape)\n",
        "# currOutput = currOutput.view(-1, currOutput.shape[2])\n",
        "# targetInput = target[:,1:].reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6MAXgiQ7TWe",
        "outputId": "3c7d2128-dbcc-47ec-bcde-0f72eccbae80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 153])\n"
          ]
        }
      ],
      "source": [
        "targetTest1 = [0, 1]\n",
        "targetTest2 = [0, 1]\n",
        "for i in range(151):\n",
        "  targetTest1.append(2)\n",
        "  targetTest2.append(2)\n",
        "\n",
        "test1 = torch.tensor(targetTest1).unsqueeze(0).to(device)\n",
        "test2 = torch.tensor(targetTest2).unsqueeze(0).to(device)\n",
        "targetCaption = torch.cat((test1, test2))\n",
        "print(targetCaption.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbEb2F-k8RtN"
      },
      "outputs": [],
      "source": [
        "testOutput = newModel(input, targetCaption)\n",
        "print(testOutput)\n",
        "max = testOutput[0].argmax(1)\n",
        "print(max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSLmqDlu9iON"
      },
      "source": [
        "## Dynamic Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB2toqEr9mTO",
        "outputId": "2f474cbe-f8e3-4a12-a2a5-37da9f52d34a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78\n",
            "78\n"
          ]
        }
      ],
      "source": [
        "batch = ds_train[0:2]\n",
        "captions = batch[\"tokenizedCaption\"]\n",
        "maxCaptionLen = 0\n",
        "\n",
        "# Find max length of caption in batch\n",
        "for i in range(batch_size):\n",
        "  if(len(captions[i]) > maxCaptionLen):\n",
        "    maxCaptionLen = len(captions[i])\n",
        "\n",
        "for j in range(batch_size):\n",
        "  if(len(captions[j]) < maxCaptionLen):\n",
        "    for k in range(len(captions[j]), maxCaptionLen):\n",
        "      captions[j].append(2)\n",
        "\n",
        "\n",
        "target = torch.tensor(batch[\"tokenizedCaption\"]).to(device)\n",
        "print(len(batch[\"tokenizedCaption\"][0]))\n",
        "print(len(batch[\"tokenizedCaption\"][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM0xLccZ5izu",
        "outputId": "ef3a777a-f00f-4da2-8c1f-914a0c38b429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: newModelCheckpoint.pth (deflated 7%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r 'audioCaptionModel.zip' 'newModelCheckpoint.pth'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"newModelCheckpoint.pth\")"
      ],
      "metadata": {
        "id": "PwSvHA_U1tI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37e32ddf-c719-4a5e-8555-723d4762a19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cff842ed-9617-492d-894c-7394e91a78aa\", \"newModelCheckpoint.pth\", 832730631)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IIOwtVvmJn2x",
        "outputId": "5a35ecf2-d9fc-4949-df0b-e39c53a4f4f3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_2d3b17c8-0cf6-4427-a4cf-54f6f1bb3e41\", \"audioCaptionModel.zip\", 772473597)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"audioCaptionModel.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Zkq-Fbk6WS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfnfsPRck8kQ",
        "outputId": "638701d4-0312-40c2-c5d1-87900da42f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153\n",
            "torch.Size([2, 153])\n"
          ]
        }
      ],
      "source": [
        "# [<SOS> ... <PAD> ]\n",
        "infTarg = [0]\n",
        "for i in range(152):\n",
        "  infTarg.append(2)\n",
        "print(len(infTarg))\n",
        "\n",
        "infTarg = torch.tensor(infTarg).unsqueeze(0).to(device)\n",
        "infTarg = torch.cat((infTarg, infTarg))\n",
        "print(infTarg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKcBGfBftGux"
      },
      "outputs": [],
      "source": [
        "input = torch.tensor(ds_test[0:2][\"input_values\"]).squeeze(1).to(device)\n",
        "modelOutput = newModel(input, infTarg)\n",
        "\n",
        "# Branch out, rank, reduce, repeat\n",
        "beam_size = 3\n",
        "\n",
        "probabilities = modelOutput.clone()\n",
        "hypothesis = []\n",
        "score = []\n",
        "for i in range(beam_size):\n",
        "  pred = probabilities[0].argmax(1)\n",
        "  hypothesis.append([pred])\n",
        "  probabilities[0] = probabilities[0].remove(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LsgbIc19CBt"
      },
      "outputs": [],
      "source": [
        "beam_size = 2\n",
        "text = [0]\n",
        "text = torch.tensor(text).unsqueeze(0).to(device)\n",
        "hypotheses = [text]\n",
        "\n",
        "newText = torch.tensor([0]).unsqueeze(0).to(device)\n",
        "\n",
        "currSeqPos = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-2rUJaa3EI6"
      },
      "outputs": [],
      "source": [
        "output = newModel(input,text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmD7HTMS04z6",
        "outputId": "5cf2d255-98ca-49bd-a285-dfdd807b602b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([39], device='cuda:0')\n",
            "tensor([7.6185], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([0.], device='cuda:0', grad_fn=<IndexBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Code to slice an index from the output tensor\n",
        "# output = newModel(input,text)\n",
        "seqPos = 0;\n",
        "predIdx = 4\n",
        "# output[0][seqPos] = torch.cat((output[0][seqPos][:4], output[0][seqPos][4:]))\n",
        "# output[0][seqPos][predIdx] = torch.cat((output[0][seqPos][:predIdx], output[0][seqPos][predIdx+1:]))\n",
        "# output[0][seqPos] = tempOutput\n",
        "\n",
        "# Can't set the output to a tensor with different values - in the case of slicing, we remove 1\n",
        "# So we instead set that prediction to 0\n",
        "print(output[0].argmax(1))\n",
        "predIdx = output[0].argmax(1)\n",
        "print(output[0][0][predIdx])\n",
        "output[0][seqPos][predIdx] = 0\n",
        "print(output[0][0][predIdx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6h1iogJEKuL"
      },
      "outputs": [],
      "source": [
        "newInputTensor = torch.tensor([5]).to(device)\n",
        "newText = newText.squeeze(0).to(device)\n",
        "newText = torch.cat((newText, newInputTensor))\n",
        "# newText = newText.unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vj5ulHv5epn",
        "outputId": "97727fcb-d506-4af2-8fd8-fe63087c3470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 5, 5, 5], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(newText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "f90i0nxR6y5g",
        "outputId": "00ac9f27-d7b8-4ab6-e7c4-8f31dce8e185"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-568cff30ca3d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempVal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [2]"
          ]
        }
      ],
      "source": [
        "newText[0] = tempVal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "AfTmDFUIjeQV",
        "outputId": "ec9e490d-859f-4cb1-fd42-576a8764d459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "tensor(4, device='cuda:0')\n",
            "tensor([4], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "tensor(7.9543, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "2\n",
            "tensor(4, device='cuda:0')\n",
            "tensor([4], device='cuda:0')\n",
            "tensor([0, 4], device='cuda:0')\n",
            "tensor(7.9543, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "2\n",
            "tensor(4, device='cuda:0')\n",
            "tensor([4], device='cuda:0')\n",
            "tensor([0, 4, 4], device='cuda:0')\n",
            "tensor(7.9543, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-851d2e930dc3>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# del probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrSeqPos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-851d2e930dc3>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(input, newText, currSeqPos, max_depth)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Calculate score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Delete current probabilities tensor to free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrSeqPos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# del probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-851d2e930dc3>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(input, newText, currSeqPos, max_depth)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Calculate score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Delete current probabilities tensor to free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrSeqPos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# del probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-851d2e930dc3>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(input, newText, currSeqPos, max_depth)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Calculate score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Delete current probabilities tensor to free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrSeqPos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# del probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-851d2e930dc3>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(input, newText, currSeqPos, max_depth)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mnewText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m# del probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# probabilities = output.detach().clone()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-b10a8eada05e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# trg_mask = nn.Transformer.generate_square_subsequent_mask(max_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pooler_output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     ) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n\u001b[0;32m--> 290\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# in AST, layernorm is applied before self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     ) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 42.81 MiB is free. Process 609099 has 14.70 GiB memory in use. Of the allocated memory 13.31 GiB is allocated by PyTorch, and 312.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "def beam_search(input, newText, currSeqPos, max_depth=100):\n",
        "\n",
        "  if(currSeqPos >= max_depth):\n",
        "    return\n",
        "\n",
        "  newText = newText.unsqueeze(0).to(device)\n",
        "  output = newModel(input, newText)\n",
        "  # del probabilities\n",
        "  # probabilities = output.detach().clone()\n",
        "  if(currSeqPos != 0):\n",
        "    currSeqPos += 1\n",
        "\n",
        "\n",
        "  for i in range(beam_size):\n",
        "    print(beam_size)\n",
        "    # Provides values for each token in sequence - found via largest probability\n",
        "    # prediction = probabilities[0].argmax(1)\n",
        "    prediction = output[0].argmax(1)\n",
        "    tokenIdx = prediction[currSeqPos]\n",
        "    print(tokenIdx)\n",
        "    newToken = tokenIdx.view(1)\n",
        "    print(newToken)\n",
        "    # Appends token to newText based on the position of the sequence\n",
        "    # newText.append(tokenIdx)\n",
        "    # newText[0] = torch.cat((newText[0], tokenIdx))\n",
        "    newText = newText.squeeze(0).to(device)\n",
        "    print(newText)\n",
        "    newText = torch.cat((newText, newToken))\n",
        "    # Remove the highest probability from the output to find the next highest probability for the next iteration of the beam length\n",
        "    print(output[0][currSeqPos][tokenIdx])\n",
        "    output[0][currSeqPos][tokenIdx] = 0\n",
        "    print(output[0][currSeqPos][tokenIdx])\n",
        "    # Calculate score\n",
        "    # Delete current probabilities tensor to free up memory\n",
        "    beam_search(input, newText, currSeqPos)\n",
        "\n",
        "  # del probabilities\n",
        "\n",
        "beam_search(input, newText, currSeqPos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvrk2VxeLRbM"
      },
      "outputs": [],
      "source": [
        "def beam_search_iterative(input, newText, max_depth=10):\n",
        "  for currSeqPos in range(max_depth):\n",
        "    newText = newText.unsqueeze(0).to(device)\n",
        "    print(\"New Text shape\", newText.shape)\n",
        "    output = newModel(input, newText)\n",
        "    probabilities = output.detach().clone()\n",
        "\n",
        "    for i in range(beam_size):\n",
        "      prediction = probabilities[0].argmax(1)\n",
        "      tokenIdx = prediction[currSeqPos]\n",
        "      # print(tokenIdx)\n",
        "      # if(tokenIdx == 1):\n",
        "      #   break\n",
        "      newToken = tokenIdx.view(1)\n",
        "      newText = newText.squeeze(0).to(device)\n",
        "      newText = torch.cat((newText, newToken))\n",
        "      output[0][currSeqPos][tokenIdx] = 0\n",
        "\n",
        "    del probabilities\n",
        "\n",
        "\n",
        "beam_search_iterative(input, newText)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "# Test cell to remove a number from a tensor\n",
        "arr = [ 4,   35,   31, 2004, 2126,  197]\n",
        "remove = 197\n",
        "tensor = torch.tensor(arr).to(device)\n",
        "filter=2\n",
        "# print(tensor)\n",
        "# index = ((tensor == remove).nonzero().squeeze())\n",
        "# print(index)\n",
        "# newTen = torch.cat((tensor[:index], tensor[index+1:]))\n",
        "# print(newTen)\n",
        "# test = collections.deque(tensor, maxlen=filter)\n",
        "# print(test)\n",
        "\n",
        "tenLen = tensor.shape[0]\n",
        "print(tenLen)\n",
        "\n",
        "indexes = tenLen - filter\n",
        "\n",
        "test = tensor[indexes:]\n",
        "print(test)\n",
        "# test = tensor[0]\n",
        "for i in range(len(test)):\n",
        "  if(test[i] == remove):\n",
        "    found = i\n",
        "  else:\n",
        "    found = 0\n",
        "\n",
        "\n",
        "newIdx = indexes+found\n",
        "print(tensor[newIdx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSkCwA-1si3_",
        "outputId": "618084ee-92e0-4b98-f3b2-403e118492fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "tensor([2126,  197], device='cuda:0')\n",
            "tensor(197, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJqo4vMFOyQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a10ca17-f99e-488e-97b7-a50ebca724a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prev text tensor([[0, 0]], device='cuda:0')\n",
            "_ 0\n",
            "node length 1\n",
            "node token id tensor([[0]], device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 2])\n",
            "Pred shape torch.Size([1, 2, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([0], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[0, 4]], device='cuda:0')\n",
            "_ 1\n",
            "node length 2\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 2])\n",
            "Pred shape torch.Size([1, 2, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427]], device='cuda:0')\n",
            "_ 2\n",
            "node length 3\n",
            "node token id tensor(427, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 3])\n",
            "Pred shape torch.Size([1, 3, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  0,   4, 427], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28]], device='cuda:0')\n",
            "_ 3\n",
            "node length 4\n",
            "node token id tensor(28, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 4])\n",
            "Pred shape torch.Size([1, 4, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  4, 427,  28], device='cuda:0')\n",
            "history tensor(4, device='cuda:0') token tensor(4, device='cuda:0')\n",
            "Multinomial_input shape torch.Size([1048])\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74]], device='cuda:0')\n",
            "_ 4\n",
            "node length 5\n",
            "node token id tensor(74, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 5])\n",
            "Pred shape torch.Size([1, 5, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([427,  28,  74], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4]], device='cuda:0')\n",
            "_ 5\n",
            "node length 6\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 6])\n",
            "Pred shape torch.Size([1, 6, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([28, 74,  4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13]], device='cuda:0')\n",
            "_ 6\n",
            "node length 7\n",
            "node token id tensor(13, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 7])\n",
            "Pred shape torch.Size([1, 7, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([74,  4, 13], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270]], device='cuda:0')\n",
            "_ 7\n",
            "node length 8\n",
            "node token id tensor(270, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 8])\n",
            "Pred shape torch.Size([1, 8, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  4,  13, 270], device='cuda:0')\n",
            "history tensor(4, device='cuda:0') token tensor(4, device='cuda:0')\n",
            "Multinomial_input shape torch.Size([1048])\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558]], device='cuda:0')\n",
            "_ 8\n",
            "node length 9\n",
            "node token id tensor(558, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 9])\n",
            "Pred shape torch.Size([1, 9, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 13, 270, 558], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10]], device='cuda:0')\n",
            "_ 9\n",
            "node length 10\n",
            "node token id tensor(10, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 10])\n",
            "Pred shape torch.Size([1, 10, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([270, 558,  10], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10,  64]],\n",
            "       device='cuda:0')\n",
            "_ 10\n",
            "node length 11\n",
            "node token id tensor(64, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 11])\n",
            "Pred shape torch.Size([1, 11, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([558,  10,  64], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10,  64, 199]],\n",
            "       device='cuda:0')\n",
            "_ 11\n",
            "node length 12\n",
            "node token id tensor(199, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 12])\n",
            "Pred shape torch.Size([1, 12, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 10,  64, 199], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215]], device='cuda:0')\n",
            "_ 12\n",
            "node length 13\n",
            "node token id tensor(2215, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 13])\n",
            "Pred shape torch.Size([1, 13, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  64,  199, 2215], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158]], device='cuda:0')\n",
            "_ 13\n",
            "node length 14\n",
            "node token id tensor(1158, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 14])\n",
            "Pred shape torch.Size([1, 14, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 199, 2215, 1158], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41]], device='cuda:0')\n",
            "_ 14\n",
            "node length 15\n",
            "node token id tensor(41, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 15])\n",
            "Pred shape torch.Size([1, 15, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2215, 1158,   41], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269]], device='cuda:0')\n",
            "_ 15\n",
            "node length 16\n",
            "node token id tensor(269, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 16])\n",
            "Pred shape torch.Size([1, 16, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([1158,   41,  269], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692]], device='cuda:0')\n",
            "_ 16\n",
            "node length 17\n",
            "node token id tensor(692, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 17])\n",
            "Pred shape torch.Size([1, 17, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 41, 269, 692], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229]], device='cuda:0')\n",
            "_ 17\n",
            "node length 18\n",
            "node token id tensor(229, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 18])\n",
            "Pred shape torch.Size([1, 18, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([269, 692, 229], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4]], device='cuda:0')\n",
            "_ 18\n",
            "node length 19\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 19])\n",
            "Pred shape torch.Size([1, 19, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([692, 229,   4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174]], device='cuda:0')\n",
            "_ 19\n",
            "node length 20\n",
            "node token id tensor(2174, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 20])\n",
            "Pred shape torch.Size([1, 20, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 229,    4, 2174], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233]],\n",
            "       device='cuda:0')\n",
            "_ 20\n",
            "node length 21\n",
            "node token id tensor(233, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 21])\n",
            "Pred shape torch.Size([1, 21, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([   4, 2174,  233], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084]],\n",
            "       device='cuda:0')\n",
            "_ 21\n",
            "node length 22\n",
            "node token id tensor(2084, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 22])\n",
            "Pred shape torch.Size([1, 22, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2174,  233, 2084], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095]],\n",
            "       device='cuda:0')\n",
            "_ 22\n",
            "node length 23\n",
            "node token id tensor(2095, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 23])\n",
            "Pred shape torch.Size([1, 23, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 233, 2084, 2095], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557]],\n",
            "       device='cuda:0')\n",
            "_ 23\n",
            "node length 24\n",
            "node token id tensor(557, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 24])\n",
            "Pred shape torch.Size([1, 24, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2084, 2095,  557], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95]], device='cuda:0')\n",
            "_ 24\n",
            "node length 25\n",
            "node token id tensor(95, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 25])\n",
            "Pred shape torch.Size([1, 25, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2095,  557,   95], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744]], device='cuda:0')\n",
            "_ 25\n",
            "node length 26\n",
            "node token id tensor(744, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 26])\n",
            "Pred shape torch.Size([1, 26, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([557,  95, 744], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520]], device='cuda:0')\n",
            "_ 26\n",
            "node length 27\n",
            "node token id tensor(520, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 27])\n",
            "Pred shape torch.Size([1, 27, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 95, 744, 520], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520, 4229]], device='cuda:0')\n",
            "_ 27\n",
            "node length 28\n",
            "node token id tensor(4229, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 28])\n",
            "Pred shape torch.Size([1, 28, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 744,  520, 4229], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520, 4229, 2037]], device='cuda:0')\n",
            "_ 28\n",
            "node length 29\n",
            "node token id tensor(2037, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 29])\n",
            "Pred shape torch.Size([1, 29, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 520, 4229, 2037], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "class BeamSearchNode:\n",
        "  def __init__(self, prev_node, token_id, log_prob, length):\n",
        "    self.prev_node = prev_node\n",
        "    self.token_id = token_id\n",
        "    self.log_prob = log_prob\n",
        "    self.length = length\n",
        "\n",
        "\n",
        "def top_p_sampling(logits, p):\n",
        "  # Sort logits in descending order\n",
        "  sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "  print(sorted_logits.shape)\n",
        "  # Calculate cumulative probabilities\n",
        "  cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "  print(cumulative_probs)\n",
        "  # Determine indices to sample\n",
        "  indices_to_sample = sorted_indices[cumulative_probs < p]\n",
        "  print(\"Indices_to_sample\", indices_to_sample, \"len\", indices_to_sample.shape)\n",
        "  return indices_to_sample\n",
        "\n",
        "\n",
        "def sample_from_subset(indices_to_sample, logits):\n",
        "  # Sample one index from the subset\n",
        "  multinomial_input = F.softmax(logits[indices_to_sample], dim=-1)\n",
        "  print(\"Multinomial_input shape\", multinomial_input.shape)\n",
        "  sampled_index = torch.multinomial(multinomial_input, 1)\n",
        "  return sampled_index.item()\n",
        "\n",
        "\n",
        "def top_p_sample(logits, prevText, p, filter):\n",
        "  # Compute indices to sample from\n",
        "  indices_to_sample = top_p_sampling(logits, p)\n",
        "  # Sample from the subset\n",
        "  sampled_index = sample_from_subset(indices_to_sample, logits)\n",
        "  token = indices_to_sample[sampled_index]\n",
        "  # Token filtering here\n",
        "  # If token is in token history then remove it from indices to sample and sample from subset again\n",
        "  filterWindow = prevText.shape[1] - filter\n",
        "  token_history = prevText[0][filterWindow:]\n",
        "  print(\"History\", token_history)\n",
        "  for i in range(len(token_history)):\n",
        "    if(token_history[i] == token):\n",
        "      print(\"history\", token_history[i], \"token\", token)\n",
        "      indices_to_sample = torch.cat((indices_to_sample[:sampled_index], indices_to_sample[sampled_index+1:]))\n",
        "      sampled_index = sample_from_subset(indices_to_sample, logits)\n",
        "      token = indices_to_sample[sampled_index]\n",
        "      continue\n",
        "  # indices_to_sample = torch.cat((indices_to_sample[:sampled_index], indices_to_sample[sampled_index+1:]))\n",
        "  return token\n",
        "\n",
        "\n",
        "\n",
        "# def node_to_array(node):\n",
        "#   array = [node.token_id]\n",
        "#   while(node.prev):\n",
        "#     node = node.prev\n",
        "#     array.append(node.token_id)\n",
        "#   print(array)\n",
        "#   return array\n",
        "\n",
        "\n",
        "def beam_search_node(newModel, input, newText, max_length=10, num_beams=2):\n",
        "  initial_node = BeamSearchNode(prev_node=None, token_id=newText, log_prob=0.0, length=1)\n",
        "  beam = [initial_node]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    new_beam = []\n",
        "    for node in beam:\n",
        "      if node.length >= max_length:\n",
        "        new_beam.append(node)\n",
        "        continue\n",
        "\n",
        "      tempNodes = node\n",
        "      prevText = []\n",
        "      while tempNodes.prev_node:\n",
        "        prevText.append(tempNodes.prev_node.token_id)\n",
        "        tempNodes = tempNodes.prev_node\n",
        "      if(prevText == []):\n",
        "        prevText.append(0)\n",
        "      # Reverses the array\n",
        "      prevText = prevText[::-1]\n",
        "      prevText.append(node.token_id)\n",
        "      prevText = torch.tensor(prevText).unsqueeze(0).to(device)\n",
        "      print(\"Prev text\", prevText)\n",
        "      # print(\"Prev text shape\", prevText.shape)\n",
        "      # print(\"New token shape\", newToken.shape)\n",
        "      text_input = prevText\n",
        "\n",
        "      print(\"_\", _)\n",
        "      print(\"node length\", node.length)\n",
        "      print(\"node token id\", node.token_id)\n",
        "      print(\"New beam len\", len(new_beam))\n",
        "      print(\"beam len\", len(beam))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Log prob\n",
        "        print(\"Text input shape\", text_input.shape)\n",
        "        preds = newModel(input, text_input)\n",
        "        print(\"Pred shape\", preds.shape)\n",
        "        temperature = 1.25\n",
        "        scaled_logits = preds[0][0] / temperature\n",
        "        top_p_index = top_p_sample(scaled_logits, prevText, p=0.8, filter=3)\n",
        "        log_probs = F.log_softmax((scaled_logits), dim=-1)\n",
        "        # log_probs = F.log_softmax(preds[0], dim=-1)\n",
        "        print(\"Log probs shape\", log_probs.shape)\n",
        "\n",
        "      topk_probs, topk_ids = torch.topk(log_probs, num_beams)\n",
        "      print(topk_probs)\n",
        "      seqIdx = log_probs.shape[0] - 1\n",
        "\n",
        "      # for prob, token_id in zip(topk_probs[seqIdx], topk_ids[seqIdx]):\n",
        "      #   print(\"Prob\", prob)\n",
        "      #   new_node = BeamSearchNode(\n",
        "      #       prev_node=node,\n",
        "      #       token_id=token_id.item(),\n",
        "      #       log_prob=node.log_prob+prob.item(),\n",
        "      #       length = node.length + 1\n",
        "      #   )\n",
        "      #   print(\"New node token\", new_node.token_id)\n",
        "      #   new_beam.append(new_node)\n",
        "      #   print(\"New beam after len\", len(new_beam))\n",
        "\n",
        "      new_node = BeamSearchNode(\n",
        "          prev_node=node,\n",
        "          token_id=top_p_index,\n",
        "          log_prob = node.log_prob+scaled_logits[top_p_index],\n",
        "          length = node.length+1,\n",
        "      )\n",
        "      new_beam.append(new_node)\n",
        "\n",
        "\n",
        "    beam = sorted(new_beam, key=lambda x: x.log_prob, reverse=True)[:num_beams]\n",
        "\n",
        "  output_sequences = []\n",
        "  for node in beam:\n",
        "    output_sequence = []\n",
        "    while node:\n",
        "      output_sequence.append(node.token_id)\n",
        "      node = node.prev_node\n",
        "    output_sequence.reverse()\n",
        "    output_sequences.append(output_sequence)\n",
        "  return output_sequences\n",
        "\n",
        "\n",
        "gen = beam_search_node(newModel, input, newText, max_length=30, num_beams=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPqpTW0X0gB8",
        "outputId": "fc15176b-6a78-4839-e826-89a7ba450506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0]], device='cuda:0')\n",
            "[[tensor([[0]], device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(506, device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(66, device='cuda:0'), tensor(651, device='cuda:0'), tensor(76, device='cuda:0'), tensor(48, device='cuda:0'), tensor(76, device='cuda:0'), tensor(76, device='cuda:0'), tensor(100, device='cuda:0'), tensor(4, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(76, device='cuda:0'), tensor(4, device='cuda:0'), tensor(4, device='cuda:0'), tensor(66, device='cuda:0'), tensor(18, device='cuda:0'), tensor(104, device='cuda:0'), tensor(76, device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(507, device='cuda:0'), tensor(934, device='cuda:0'), tensor(104, device='cuda:0')]]\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "print(newText)\n",
        "# print(hypotheses)\n",
        "print(gen)\n",
        "print(len(gen[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fth-xKliSeK",
        "outputId": "86bcec92-0ddc-4afb-9bd3-f9b81948260a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<SOS>', 'low', 'scuffling', 'instrumental', 'live', 'low', 'piano', 'loud', 'symphonic', 'female', 'unrelated', 'shrutibox', 'tap', 'swing', 'jazzy', 'harp', 'indian', 'classical', 'low', 'diy', 'joyful', 'climax', 'snapping', 'opera', 'kids', 'acapella', 'bad', 'benign', 'hindu']\n",
            "['percussion', 'music', 'no', 'other', 'instruments', 'no', 'voices', 'instrumental', 'advertisement', 'music', 'promotional', 'music']\n"
          ]
        }
      ],
      "source": [
        "tokenizedInput = [  0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
        "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
        "           95,  744,  520, 4229, 2037]\n",
        "outputSentence = createSentence(tokenizedInput)\n",
        "print(outputSentence)\n",
        "print(ds_test[0][\"aspect_list\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_list[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WU9gkMuoeuVU",
        "outputId": "6967c9ef-efaa-4da9-a62a-1c7771ed4d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'low'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "ulrrrdQrlbBH",
        "outputId": "1b052fe4-1ed6-471d-eb05-904122740469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-550675b44748>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  infTarg[0][i+1] = torch.tensor(pred[i+1])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(27)\n",
            "tensor(27)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-550675b44748>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m152\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfTarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minfTarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b10a8eada05e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# trg_mask = nn.Transformer.generate_square_subsequent_mask(max_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pooler_output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     ) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n\u001b[0;32m--> 290\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# in AST, layernorm is applied before self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     ) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "input = torch.tensor(ds_test[0:2][\"input_values\"]).squeeze(1).to(device)\n",
        "\n",
        "for i in range(152):\n",
        "  modelOutput = newModel(input, infTarg)\n",
        "  pred = modelOutput[0].argmax(1)\n",
        "  infTarg[0][i+1] = torch.tensor(pred[i+1])\n",
        "  print(pred[i+1])\n",
        "  if(pred[i+1] == 1):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Ec9-X9ZgxJ",
        "outputId": "01b01187-f285-4e5f-8339-113b0a659fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the\n"
          ]
        }
      ],
      "source": [
        "print(vocab_list[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnrOADocnaj2",
        "outputId": "9239d21c-5f78-4d4d-9587-53c619081477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  0, 110, 110, 110, 219, 110, 219, 219, 219, 110, 110, 110, 110, 110,\n",
            "         219, 219, 110, 110, 110, 219, 110, 219, 219, 110, 110, 110, 219, 219,\n",
            "         110, 110, 110, 219, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110,\n",
            "         219, 219, 219, 110, 219, 219, 110, 110, 219, 110, 219, 219, 110, 110,\n",
            "         110, 110, 219, 219, 110, 110, 110, 110, 110, 110, 219, 219, 110, 110,\n",
            "         110, 110, 110, 110, 110, 219, 219, 219, 110, 219, 110, 110, 110, 110,\n",
            "         110, 219, 110, 110, 219, 110, 110, 110, 110, 219, 110, 110, 110, 110,\n",
            "         110, 110, 110, 110, 110, 110, 110, 219, 219, 219, 110, 219, 219, 110,\n",
            "         110, 110, 110, 110, 110, 110, 219, 110, 219, 110, 110, 110, 110, 219,\n",
            "         219, 110, 219, 219, 110, 110, 219, 110, 110, 110, 219, 219, 219, 110,\n",
            "         110, 219, 219, 110, 219, 110, 110, 110, 219, 219, 110, 219, 219],\n",
            "        [  0,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(infTarg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO89THoFDbQL"
      },
      "outputs": [],
      "source": [
        "encoderOutput = model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLNg5N0bJlww",
        "outputId": "d2b4f7d1-596c-42bd-f171-cb5120208b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['last_hidden_state', 'pooler_output'])\n"
          ]
        }
      ],
      "source": [
        "print(encoderOutput.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IHa0YcxDeDF",
        "outputId": "c2b14896-4370-44e2-d74f-ce735b4562b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1214, 768])\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 153, 768])\n",
            "torch.Size([1, 153, 768])\n",
            "torch.Size([153, 768])\n"
          ]
        }
      ],
      "source": [
        "print(encoderOutput[\"last_hidden_state\"].shape)\n",
        "print(encoderOutput[\"pooler_output\"].shape)\n",
        "print(encoderOutput[\"pooler_output\"].unsqueeze(1).expand(-1, target.shape[1], -1).shape)\n",
        "enc_src = encoderOutput[\"pooler_output\"].unsqueeze(1).expand(-1, target.shape[1], -1)\n",
        "print(enc_src.shape)\n",
        "print(enc_src[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwMQCU6WESF_"
      },
      "outputs": [],
      "source": [
        "def make_src_mask(src):\n",
        "  src_mask = (src != src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "  # (N, 1, 1, src_length)\n",
        "  return src_mask.to(device)\n",
        "\n",
        "def make_trg_mask(trg):\n",
        "  N, trg_len = trg.shape\n",
        "  # trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
        "  #     N, 1, trg_len, trg_len\n",
        "  # )\n",
        "  trg_mask = torch.tril(torch.ones(trg_len, N))\n",
        "  return trg_mask.to(device)\n",
        "\n",
        "\n",
        "\n",
        "src_mask = make_src_mask(input)\n",
        "trg_mask = make_trg_mask(target)\n",
        "\n",
        "decoderBlock = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length).to(device)\n",
        "\n",
        "decoderOutput = decoderBlock(target, enc_src, src_mask, trg_mask).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgynqSIaMDlC",
        "outputId": "a152caba-7f53-4c5c-f2fe-765372e25839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 152])\n"
          ]
        }
      ],
      "source": [
        "print(target[:,:-1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrvWewaAFGAs",
        "outputId": "79e861c4-feba-4a4e-9f88-2565f5cd3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 153, 5475])\n",
            "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(decoderOutput.shape)\n",
        "print(decoderOutput[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnvvsRM0C9Ws"
      },
      "outputs": [],
      "source": [
        "print(modelOutput[0].shape)\n",
        "print(modelOutput[0])\n",
        "pred = modelOutput[0].argmax(1)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SncPQ7ua-ZwL",
        "outputId": "7e874861-0c86-4b82-e548-b76aeb7d777e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
            "        [0.7229, 0.5077, 0.4864,  ..., 0.3799, 0.6367, 0.4397],\n",
            "        [0.1653, 0.7800, 0.5162,  ..., 0.6711, 0.3135, 0.3795],\n",
            "        ...,\n",
            "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([   0,   39,  196,   13,    9,  918,   91,   55,  210,  132,  716,   43,\n",
            "         669,  110,    9,   19,   49,    4,   61,  394,  112,   96,    9,  730,\n",
            "         461,   20,    9,   72,  461,   27,   39,   11,  109,   90,  110,   36,\n",
            "           9, 1967, 5278,   39,  918,   27,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# currOutput[0]\n",
        "# pred = currOutput[0].argmax(1)\n",
        "# print(pred)\n",
        "# print(len(currOutput[0][1]))\n",
        "# print(currOutput.shape)\n",
        "print(currOutput)\n",
        "# print(outputSentence)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEZ7zOaHkeRt",
        "outputId": "8f8ac360-ac23-4c1e-8a99-918e35a1e581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "used\n"
          ]
        }
      ],
      "source": [
        "print(vocab_list[310])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOhOpB4hDMNR",
        "outputId": "da4a2596-9c93-4711-99ec-0d86db185e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<SOS>', 'this', 'audio', 'contains', 'a', 'composition', 'played', 'by', 'brass', 'instruments', 'such', 'as', 'trumpets', 'playing', 'a', 'melody', 'in', 'the', 'higher', 'range', 'along', 'with', 'a', 'deeper', 'horn', 'and', 'a', 'bass', 'horn', '.', 'this', 'song', 'may', 'be', 'playing', 'at', 'a', 'theater', 'presenting', 'this', 'composition', '.', '<EOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>']\n"
          ]
        }
      ],
      "source": [
        "outputSentence = createSentence(pred)\n",
        "print(outputSentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1_Tz-FIFZXA",
        "outputId": "00d52e5c-96cf-4c9b-b524-a96e55babacf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This audio contains a composition played by brass instruments such as trumpets playing a melody in the higher range along with a deeper horn and a bass horn. This song may be playing at a theater presenting this composition.\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(ds_train)):\n",
        "  if(ds_train[i][\"ytid\"] == \"r_KdRKquXsM\"):\n",
        "    print(ds_train[i][\"caption\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqumM414F4TL"
      },
      "outputs": [],
      "source": [
        "input = torch.tensor(ds_test[0][\"input_values\"]).to(device)\n",
        "target = torch.tensor(ds_test[0][\"tokenizedCaption\"]).to(device)\n",
        "testOutput = newModel(input.squeeze(1), target.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-LcXslVGn_5",
        "outputId": "99f92300-3ee0-41df-9069-cdf059677f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(testOutput[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSKBlE3mLxoc",
        "outputId": "fd46b83b-46cd-4846-c7ec-2b9374065dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5000, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(currOutput[1][489])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yMqZRIbqh9H"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader\n",
        "# word2vec = Word2Vec.load()\n",
        "glove_vec = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMjpq91Ure16"
      },
      "outputs": [],
      "source": [
        "glove_vec.most_similar(\"guitar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWaLjEJAteDB"
      },
      "outputs": [],
      "source": [
        "glove_vec.index_to_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlWlXVVqs5KJ"
      },
      "outputs": [],
      "source": [
        "closest_word = None\n",
        "max_sim = -1\n",
        "vector1 = output[0][1][0]\n",
        "vector2 = torch.zeros(149)\n",
        "print(vector1.shape)\n",
        "\n",
        "vector = torch.cat((vector1, vector2), dim=0)\n",
        "for word in glove_vec.index_to_key:\n",
        "  word_vector = torch.tensor(glove_vec[word])\n",
        "  sim = torch.dot(vector, word_vector) / (torch.norm(vector) * torch.norm(word_vector)).detach.numpy()\n",
        "  if sim > max_sim:\n",
        "    max_sim = sim\n",
        "    closest_word = word\n",
        "\n",
        "\n",
        "print(closest_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5k88lUorvPU"
      },
      "source": [
        "# Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4pv0oLxrCDE"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEEJ0IcUDn3a",
        "outputId": "21f87e98-1406-4ca3-8fb6-e05d2c26c54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['last_hidden_state', 'pooler_output'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1214, 768])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.keys())\n",
        "outputs[\"last_hidden_state\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr-7ga5_sHHx"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHsoGO3osLDJ",
        "outputId": "005341a0-04cc-48f9-8431-293606c133bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder(\n",
            "  (word_embedding): Embedding(6143, 768)\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x DecoderBlock(\n",
            "      (attention): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (transformer_block): TransformerBlock(\n",
            "        (attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (feed_forward): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0, inplace=False)\n",
            "      )\n",
            "      (dropout): Dropout(p=0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (fc_out): Linear(in_features=768, out_features=6143, bias=True)\n",
            "  (dropout): Dropout(p=0, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIb66xyprtV9"
      },
      "outputs": [],
      "source": [
        "def make_src_mask(src):\n",
        "  # src_mask = (src != src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "  src_mask = (src != src_pad_idx).squeeze()\n",
        "  # (N, 1, 1, src_length)\n",
        "  return src_mask.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va10rYkhn2yn"
      },
      "outputs": [],
      "source": [
        "def make_trg_mask(trg):\n",
        "  N, trg_len = trg.shape\n",
        "  # trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
        "  #     N, 1, trg_len, trg_len\n",
        "  # )\n",
        "  trg_mask = torch.tril(torch.ones(trg_len, N))\n",
        "  return trg_mask.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CatLAmwsQzR",
        "outputId": "1fe8d319-2611-4a8a-f60e-3490af41cdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([18, 1])\n",
            "torch.Size([1024, 128])\n"
          ]
        }
      ],
      "source": [
        "enc_src = outputs[\"pooler_output\"].unsqueeze(1).expand(-1, 18, -1)\n",
        "src_mask = make_src_mask(inputs)\n",
        "trg_mask = make_trg_mask(trg)\n",
        "print(trg_mask.shape)\n",
        "print(src_mask.shape)\n",
        "decodeOut = decoder(trg, enc_src, trg_mask, trg_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C0G2KcttDs",
        "outputId": "5a229063-3d11-4ef0-c557-a7bde25e13be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 18, 6143])\n"
          ]
        }
      ],
      "source": [
        "print(decodeOut.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDrVIY-uwU88"
      },
      "outputs": [],
      "source": [
        "N, seq_length = trg.shape\n",
        "positions = torch.arange(0, seq_length).expand(N, seq_length).to(device)\n",
        "word_embedding = nn.Embedding(trg_vocab_size, embed_size).to(device)\n",
        "# position_embedding = nn.Embedding(embed_size, max_length).to(device)\n",
        "position_embedding = nn.Parameter(torch.randn(max_length, embed_size)).to(device)\n",
        "dropoutFunc =  nn.Dropout(dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0TMY1lBwoUN",
        "outputId": "5a892e9a-ac5a-401b-e7be-ee6d05e3e9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 18, 768])\n",
            "torch.Size([18, 768])\n",
            "torch.Size([1, 18, 768])\n"
          ]
        }
      ],
      "source": [
        "word = word_embedding(trg)\n",
        "# pos = position_embedding(positions)\n",
        "pos = position_embedding[:seq_length]\n",
        "print(word.shape)\n",
        "print(pos.shape)\n",
        "x = dropoutFunc(word + pos)\n",
        "# x = dropout((word + pos))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y4Z0jn-Zu5s",
        "outputId": "601e977a-45c3-4439-cabe-889ab6c8cc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7805, -0.1441, -1.3261,  ..., -0.6013, -0.0808,  0.0878],\n",
            "         [ 0.7496,  1.0978,  0.0337,  ..., -0.5370, -0.1557, -0.3764],\n",
            "         [-1.1219, -0.2174, -0.2250,  ...,  0.6839, -0.2006,  0.6456],\n",
            "         ...,\n",
            "         [ 0.2170, -0.6863, -0.5809,  ...,  0.0870,  0.3194,  0.1975],\n",
            "         [-0.1514, -0.7697,  0.3599,  ...,  1.1205, -0.8512, -0.4996],\n",
            "         [ 0.7957,  0.4360,  0.1964,  ..., -0.3208, -1.2579, -0.8765]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768])\n",
            "torch.Size([1, 1, 1024, 128])\n",
            "torch.Size([1024, 128])\n"
          ]
        }
      ],
      "source": [
        "self_attention = nn.MultiheadAttention(embed_size, heads)\n",
        "self_norm = nn.LayerNorm(embed_size)\n",
        "attention, _ = self_attention(x, x, x, trg_mask)\n",
        "print(attention)\n",
        "query = dropoutFunc(self_norm(attention + x))\n",
        "print(query.shape)\n",
        "# Modifies enc_src to be the same shape as query\n",
        "test_enc_src = enc_src.unsqueeze(1).expand(-1, query.size(1), -1)\n",
        "print(test_enc_src.shape)\n",
        "print(src_mask.shape)\n",
        "test_src_mask = src_mask[-1, -1, :, :]\n",
        "print(test_src_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLE6BNJZeb7O"
      },
      "outputs": [],
      "source": [
        "transform_attention = self_attention(query, test_enc_src, test_enc_src, trg_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "O7RYXsu0dK1q",
        "outputId": "26477edd-81ca-4144-ff61-3aa6cc618d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-45af960d777e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mself_transformer_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_expansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_transformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_enc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_enc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-525c57b34665>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, value, key, query, mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5225\u001b[0m         )\n\u001b[1;32m   5226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5227\u001b[0;31m     \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mha_shape_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5229\u001b[0m     \u001b[0;31m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_mha_shape_check\u001b[0;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[1;32m   5024\u001b[0m              f\" but found {key.dim()}-D and {value.dim()}-D tensors respectively\")\n\u001b[1;32m   5025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey_padding_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5026\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5027\u001b[0m                 (\"For batched (3-D) `query`, expected `key_padding_mask` to be `None` or 2-D\"\n\u001b[1;32m   5028\u001b[0m                  f\" but found {key_padding_mask.dim()}-D tensor instead\")\n",
            "\u001b[0;31mAssertionError\u001b[0m: For batched (3-D) `query`, expected `key_padding_mask` to be `None` or 2-D but found 4-D tensor instead"
          ]
        }
      ],
      "source": [
        "self_transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion)\n",
        "print(enc_src.shape)\n",
        "trans = self_transformer_block(query, test_enc_src, test_enc_src, src_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gwFkj402urF",
        "outputId": "457e2b3f-fc47-486d-ca4a-a2972bfe86b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([18, 18])\n"
          ]
        }
      ],
      "source": [
        "print(trg_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ2NLSoJoEyd",
        "outputId": "bf5c4a9c-d31f-425a-9a9c-f89d4c7e1f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[1., 0., 0., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 1., 1., 1.]]]])\n"
          ]
        }
      ],
      "source": [
        "target = [[1,3,2,4,5], [6,7,8,9,10]]\n",
        "target = np.asarray(target)\n",
        "target_mask = make_trg_mask(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MhYYuWFoDqj",
        "outputId": "317dfa47-8b4a-47fd-d792-feec8588f414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[1., 0., 0., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 1., 1., 1.]]]])\n",
            "torch.Size([2, 1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "print(target_mask)\n",
        "print(target_mask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwxFHh_WxOzk"
      },
      "source": [
        "# LSTM Decoder Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqNB4wZeYpiW",
        "outputId": "24590502-68a8-435f-b2b3-3a03ceafe247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0-11): 12 x ASTLayer(\n",
            "    (attention): ASTAttention(\n",
            "      (attention): ASTSelfAttention(\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (output): ASTSelfOutput(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): ASTIntermediate(\n",
            "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (intermediate_act_fn): GELUActivation()\n",
            "    )\n",
            "    (output): ASTOutput(\n",
            "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model.encoder.layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Tek2Wq8xSTb"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input=3072, output_size=64, embedding_size=64, hidden_size=64, num_layers=2, p=0.2):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.embedding = nn.Embedding(input, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    self.h = [torch.zeros(num_layers, 4, hidden_size) for _ in range(2)]\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = x.unsqueeze(0)\n",
        "    # embedding = self.dropout(self.embedding(x))\n",
        "    embedding = self.embedding(x.int())\n",
        "    outputs, (hidden, cell) = self.rnn(embedding, (hidden, self.h))\n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    return predictions, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lq2_0pUx4_L"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, n_hidden, n_layers):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.input_hidden = nn.Embedding(vocab_size, n_hidden)\n",
        "    self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "    self.hidden_out = nn.Linear(n_hidden, vocab_size)\n",
        "    self.h = [torch.zeros(n_layers, 4, n_hidden) for _ in range(2)]\n",
        "\n",
        "  def forward(self, x, bias):\n",
        "    res, h = self.rnn(self.input_hidden(x.int()), self.h)\n",
        "    self.h = [h_.detach() for h_ in h]\n",
        "    return self.hidden_out(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJGkdGMH3JOa",
        "outputId": "29987736-6df4-4225-b4e6-965f0c397028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "torch.Size([2, 4, 64])\n",
            "Embedding(3072, 64)\n"
          ]
        }
      ],
      "source": [
        "# model.encoder\n",
        "# model.encoder.layer.output = LSTM(3072, 64)\n",
        "h = [torch.zeros(2, 4, 64) for _ in range(2)]\n",
        "print(len(h))\n",
        "print(h[0].shape)\n",
        "input_h = nn.Embedding(3072, 64)\n",
        "print(input_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZtOZ8Vo8keH"
      },
      "outputs": [],
      "source": [
        "class Instantiate(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Instantiate, self).__init__()\n",
        "\n",
        "  def forward(self, x, bias):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc8VsmDN3MGc",
        "outputId": "eb97d2d6-096a-4382-eee7-6ee2d3981040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0-11): 12 x ASTLayer(\n",
            "    (attention): ASTAttention(\n",
            "      (attention): ASTSelfAttention(\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (output): ASTSelfOutput(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): ASTIntermediate(\n",
            "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (intermediate_act_fn): GELUActivation()\n",
            "    )\n",
            "    (output): Instantiate()\n",
            "    (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# print(model.encoder.layer[0].output)\n",
        "for layer in model.encoder.layer:\n",
        "  # layer.output = Decoder(3072, 64, 2)\n",
        "  layer.output = Instantiate()\n",
        "\n",
        "print(model.encoder.layer[0:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "S4vbeVnsYinf",
        "outputId": "fb464ed3-e22f-4905-d7a4-0a7327c8c0ef"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-22ad3be4b478>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 )\n\u001b[1;32m    351\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    289\u001b[0m     ) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n\u001b[1;32m    290\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# in AST, layernorm is applied before self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    191\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2513\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m         )\n\u001b[0;32m-> 2515\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[768], expected input with shape [*, 768], but got input of size[1, 1214, 3072]"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgFu7_Ou4G0y",
        "outputId": "1aec73da-7694-49b7-f568-eff2564f6417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0-11): 12 x ASTLayer(\n",
            "    (attention): ASTAttention(\n",
            "      (attention): ASTSelfAttention(\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (output): ASTSelfOutput(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): ASTIntermediate(\n",
            "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (intermediate_act_fn): GELUActivation()\n",
            "    )\n",
            "    (output): Decoder(\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (embedding): Embedding(3072, 64)\n",
            "      (rnn): LSTM(64, 64, num_layers=2, dropout=0.2)\n",
            "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
            "    )\n",
            "    (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model.encoder.layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-2MEaNT5Two"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1VBOgdySxGb5bUNgN1kWfZFR050qmmec3",
      "authorship_tag": "ABX9TyMoRLS6Q2GrMTqAZ6hV3VBu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caf864f927bb4dfd9a920af784e6279a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c820ef37e37f46ae97f8f8c7835d6155",
              "IPY_MODEL_6ce05079f751444e858fdec3490c643d",
              "IPY_MODEL_f10c7b8c53434b149a738349e2db4f83"
            ],
            "layout": "IPY_MODEL_efbd27fbeb2743e5959f922766f7af1d"
          }
        },
        "c820ef37e37f46ae97f8f8c7835d6155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9afc25d4ce5947d5a6d9a18efb1867f5",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab758d6094b48f0bc16c97d0f51bdd1",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "6ce05079f751444e858fdec3490c643d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9796c68ea3b48f8ab531dd95da9248b",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8600763699148a7ba75cb5bf452760e",
            "value": 4000
          }
        },
        "f10c7b8c53434b149a738349e2db4f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a9eaedc8404c5ab058991e29755084",
            "placeholder": "​",
            "style": "IPY_MODEL_eebc759d45fc4ee0adb0c909a666256d",
            "value": " 4000/4000 [01:40&lt;00:00, 21.43 examples/s]"
          }
        },
        "efbd27fbeb2743e5959f922766f7af1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afc25d4ce5947d5a6d9a18efb1867f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab758d6094b48f0bc16c97d0f51bdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9796c68ea3b48f8ab531dd95da9248b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8600763699148a7ba75cb5bf452760e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15a9eaedc8404c5ab058991e29755084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebc759d45fc4ee0adb0c909a666256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe5e88f46814addb420127fba3e1a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98882b6be26d4adb984b780f18b42475",
              "IPY_MODEL_cbcdddb134184651878d4095e86f568a",
              "IPY_MODEL_0b3a52a94e964d3d88cd3f4af589ec32"
            ],
            "layout": "IPY_MODEL_8cb19431548240c6aef34ee2f7b727d9"
          }
        },
        "98882b6be26d4adb984b780f18b42475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51160fe4f0f4428a849ae2f45cdeb6f",
            "placeholder": "​",
            "style": "IPY_MODEL_4e50c217fc9a4593ad1a4b13d3cd6520",
            "value": "Filter: 100%"
          }
        },
        "cbcdddb134184651878d4095e86f568a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f7e377db9d402589c0b62459eeb6f8",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4e0be3a213144b28c49e5bf8bfb3cea",
            "value": 4000
          }
        },
        "0b3a52a94e964d3d88cd3f4af589ec32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0414bc80ce8843089e4cb2703c148d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_92f8854f16fa4aa589e5cca56519e17e",
            "value": " 4000/4000 [00:00&lt;00:00, 19839.85 examples/s]"
          }
        },
        "8cb19431548240c6aef34ee2f7b727d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51160fe4f0f4428a849ae2f45cdeb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e50c217fc9a4593ad1a4b13d3cd6520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39f7e377db9d402589c0b62459eeb6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e0be3a213144b28c49e5bf8bfb3cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0414bc80ce8843089e4cb2703c148d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f8854f16fa4aa589e5cca56519e17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfefceaa9a994572bc75f13848d17e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b182fdc6fb142e99a3e1c68e64a85c6",
              "IPY_MODEL_0a12a718706941388f4648d6f253aff2",
              "IPY_MODEL_dc91bd5090d146b1898283e57504f417"
            ],
            "layout": "IPY_MODEL_79e43e78edd44d659c596010bb8cd8cf"
          }
        },
        "1b182fdc6fb142e99a3e1c68e64a85c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa698a1c6114d4e838cead88aadd973",
            "placeholder": "​",
            "style": "IPY_MODEL_50f48d378d984300b20567188119f2a7",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "0a12a718706941388f4648d6f253aff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf2bf40e7b94e5788c62e90eb130811",
            "max": 3938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_408414e23a3f486f8f1ca8ddcd58571e",
            "value": 3938
          }
        },
        "dc91bd5090d146b1898283e57504f417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b83da868d64aacb2813ee62aa56592",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0b7242250542b3bd24fff37f9b8c0f",
            "value": " 3938/3938 [00:36&lt;00:00, 117.02 examples/s]"
          }
        },
        "79e43e78edd44d659c596010bb8cd8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa698a1c6114d4e838cead88aadd973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f48d378d984300b20567188119f2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bf2bf40e7b94e5788c62e90eb130811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408414e23a3f486f8f1ca8ddcd58571e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59b83da868d64aacb2813ee62aa56592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0b7242250542b3bd24fff37f9b8c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edc9bfb111894241b7743ade8368adc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cc7c21de84f42baa203e7a6cbfd4dcd",
              "IPY_MODEL_8c8ce7cf8338462e90432586090c2546",
              "IPY_MODEL_d95723b737444067bd108b9d98e93730"
            ],
            "layout": "IPY_MODEL_30ab350318e84c0a9946c2335e69c3c9"
          }
        },
        "8cc7c21de84f42baa203e7a6cbfd4dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3e65a266f34760804bc2251ff5f982",
            "placeholder": "​",
            "style": "IPY_MODEL_1e74f90df3724ac994b8b7fcb36ccae5",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "8c8ce7cf8338462e90432586090c2546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046c9b249add4637946e8737e51b8873",
            "max": 3938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34f82ef2f34b46459cc0fd66b2486ecf",
            "value": 3938
          }
        },
        "d95723b737444067bd108b9d98e93730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9c235094cd462980e3493da044942c",
            "placeholder": "​",
            "style": "IPY_MODEL_898aa92f313841f1a5a668a73b342a70",
            "value": " 3938/3938 [02:56&lt;00:00,  3.40s/ examples]"
          }
        },
        "30ab350318e84c0a9946c2335e69c3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3e65a266f34760804bc2251ff5f982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e74f90df3724ac994b8b7fcb36ccae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "046c9b249add4637946e8737e51b8873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34f82ef2f34b46459cc0fd66b2486ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9c235094cd462980e3493da044942c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898aa92f313841f1a5a668a73b342a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3ee0149e064d1a8c546e91aa99d8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04b0b6f18014987a1eb327448d52e00",
              "IPY_MODEL_e194bcae55cb48f680b425ca5dec78f9",
              "IPY_MODEL_19a5b8526e3647619c6394e6171d6061"
            ],
            "layout": "IPY_MODEL_054aeb09d15d4e56a05d24e2bb9bdebb"
          }
        },
        "a04b0b6f18014987a1eb327448d52e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf66265813542a088ec4c0802fba527",
            "placeholder": "​",
            "style": "IPY_MODEL_a3458938928b4a3a870d6adb8aa92982",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "e194bcae55cb48f680b425ca5dec78f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b3722deba44609867fe515213b6cce",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b26c31d96cca4b248fc5f687c3819115",
            "value": 800
          }
        },
        "19a5b8526e3647619c6394e6171d6061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9af07bdf9764d45bb758fd91b93b643",
            "placeholder": "​",
            "style": "IPY_MODEL_fab2854df7ba4574888d6f97b545171e",
            "value": " 800/800 [00:12&lt;00:00, 49.69 examples/s]"
          }
        },
        "054aeb09d15d4e56a05d24e2bb9bdebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf66265813542a088ec4c0802fba527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3458938928b4a3a870d6adb8aa92982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b3722deba44609867fe515213b6cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26c31d96cca4b248fc5f687c3819115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9af07bdf9764d45bb758fd91b93b643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab2854df7ba4574888d6f97b545171e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225c1f91cb1c405a84eb42282a1fed5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_652cfb71336c48ac83069d0126c2d98a",
              "IPY_MODEL_579d5da2cf524faa829462f30d8edc8f",
              "IPY_MODEL_49ea87b042404059a62a4b78de5fe987"
            ],
            "layout": "IPY_MODEL_8500fd266cca4dfdb71773360136fbf8"
          }
        },
        "652cfb71336c48ac83069d0126c2d98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52b0397f846448f88138aadf54245d4",
            "placeholder": "​",
            "style": "IPY_MODEL_f43b3ecb31d64e1cb8b3b7113fd5ff8d",
            "value": "Filter: 100%"
          }
        },
        "579d5da2cf524faa829462f30d8edc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218f39ee38134945b6ed0f237154475e",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bed47b85e2f1445a8f233f4d140ab006",
            "value": 800
          }
        },
        "49ea87b042404059a62a4b78de5fe987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba7c9753e16428d95c64cf451000ac2",
            "placeholder": "​",
            "style": "IPY_MODEL_933d03e0e2d34787ac431aaadcf34744",
            "value": " 800/800 [00:00&lt;00:00, 16478.62 examples/s]"
          }
        },
        "8500fd266cca4dfdb71773360136fbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52b0397f846448f88138aadf54245d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43b3ecb31d64e1cb8b3b7113fd5ff8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218f39ee38134945b6ed0f237154475e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed47b85e2f1445a8f233f4d140ab006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba7c9753e16428d95c64cf451000ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933d03e0e2d34787ac431aaadcf34744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3818e5a00b7f4d77b0a7e91a7cb6ba6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6574f3aa167e4b5fb791455ff8789429",
              "IPY_MODEL_9cba04b8c0734986a8ee9e1be3573da2",
              "IPY_MODEL_c6dad448169d470888ed1f37ec78be9a"
            ],
            "layout": "IPY_MODEL_c1ebebe46d35491a866e7a7a34b7f9ec"
          }
        },
        "6574f3aa167e4b5fb791455ff8789429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566b1fed17164827a967a19d62446262",
            "placeholder": "​",
            "style": "IPY_MODEL_102b1f901b3a4a8c8d4cb3483bc07cc1",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "9cba04b8c0734986a8ee9e1be3573da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a911bca4b4b40f5924db04dd7519d39",
            "max": 786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9a3996898c643c38c803a943decc4f6",
            "value": 786
          }
        },
        "c6dad448169d470888ed1f37ec78be9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d959a491d010482695ba8ac117d6e7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_77ba9fb0314c44ed91835b93a5577e11",
            "value": " 786/786 [00:08&lt;00:00, 140.50 examples/s]"
          }
        },
        "c1ebebe46d35491a866e7a7a34b7f9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566b1fed17164827a967a19d62446262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102b1f901b3a4a8c8d4cb3483bc07cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a911bca4b4b40f5924db04dd7519d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a3996898c643c38c803a943decc4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d959a491d010482695ba8ac117d6e7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ba9fb0314c44ed91835b93a5577e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80bf7c0d05b45b1b061a9e555d2d772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ff16ebcaeb4401aae8fd9fd10d807a0",
              "IPY_MODEL_9b9d18e620994db09fe389d3411d2820",
              "IPY_MODEL_b908ef8c300f496481de5127b838cfaf"
            ],
            "layout": "IPY_MODEL_64100adbcf824998b54afdc5db21c645"
          }
        },
        "4ff16ebcaeb4401aae8fd9fd10d807a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4931815f9a114a908023a22ed7134a07",
            "placeholder": "​",
            "style": "IPY_MODEL_52a2fc382b3845d9a7c82a858b8575a2",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "9b9d18e620994db09fe389d3411d2820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dd6b3080104ad595d4c408d57dae3c",
            "max": 786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8147f2c3087148e99e73d5f1f1965327",
            "value": 786
          }
        },
        "b908ef8c300f496481de5127b838cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf0a40211f4b7996ed41a163b82389",
            "placeholder": "​",
            "style": "IPY_MODEL_7679a1e2a97442568d66d62f3ee15a33",
            "value": " 786/786 [00:34&lt;00:00, 22.37 examples/s]"
          }
        },
        "64100adbcf824998b54afdc5db21c645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4931815f9a114a908023a22ed7134a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a2fc382b3845d9a7c82a858b8575a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dd6b3080104ad595d4c408d57dae3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8147f2c3087148e99e73d5f1f1965327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fdf0a40211f4b7996ed41a163b82389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7679a1e2a97442568d66d62f3ee15a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}