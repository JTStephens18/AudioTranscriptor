{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTStephens18/AudioTranscriptor/blob/main/V9_VisionEncDec_audioProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change log:\n",
        "V9 aims to remove all unnecessary blocks and add comments about the overall code"
      ],
      "metadata": {
        "id": "a5G9UpMlHmnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation / Setup"
      ],
      "metadata": {
        "id": "BqoBQaJTH_iq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmkZlQnjPa1e",
        "outputId": "38bcfca0-8d93-4c99-f559-5e5f45b1e557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2023.11.16)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.19.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (6.0.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[audio]) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[audio]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[audio]) (2023.11.17)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2023.3.post1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->datasets[audio]) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install yt-dlp\n",
        "# Install huggingface audio datasets\n",
        "! pip install datasets[audio]\n",
        "! pip install transformers evaluate jiwer\n",
        "!pip install accelerate -U\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlQ2aruLJOcz",
        "outputId": "3f0d60f5-b74c-4ff9-ce1b-80f49b909dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from datasets import load_dataset, Audio, Dataset, concatenate_datasets\n",
        "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, ASTFeatureExtractor\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import librosa\n",
        "import re\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlVjar3hKBXU",
        "outputId": "613c8b63-f31a-44d0-bafd-f64f6f42ed4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['ytid', 'start_s', 'end_s', 'audioset_positive_labels', 'aspect_list', 'caption', 'author_id', 'is_balanced_subset', 'is_audioset_eval'],\n",
              "    num_rows: 5521\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "ds = load_dataset('google/MusicCaps', split=\"train\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unneccesary data"
      ],
      "metadata": {
        "id": "ieXUZKU1HJMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHy7po4X2o4j"
      },
      "outputs": [],
      "source": [
        "ds = ds.remove_columns([\"author_id\", \"is_balanced_subset\", \"is_audioset_eval\", \"audioset_positive_labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEyz2LDGzea4"
      },
      "source": [
        "# Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# This function removes instances of ' \\ () and [] as they are not necessary\n",
        "# Helps to reduce number of tokens during tokenization\n",
        "def process_aspect_list(example):\n",
        "  newList = []\n",
        "  aspect_list = example[\"aspect_list\"]\n",
        "  for word in word_tokenize(aspect_list):\n",
        "    cleaned_word = re.sub(r'[\\'\\[\\]\\(\\),]', ' ', word)\n",
        "    val = re.findall(r'\\w+|[^\\w\\s]', cleaned_word)\n",
        "    if(len(val) > 0):\n",
        "      newList.append(val[0])\n",
        "  example[\"aspect_list\"] = newList\n",
        "  return example\n",
        "\n",
        "\n",
        "ds = ds.map(\n",
        "    process_aspect_list,\n",
        "    num_proc=4,\n",
        "    writer_batch_size=1000,\n",
        "    keep_in_memory=False,\n",
        ")"
      ],
      "metadata": {
        "id": "6QpwkjLAKB56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell runs through the process of creating the tokens for the words in our dataset"
      ],
      "metadata": {
        "id": "FNzwQK8cID9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o72J0qczjNb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "# vocab_list = [\"word 1\", \"word 2\",  ..., \"word N\"]\n",
        "vocab_list = [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
        "max_len = 0\n",
        "vocab_count = {}\n",
        "maxLenItem = 0\n",
        "\n",
        "# Need to split on punctuation\n",
        "# I see some tokens such as \"funk/pop\" and singing.the - These should be separate\n",
        "\n",
        "def split_word(word):\n",
        "  # Removes brackets, commas, and single quotes from the corpus\n",
        "  word = re.sub(r'[\\'\\[\\]\\(\\),]', '', word)\n",
        "  return re.findall(r'\\w+|[^\\w\\s]', word)\n",
        "\n",
        "\n",
        "for i in range(ds.num_rows):\n",
        "  aspect_list = ds[i][\"aspect_list\"]\n",
        "  # Find maximum length of apsect_list in entire dataset\n",
        "  if(len(aspect_list) > max_len):\n",
        "    max_len = len(aspect_list)+1\n",
        "    maxLenItem = i\n",
        "  # Adds items to the vocab_list and keeps a count of how often that word appears in the dataset\n",
        "  for j in range(len(aspect_list)):\n",
        "    word = aspect_list[j].lower()\n",
        "    if(word) not in vocab_list:\n",
        "      vocab_list.append(word)\n",
        "      vocab_count[word] = 1\n",
        "    else:\n",
        "      vocab_count[word] += 1\n",
        "\n",
        "# Vocab_dict is useful when we have a word and want to find its token value\n",
        "vocab_dict = {}\n",
        "for i in range(len(vocab_list)):\n",
        "  vocab_dict[vocab_list[i]] = i"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "tL9kpscNH-_A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSOqyNR3H6No"
      },
      "outputs": [],
      "source": [
        "ds = ds.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the feature extractor from the AST model from hugging face\n",
        "\n",
        "https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer"
      ],
      "metadata": {
        "id": "JUhNh1p8ILsz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhMuI8fEqYO4",
        "outputId": "a9c184eb-7776-4b7f-dc56-1a733d8c6bc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
              "  \"feature_size\": 1,\n",
              "  \"max_length\": 1024,\n",
              "  \"mean\": -4.2677393,\n",
              "  \"num_mel_bins\": 128,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000,\n",
              "  \"std\": 4.5689974\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "feature_extractor = ASTFeatureExtractor()\n",
        "feature_extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPn0QMQdKtxy"
      },
      "outputs": [],
      "source": [
        "def download_clip(\n",
        "    video_id,\n",
        "    output_filename,\n",
        "    start_time,\n",
        "    end_time,\n",
        "    tmp_dir='/musiccaps',\n",
        "    num_attempts=5,\n",
        "    url_base='https://www.youtube.com/watch?v='\n",
        "):\n",
        "\n",
        "  status = False\n",
        "  command = f\"\"\"\n",
        "        yt-dlp --quiet --no-warnings -x --audio-format wav -f bestaudio -o \"{output_filename}\" --download-sections \"*{start_time}-{end_time}\" {url_base}{video_id} --force-keyframes-at-cuts\n",
        "    \"\"\".strip()\n",
        "  attempts = 0\n",
        "  while True:\n",
        "    try:\n",
        "      output = os.system(command)\n",
        "    except subprocess.CalledProcess.Error as err:\n",
        "      attempts += 1\n",
        "      if attempts == num_attempts:\n",
        "        return status, err.output\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  # Check if video was successfully saved\n",
        "  status = os.path.exists(output_filename)\n",
        "  return status, 'Downloaded'\n",
        "\n",
        "\n",
        "def toUppercase(aspect_list):\n",
        "  a_list = aspect_list[1:-1]\n",
        "  new_list = ''\n",
        "  for word in a_list:\n",
        "    new_list = ''.join(a_list).upper().replace(',', '')\n",
        "    # new_list = new_list.replace(' ', '|')\n",
        "    if(len(new_list) > 128):\n",
        "      new_list = new_list[:128]\n",
        "  return new_list\n",
        "\n",
        "# Convert the words into tokens\n",
        "def tokenizeCaption(caption):\n",
        "  output = [vocab_dict[\"<SOS>\"]]\n",
        "  input = word_tokenize(caption.lower())\n",
        "  for i in range(len(input)):\n",
        "    if(input[i]) in vocab_dict:\n",
        "      index = vocab_dict[input[i]]\n",
        "      output.append(index)\n",
        "    else:\n",
        "      output.append(vocab_dict['<UNK>'])\n",
        "  output.append(vocab_dict[\"<EOS>\"])\n",
        "  return output\n",
        "\n",
        "\n",
        "def tokenizeAspectList(aspect_list):\n",
        "  output = [vocab_dict[\"<SOS>\"]]\n",
        "  for i in range(len(aspect_list)):\n",
        "    if(aspect_list[i] in vocab_dict):\n",
        "      index = vocab_dict[aspect_list[i]]\n",
        "      output.append(index)\n",
        "    else:\n",
        "      output.append(vocab_dict[\"<UNK>\"])\n",
        "  output.append(vocab_dict[\"<EOS>\"])\n",
        "  return output\n",
        "\n",
        "\n",
        "def process(example):\n",
        "  output_path = str(data_dir / f\"{example['ytid']}.wav\")\n",
        "  status = True\n",
        "  # aspect_string = toUppercase(example['aspect_list'])\n",
        "  if not os.path.exists(output_path):\n",
        "    status = False\n",
        "    status, log = download_clip(\n",
        "        example['ytid'],\n",
        "        output_path,\n",
        "        example['start_s'],\n",
        "        example['end_s'],\n",
        "    )\n",
        "\n",
        "  # example[\"tokenizedCaption\"] = tokenizeCaption(example[\"caption\"])\n",
        "  example[\"tokenizedAspectList\"] = tokenizeAspectList(example[\"aspect_list\"])\n",
        "  example[\"audio\"] = output_path\n",
        "  example['download_status'] = status\n",
        "  if(example[\"ytid\"] == \"qsRPTMXFGsA\"):\n",
        "    example[\"download_status\"] = False\n",
        "  example[\"image_path\"] = f'./spectrograms/{example[\"ytid\"]}.png'\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqRSt4Waay0g"
      },
      "outputs": [],
      "source": [
        "def stereo_to_mono(wav):\n",
        "  chan_1 = wav[0][:]\n",
        "  chan_2 = wav[1][:]\n",
        "  mono = (chan_1 + chan_2) / 2\n",
        "  return mono"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNaBNcfVULd6"
      },
      "outputs": [],
      "source": [
        "def resample_waveform(example):\n",
        "  filepath = example[\"audio\"]\n",
        "  y, sr = librosa.load(filepath, sr=16000)\n",
        "  sf.write(filepath, y, sr)\n",
        "  waveform, sampling_rate = torchaudio.load(filepath)\n",
        "  if(waveform.shape[0] == 2):\n",
        "    waveform = stereo_to_mono(waveform)\n",
        "\n",
        "  example[\"waveform\"] = waveform\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDN_72fZqp7x"
      },
      "outputs": [],
      "source": [
        "def wavToInput(example):\n",
        "  wav = np.asarray(example[\"waveform\"])\n",
        "  inputs = feature_extractor(wav, sampling_rate=sampling_rate, padding=\"max_length\", return_tensors=\"pt\").input_values\n",
        "  example[\"input_values\"] = inputs\n",
        "  example[\"inputs_shape\"] = inputs.shape\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "caf864f927bb4dfd9a920af784e6279a",
            "c820ef37e37f46ae97f8f8c7835d6155",
            "6ce05079f751444e858fdec3490c643d",
            "f10c7b8c53434b149a738349e2db4f83",
            "efbd27fbeb2743e5959f922766f7af1d",
            "9afc25d4ce5947d5a6d9a18efb1867f5",
            "6ab758d6094b48f0bc16c97d0f51bdd1",
            "c9796c68ea3b48f8ab531dd95da9248b",
            "d8600763699148a7ba75cb5bf452760e",
            "15a9eaedc8404c5ab058991e29755084",
            "eebc759d45fc4ee0adb0c909a666256d",
            "fbe5e88f46814addb420127fba3e1a72",
            "98882b6be26d4adb984b780f18b42475",
            "cbcdddb134184651878d4095e86f568a",
            "0b3a52a94e964d3d88cd3f4af589ec32",
            "8cb19431548240c6aef34ee2f7b727d9",
            "f51160fe4f0f4428a849ae2f45cdeb6f",
            "4e50c217fc9a4593ad1a4b13d3cd6520",
            "39f7e377db9d402589c0b62459eeb6f8",
            "a4e0be3a213144b28c49e5bf8bfb3cea",
            "0414bc80ce8843089e4cb2703c148d4c",
            "92f8854f16fa4aa589e5cca56519e17e",
            "bfefceaa9a994572bc75f13848d17e34",
            "1b182fdc6fb142e99a3e1c68e64a85c6",
            "0a12a718706941388f4648d6f253aff2",
            "dc91bd5090d146b1898283e57504f417",
            "79e43e78edd44d659c596010bb8cd8cf",
            "dfa698a1c6114d4e838cead88aadd973",
            "50f48d378d984300b20567188119f2a7",
            "0bf2bf40e7b94e5788c62e90eb130811",
            "408414e23a3f486f8f1ca8ddcd58571e",
            "59b83da868d64aacb2813ee62aa56592",
            "5d0b7242250542b3bd24fff37f9b8c0f",
            "edc9bfb111894241b7743ade8368adc4",
            "8cc7c21de84f42baa203e7a6cbfd4dcd",
            "8c8ce7cf8338462e90432586090c2546",
            "d95723b737444067bd108b9d98e93730",
            "30ab350318e84c0a9946c2335e69c3c9",
            "2d3e65a266f34760804bc2251ff5f982",
            "1e74f90df3724ac994b8b7fcb36ccae5",
            "046c9b249add4637946e8737e51b8873",
            "34f82ef2f34b46459cc0fd66b2486ecf",
            "6b9c235094cd462980e3493da044942c",
            "898aa92f313841f1a5a668a73b342a70",
            "1c3ee0149e064d1a8c546e91aa99d8af",
            "a04b0b6f18014987a1eb327448d52e00",
            "e194bcae55cb48f680b425ca5dec78f9",
            "19a5b8526e3647619c6394e6171d6061",
            "054aeb09d15d4e56a05d24e2bb9bdebb",
            "8cf66265813542a088ec4c0802fba527",
            "a3458938928b4a3a870d6adb8aa92982",
            "d3b3722deba44609867fe515213b6cce",
            "b26c31d96cca4b248fc5f687c3819115",
            "e9af07bdf9764d45bb758fd91b93b643",
            "fab2854df7ba4574888d6f97b545171e",
            "225c1f91cb1c405a84eb42282a1fed5b",
            "652cfb71336c48ac83069d0126c2d98a",
            "579d5da2cf524faa829462f30d8edc8f",
            "49ea87b042404059a62a4b78de5fe987",
            "8500fd266cca4dfdb71773360136fbf8",
            "d52b0397f846448f88138aadf54245d4",
            "f43b3ecb31d64e1cb8b3b7113fd5ff8d",
            "218f39ee38134945b6ed0f237154475e",
            "bed47b85e2f1445a8f233f4d140ab006",
            "9ba7c9753e16428d95c64cf451000ac2",
            "933d03e0e2d34787ac431aaadcf34744",
            "3818e5a00b7f4d77b0a7e91a7cb6ba6b",
            "6574f3aa167e4b5fb791455ff8789429",
            "9cba04b8c0734986a8ee9e1be3573da2",
            "c6dad448169d470888ed1f37ec78be9a",
            "c1ebebe46d35491a866e7a7a34b7f9ec",
            "566b1fed17164827a967a19d62446262",
            "102b1f901b3a4a8c8d4cb3483bc07cc1",
            "9a911bca4b4b40f5924db04dd7519d39",
            "e9a3996898c643c38c803a943decc4f6",
            "d959a491d010482695ba8ac117d6e7ca",
            "77ba9fb0314c44ed91835b93a5577e11",
            "c80bf7c0d05b45b1b061a9e555d2d772",
            "4ff16ebcaeb4401aae8fd9fd10d807a0",
            "9b9d18e620994db09fe389d3411d2820",
            "b908ef8c300f496481de5127b838cfaf",
            "64100adbcf824998b54afdc5db21c645",
            "4931815f9a114a908023a22ed7134a07",
            "52a2fc382b3845d9a7c82a858b8575a2",
            "42dd6b3080104ad595d4c408d57dae3c",
            "8147f2c3087148e99e73d5f1f1965327",
            "2fdf0a40211f4b7996ed41a163b82389",
            "7679a1e2a97442568d66d62f3ee15a33"
          ]
        },
        "id": "VhNDVeTr8hzw",
        "outputId": "33f038f8-68df-483f-8469-f40046032332"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caf864f927bb4dfd9a920af784e6279a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe5e88f46814addb420127fba3e1a72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/3938 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfefceaa9a994572bc75f13848d17e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/3938 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edc9bfb111894241b7743ade8368adc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c3ee0149e064d1a8c546e91aa99d8af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "225c1f91cb1c405a84eb42282a1fed5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/786 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3818e5a00b7f4d77b0a7e91a7cb6ba6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/786 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c80bf7c0d05b45b1b061a9e555d2d772"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "samples_to_load = 4000\n",
        "cores = 4\n",
        "sampling_rate = 16000\n",
        "writer_batch_size = 1000\n",
        "data_dir = \"./music_data\"\n",
        "upper_limit = 5521\n",
        "lower_limit = 5000\n",
        "\n",
        "data_dir = Path(data_dir)\n",
        "data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "ds_train = ds[\"train\"].select(range(samples_to_load))\n",
        "ds_test = ds[\"test\"].select(range(int(samples_to_load*0.2)))\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    process,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_train = ds_train.filter(lambda ex: ex[\"download_status\"] == True)\n",
        "ds_train = ds_train.map(\n",
        "    resample_waveform,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    wavToInput,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    process,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")\n",
        "\n",
        "ds_test = ds_test.filter(lambda ex: ex[\"download_status\"] == True)\n",
        "ds_test = ds_test.map(resample_waveform, num_proc=cores, writer_batch_size=writer_batch_size, keep_in_memory=False)\n",
        "ds_test = ds_test.map(\n",
        "    wavToInput,\n",
        "    num_proc=cores,\n",
        "    writer_batch_size=writer_batch_size,\n",
        "    keep_in_memory=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rqo2cIFX5lG"
      },
      "source": [
        "# AST Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvhRQoviwiWJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "model = AutoModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWwJ3RU__7Kj"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "    super().__init__()\n",
        "\n",
        "    assert hid_dim % n_heads == 0\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.head_dim = hid_dim // n_heads\n",
        "\n",
        "    self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "  def forward(self, query, key, value, mask = None):\n",
        "\n",
        "    batch_size = query.shape[0]\n",
        "\n",
        "    # query = [batch_size, query len, hid_dim]\n",
        "    # key = [batch_size, key len, hid_dim]\n",
        "    # value = [batch_size, value len, hid_dim]\n",
        "\n",
        "    Q = self.fc_q(query)\n",
        "    K = self.fc_k(query)\n",
        "    V = self.fc_v(query)\n",
        "\n",
        "    # Q = [batch_size, query len, hid_dim]\n",
        "    # K = [batch_size, key len, hid_dim]\n",
        "    # V = [batch_size, value len, hid_dim]\n",
        "\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
        "\n",
        "    # Q = [batch_size, n heads, query len, hid_dim]\n",
        "    # K = [batch_size, n heads, key len, hid_dim]\n",
        "    # V = [batch_size, n heads, value len, hid_dim]\n",
        "\n",
        "    energy = torch.matmul(Q, K.permute(0,1,3,2)) / self.scale\n",
        "\n",
        "    # energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "    # attention = [batch_size, n_heads, query len, key len]\n",
        "\n",
        "    x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "    # x = [batch_size, n_heads, query len, head_dim]\n",
        "\n",
        "    x = x.permute(0,2,1,3).contiguous()\n",
        "\n",
        "    # x = [batch_size, query len, n_heads, head_dim]\n",
        "\n",
        "    x = x.view(batch_size, -1, self.hid_dim)\n",
        "\n",
        "    # x = [batch_size, query len, hid dim]\n",
        "\n",
        "    x = self.fc_o(x)\n",
        "\n",
        "    # x = [batch_size, query len, hid dim]\n",
        "\n",
        "    return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd5W3ysr1jXt"
      },
      "source": [
        "# Transformer Decoder Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LwFv1dG2sWx"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.attention = nn.MultiheadAttention(embed_size, heads).to(device)\n",
        "    # self.attention = MultiHeadAttentionLayer(embed_size, heads, dropout, device)\n",
        "    self.norm1 = nn.LayerNorm(embed_size)\n",
        "    self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_size, forward_expansion*embed_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(forward_expansion*embed_size, embed_size)\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, value, key, query, mask):\n",
        "    # attention, _ = self.attention(query, key, value, mask)\n",
        "    # Shouldn't need a mask to ignore padding on inputs since padding is not needed for inputs\n",
        "    attention, _ = self.attention(query, key, value)\n",
        "\n",
        "    x = self.dropout(self.norm1(attention + query))\n",
        "    forward = self.feed_forward(x)\n",
        "    out = self.dropout(self.norm2(forward + x))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMgAofOR6IgS"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads, forward_expansion, dropout, device, max_length):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = nn.MultiheadAttention(embed_size, heads).to(device)\n",
        "    # self.attention = MultiHeadAttentionLayer(embed_size, heads, dropout, device)\n",
        "    self.norm = nn.LayerNorm(embed_size)\n",
        "    self.transformer_block = TransformerBlock(\n",
        "        embed_size, heads, dropout, forward_expansion\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    # self.feed_forward = nn.Sequential(\n",
        "    #     # Target shape[1] to forward_expansion*embed_size\n",
        "    #     nn.Linear(max_length, forward_expansion*embed_size),\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Linear(forward_expansion*embed_size, max_length)\n",
        "    # )\n",
        "\n",
        "  def forward(self, x, value, key, src_mask, trg_mask):\n",
        "    # A feed forward connection adds other parameters so there is an additional case to learn if needed\n",
        "    # x = self.feed_forward(x)\n",
        "    attention, _ = self.attention(x, x, x, trg_mask)\n",
        "    query = self.dropout(self.norm(attention + x))\n",
        "    # query = self.norm(x + self.dropout(attention))\n",
        "    out = self.transformer_block(value, key, query, src_mask)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER1XVfzI4Ev6"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.device = device\n",
        "    self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
        "    self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "    # self.position_embedding = nn.Parameter(torch.randn(max_length, embed_size))\n",
        "\n",
        "    self.layers = nn.ModuleList(\n",
        "        [DecoderBlock(embed_size, heads, forward_expansion, dropout, device, max_length)\n",
        "        for _  in range(num_layers)]\n",
        "    )\n",
        "\n",
        "    self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([embed_size])).to(device)\n",
        "\n",
        "  def forward(self, x, enc_out, src_mask, trg_mask):\n",
        "    N, seq_length = x.shape\n",
        "    pos = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "    # x = self.dropout(self.word_embedding(x) + self.position_embedding(pos))\n",
        "    x = self.dropout((self.word_embedding(x) * self.scale) + self.position_embedding(pos))\n",
        "    # positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
        "    # positions = position_embedding[:seq_length]\n",
        "    # x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
        "    # x = self.dropout((self.word_embedding(x) + self.position_embedding[:seq_length]))\n",
        "\n",
        "    for layer in self.layers:\n",
        "      # x = [N, seq_length, embed_size]\n",
        "      x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
        "\n",
        "    out = self.fc_out(x)\n",
        "    # out = self.softmax(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWubbuB28DSs"
      },
      "outputs": [],
      "source": [
        "class Instantiate(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Instantiate, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRqHc7vX-dUT"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "src_vocab_size = 1024 # max_length of feature extractor - not even used\n",
        "trg_vocab_size = len(vocab_list)\n",
        "embed_size = 768\n",
        "num_layers = 12\n",
        "heads = 12\n",
        "forward_expansion = 4\n",
        "dropout = 0.1\n",
        "device = device\n",
        "max_length = max_len\n",
        "\n",
        "src_pad_idx = 2\n",
        "trg_pad_idx = 2\n",
        "\n",
        "num_epochs = 20\n",
        "# Number of training samples in the batch\n",
        "batch_size = 4\n",
        "learning_rate = 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDSVpVZU77fC"
      },
      "outputs": [],
      "source": [
        "model.layernorm = Instantiate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTohuA8MGet_"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,\n",
        "               src_vocab_size,\n",
        "               trg_vocab_size,\n",
        "               src_pad_idx,\n",
        "               trg_pad_idx,\n",
        "               model,\n",
        "               embed_size=768,\n",
        "               num_layers=12,\n",
        "               heads=12,\n",
        "               forward_expansion=4,\n",
        "               dropout=0,\n",
        "               device=device,\n",
        "               max_length=max_len,\n",
        "              ):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = model\n",
        "    self.decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length)\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "# Src mask is used so the encoder does not pay attention to the padding values appended to the input\n",
        "  def make_src_mask(self, src):\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # (N, 1, 1, src_length)\n",
        "    return src_mask.to(self.device)\n",
        "\n",
        "  def make_trg_mask(self, trg):\n",
        "    N, trg_len= trg.shape\n",
        "    # trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
        "    #     N, 1, trg_len, trg_len\n",
        "    # )\n",
        "    trg_mask = torch.tril(torch.ones(trg_len, N))\n",
        "    return trg_mask.to(self.device)\n",
        "\n",
        "\n",
        "  def make_trg_mask_custom_attention(self, trg):\n",
        "    # trg  = [batch_size, trg_len]\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # trg_pad_mask = [batch_size, 1, 1, trg_len]\n",
        "\n",
        "    trg_len = trg.shape[1]\n",
        "\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
        "\n",
        "    # trg_sub_mask = [trg_len, trg_len]\n",
        "\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "    #trg_mask = [batch_size, 1, trg len, trg len]\n",
        "\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    # trg_mask = nn.Transformer.generate_square_subsequent_mask(max_length)\n",
        "\n",
        "    enc_src = self.encoder(src)\n",
        "    enc_out = enc_src[\"pooler_output\"].unsqueeze(1).expand(-1, trg.shape[1], -1)\n",
        "    out = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVR5fildVPoW"
      },
      "outputs": [],
      "source": [
        "newModel = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, model).to(device)\n",
        "optimizer = torch.optim.Adam(newModel.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21BNuiE94yjM"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab_dict[\"<PAD>\"])\n",
        "optimizer = torch.optim.Adam(newModel.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYt99TCvRG3P"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "  def __init__(self, pad_idx, eos_idx):\n",
        "    super(CustomLoss, self).__init__()\n",
        "    self.cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=vocab_dict[\"<PAD>\"])\n",
        "    self.pad_idx = pad_idx\n",
        "    self.eos_idx = eos_idx\n",
        "\n",
        "  def forward(self, logits, targets):\n",
        "     # Calculate standard cross-entropy loss\n",
        "    ce_loss = self.cross_entropy_loss(logits, targets)\n",
        "\n",
        "    # Penalize extra tokens beyond first occurence of <EOS>\n",
        "    eos_positions = (targets == self.eos_idx).nonzero()\n",
        "    if(eos_positions.numel() > 0):\n",
        "      # Only consider the first occurence of <EOS>\n",
        "      first_eos_pos = eos_positions[0, :]\n",
        "\n",
        "      # Count tokens beyond the first <EOS> position\n",
        "      if first_eos_pos.dim() > 0:\n",
        "        # extra_tokens = torch.clamp(first_eos_pos - logits.size(1), min=0)\n",
        "        extra_tokens = max(first_eos_pos - logits.size(1), 0)\n",
        "      else:\n",
        "        extra_tokens = 0\n",
        "\n",
        "      penalty_weight = 0.1\n",
        "\n",
        "      # Add penalty term to loss\n",
        "      extra_tokens_penalty = penalty_weight * extra_tokens\n",
        "      total_loss = ce_loss + extra_tokens_penalty\n",
        "    else:\n",
        "      total_loss = ce_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "pad_idx = 2\n",
        "eos_idx = 1\n",
        "custom_loss = CustomLoss(pad_idx, eos_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczqsAkDEcw1",
        "outputId": "2850f637-e813-49ed-d6ac-0dcf004e37de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18432 ['cY3g6N5Sokk', 'feC0L9MtghM', '-Umconw-CRE', 'A6HJBIU1rD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18433 ['YE2rN3xknlk', 'B_kAtTBUDIA', 'EkmHGd0U8yE', 'BVt8RgNrwbQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18434 ['A5fPSkTvjmY', 'PlQibWaPAcM', 'ymuRKv9iJm4', 'LAHWV6fZwUk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18435 ['X-uVubaJ3II', '244y56-vLWE', 'nU7x170OvJ4', 'paeNnR33i5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18436 ['cG1dpyC8gV4', 'n3X8RGZsGg4', 'sDoV3sMgDhE', 'lSb7Y-_3to8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18437 ['iqEQBCrOLWc', 'XYOnq7ju7o0', '8jDanS4ZzRc', '-0vPFx-wRRI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18438 ['-1UWSisR2zo', 'EGIeykrN4eg', '8Ha5qGnT7lg', 'sYIymaJi6tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18439 ['Tt3BnoJw8ds', '9K8EePrEDdo', 'iUxy2s5d60o', '-VI2IRq17rs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18440 ['7JE2eBK1f9M', 'hRbukCd6N68', 'WmyhSRhWh3k', 'OEjgIDubFbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18441 ['Ca3b8qNUbsk', 'TnJE6W6Z6mM', 'N_LKZjw9DLk', 'U4UtZeTl2DE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18442 ['nqcVA89BD6I', 'SEHE3WGui30', 'xrqDoBor2dk', 'c9JyKnsegog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18443 ['rLQ93N6RJC0', 'BBmXMoI9Qus', 'pte5jvRKwsA', 'uTfLf1Y8hhM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18444 ['1ACn3u5UnBw', 'T9dKp1EN4p8', 'VDYqYuPzW8E', 'ohikUtjUN7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18445 ['OoyxPPoPmt0', 'K9zE9x2ccJk', 'NwA9JSlK_lM', 'n179cK8EubU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18446 ['GUwBLItoJXk', 'cJ80eZY03Yg', 'WditOomsdRU', '9Y8NR6nDxjk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18447 ['vmVOWilkmOA', 'BquHBzP5Ep0', '4TDtUHo5cSE', 'KUE_I30--AY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18448 ['KdNhYvN4Xoo', 'JOhK7oq9KtU', '7_80oVTLkGU', 'iYWvaxU5OXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18449 ['C7WAx3n57Hk', 'jBmP7xTI_TA', '4Gow6qZcNZI', 'iUHqyjf3NcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18450 ['9YnYlDFKn-U', 'zYM0gtd_PRo', '-4NLarMj4xU', '1SO5RJLWKAs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18451 ['qaQjG9SwORU', '7AC9RqECN5k', 'gTX4SG70cEY', '-hSMzrWZCAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18452 ['2vQTq4QLP8U', 'yfZ0z1C3blk', 'sfmAeijj5cM', '28wBrNjHXOM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18453 ['zWJC_qr2610', 'DTkKGYCRMlc', 'OzaVvthCvtk', 'YAYp2E5vMNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18454 ['UQKLBsZJsww', 'UxT3KG4AHAI', 'echeYDYFhlY', '4QES-SJ7mP0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18455 ['ZM0imDMXuw8', 'SEDfsU63w8I', 'tUZB_Xf1m6k', 'YcWJUHWt-64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18456 ['GWcMqKYOJR4', 'xzgnLpKkvdg', 'qW4kBJsudLI', 'L5UDz2PJ9sk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18457 ['_78P-0zWJtg', 'BEZdszHKGTQ', 'n_boIyhZqWc', 'HwGK5RvNOFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18458 ['RDNatVYvpeA', 'YNoR-SR5t1s', 'w9EGDo9Yybc', '6lPgzqrvHHw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18459 ['L0oun9F67tg', 'e2tZmQI8ICw', 'hBT0bbJl1dU', 'TA-O_bVnvLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18460 ['WMtztIW1f6k', 'QUB_vpjogmo', 'AzWIKyRnhG8', 'GG6XkHATIyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18461 ['Ns-iXXKmzzU', 'l5QPXVIxxwk', 'Wu-Oh9OJIlI', 'MfX7Q0ucts8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18462 ['l0fCHZhKEDA', 'aO0QzRPiEC4', '3sIlpn9nvKU', '6YXjJ6ABnZU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18463 ['zdtVT2xwrHU', '3EXXs3x4Ius', 'DC0C-KO9EJk', 'Lc6OfmzV7Pk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18464 ['54yI3In3DrU', 'LSaLPObrnZw', 'RdKQGIzKZ_c', 'L9GXrmmlYhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18465 ['CxTFgimfNfA', 'grisjVTZeTk', '1JqNiV03kog', 'BL181hSAG60']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18466 ['9gkppwB5CXA', 'RFKTlhbnfXA', 'SUclDZHax0w', 'B_ohqOgK6T8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18467 ['xUVvBF9BWdg', '6-CMq6xw0fg', 'hlHb9HwNxk8', '-qcTD2o6I9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18468 ['j-TVVmVmygg', 'D3FyfFIKLVc', 'KLFoZA8btu4', 'TCRxCAYyduo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18469 ['-YATTKBtmRA', 'XdBf_omYIO4', 'kdxW11WBlQE', 'HQb2jhmw1BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18470 ['_u2cNlW5DxQ', 'hTlIqICkbW8', '3OLeJZF4oI0', 'TPYNIc_M1ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18471 ['2z1elo4ucis', 'KoAGZ_dB8MM', 'ikEuQPSBY-0', 'Pgpd1yxLcLI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18472 ['HY1KdNS19CM', 'j0FynYzQvcM', 'oGbNzR_lpSk', 'MHkfPjW0aRg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18473 ['YW4AKwkpYxs', 'yO7MWuJ7zLA', 'hrCf8rMBtA8', 'c6Fiz5IznkU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18474 ['lNg2y6SRZPo', 'WCiS9IDILQg', 'G7pD1K3jYg4', 'ATDi-irUEWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18475 ['h-3DrDQC62k', 'R5KBk76b9HE', 'YxkYVsE0UdQ', 'AVVfOYSmexM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18476 ['67S7s_jFXhc', 'lYtoy8sa-Q0', 'GwxSvUoYSZg', 'cOgNXgF21u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18477 ['19-GI2LzOtc', 'Qz2PIXM60iE', 'B-1QW7g81gA', 'Gow0TlxIx7U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18478 ['4gEmWJCPZGo', 'sgJT5lIFttM', 'CM2rKZmcR0I', 'bTlp5Qr99RY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18479 ['2zrPFxxT1VM', 'Xm2ciX0_UP8', '2IpapScfsT4', 'Y8ULUSXWTcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18480 ['ksYM8YzzWXo', 's3Q8pVDY7ZI', 'fU9woCZqemw', 'KDzy3ZL626U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18481 ['F2ekiX14ID4', 'M-RX7LqL50A', '2qO-OQtOBK0', '6cQjwXNY4sc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18482 ['9kt7rsziUVQ', 'XUzaEsoOlWQ', 't8uF3PZ3KGQ', 'EZAwPnGOJPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18483 ['nBSMh7pgn2o', 'aWK9CcvOK9w', 'gkMbHlNAFig', 'bqeVxA97TQU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18484 ['15CZ2h5VL-A', 'BdhaR2QUGqY', 'A2NtJ12KIuU', 'lV0-LMVpZLg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18485 ['ql7aH8wF6JM', '2y1QnNBaxAU', 'LK6zk03lPlM', 'mQ1E8rx2dnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18486 ['qtnE1hnCD0M', 'eISYX9koocM', 'CD3OyaDW348', 'B00nfVc4FPI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18487 ['AmAThmRphk0', 'tmabzx6yxqs', 'qeoYWM1uYPI', 'R5JRh08zgMo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18488 ['_KYo_89lgf0', 'nnc6m1pBJ4c', 'Fa1KdG8niq0', 'smU92Nu0FmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18489 ['eUZ-v8GEcNk', 'UR3k09hOxI4', 'C6m_OWe-JE4', 'hwSOjoHFLn4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18490 ['evG8CQRCdV8', 'FFQVVwFjy7s', '0oIFGARD9xE', 'CZuH43NPynA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18491 ['frqnZb8Ssjo', 'gCSShNsw-_A', 'BsLFQV8HVZE', 'hvmCuosF0Xo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.7434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18492 ['qcjzfHmQvxg', '0a6uLBmqZgA', 'fAfk9yrGhWw', '5pIdH6p3kuo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18493 ['WTVC7ZI9WtY', 'O28kY0aN8VI', 'Q2Omtt4A8ls', 'VHyXvbg6y9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18494 ['Inuq5W98ktA', 'XjoRxeEyjz4', 'mRKud6yP4iU', '8pYHLfKqHL4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18495 ['91Qp8XUskXo', '6nWWTNVRDjw', '23xC7lTBikU', 'GuHDy--gWiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18496 ['fXhN3_gGpQw', '3e6GleQ9sl0', 'S8WTaKLpmmg', '7RtQpW2dSU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18497 ['4Mm5mBgktG0', 'A_oaLt-n4fQ', 't7oAteGa55g', '6jdeSAmkzEU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18498 ['kMK10SknFAI', '3bg0iy-ypcw', 'R6k2BkwZt1Y', 'UO9HtZMrbBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18499 ['yBYd03Hr2kQ', 'YddV91xnUz4', 'O2HttJtcec4', 'R6lRMU-zBLA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18500 ['VSf3_XpiPkQ', 'FXVu-YwjhxM', 'nY4tpb8O_Rg', 'VlXi2TxMXbc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18501 ['AzhfZ8rNhRk', 'pKFXFu8st9I', 'HyJ2YaNrA3U', 'Brc_nOquNbY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18502 ['65KYS3lIRII', 'UhcoWyEQwBI', 'd-KxsdWX9xE', 't3758pixHZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18503 ['1xhwyUVSRQk', 'svNayU6q3Dg', 'HFVM5pVTwkM', '9ZeoYezrI7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18504 ['5xAzHL8Zlcs', '3sRO6iwfUxo', 'ihJT65fZaHY', '0a91szM1Ivw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18505 ['XWhmLbnrtd0', 'fhWzjWZqzvs', '2juYRZnhF3g', 'ZVMIk3xYaYo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18506 ['NSyqj1DXZKg', 'UinQGYfmZhE', 'pcOPueObfWs', 'f7OQTtTdgrA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18507 ['3TQmts_MxyQ', 'RS43EP1EXz4', 'lfCWGQ6URds', '-wymN80CiYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18508 ['4jzr88nEdCM', 'u3n2OcpEC48', 'UEOUXjX5R2I', 'mqyeBqaUeN8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18509 ['entThp930cw', 'BsVsoZ4ojp0', 'QqRrZzOY2xw', 'UxrAsZ7Z09Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18510 ['0hfU27A6tus', '1RhYdQnZ_hw', 'DYp8940tHso', 'zTuxNA1y6Os']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18511 ['UOC4VWQpnDM', '4M0njWKFsME', 'tMMjurLqYJQ', 'vnwKpQeza3A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18512 ['IiBgER0W8iA', 'dzW5M4sCphI', 'p2fXNAPYD20', 'Ux3YosKD-9I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18513 ['Vx4aO4-nr0c', 'gEYTdeQiFv8', 'I368EWBLIs4', '9aE33JEIGOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18514 ['VuWr1HXHoZg', 'mMf4vJFT8Fw', 'thHSYzhoLo4', 'woyCm7d2UIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18515 ['CdFutCUKTXI', 'fUC45bzOOJw', 'O5IulN0n6d0', 'SSVlD_ZDb70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18516 ['YFhbrSUb0JQ', '8MbxazeMw2E', '4CrPPlHN9_s', 'Pf9AaTV4-yw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.7092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18517 ['1ypKEH2kd7g', 'W7KbboEOmeM', 'ODRAYQE9GXs', 'b12xqPnM0So']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18518 ['ua0hgl8fi0I', '5qVc9y3TNnY', 'NdiSW-p2I0c', '-BIMKnb3tlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18519 ['vBkDLBO-Aok', '-T4GeTHKtJQ', 'tUBTRs7Avk0', 'oBBTqXQFTiA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18520 ['8hO1S9VIfPY', 'p4T1pddBia0', 'Y02VBGoTi9w', 'x1S2oreZBWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18521 ['Zmtw8tP-KFo', 'IhNPDueFVSo', 'I-Z3gB6pfIA', 'qtNTHnXOQew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18522 ['IC_Wpalzzm8', 'IcPbxJRbe5g', 'bxF2vxTzlvo', 'p2yedR_jMTU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18523 ['qDiTICmdUQg', '4LZSSya3ZZQ', '7avMUhHOCR8', 'e1KHGfMekek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18524 ['4ueN2gGsH5Y', '1FnT0RrfMEA', 'TZlFTbvfKPE', 'u6tgeRXOxnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18525 ['AVuh8-CucrE', 'w3QIsHxQfPE', 's1eMgmzCMDM', 'Xxe6vTEwFvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.8902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18526 ['FXQxobF8FWw', 'J7d3nuS9wqg', 'OwukabRF7I4', 'W2EJai-3k2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18527 ['P5IxlG4-CY8', 'OiAJB9uydS8', 'HTQySJM4Jhg', 'u0CgRmXMXNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18528 ['ikJKSqnTylI', 'uJPW9BEhU6Y', 'mJuJfKbcJcw', 'D_QEW1Lnl2Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18529 ['I5CBPhpimtg', '58f4AsxOYhU', 'lRTeWmoeen4', 'ZFg6KpT5ehU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18530 ['Pm6vRblouxc', 'xseL3oZc7pY', 'ZahBai58_Ec', 'PE1ges9nn6A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18531 ['m9MQdg0k1t0', 'RoDS0k7qrIo', 'QtjMlA_7dds', 'bTuKGXDrqdQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.8073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18532 ['pIE-3sIPlvY', '3tlaELkmRqs', 'iTWZsfVCyBs', 'N_Wx35sNqdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18533 ['d352jaSSiFw', 'FkpJaXzgMBQ', 'macnXLRXbHU', 'q-sJu8CoZts']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18534 ['sbOBTkrivXM', 'nvvXOfLs-ng', '-m9pH0WXQto', 'F1X7egd8Us0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18535 ['MMGAKKhqxKg', '8Z5xnSxUmGE', '1LA64TXatWk', 'oynXCFZWxnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18536 ['E6B81rrUlnE', '2Ui85-AOLyo', 'xx1RccwlF5g', 'zj2G-KVw4N4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18537 ['4q-eGdrqiIw', 'yPou7kokTgA', 'RFNRR78dh-8', 'chw8sAKOM5k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18538 ['lymmNwQA0WA', 'Vo6eT8eMMfQ', 'YqZNMFyPJOQ', 'P97w3AdePgQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18539 ['3zntWbS9XeI', 'UY2_Q830lqo', 'Wu3LKQG1fwU', '4b8gTARnmVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18540 ['7FHzw4HV75Y', 'y6NS77HLjEE', 'qfVIeq7s6tw', 'dO3VsX4rKNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18541 ['HOIIp5NyFx0', 'bAJrcYJgllE', 'sxMYFYDNF_g', 'f8QGA4vN6HY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18542 ['X7LrhZX4rdU', '1BVSYfNCcv0', 'TkHZdMJPwKc', 'hVPQu1UJ2N8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18543 ['4Yc71_dU3m4', 'weJKl-6TiDQ', '2CzfBZ1mYBs', '9ZWmZdgrE78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18544 ['iQ7qeIrssds', 'IJcLW4arT6s', 's25X6KwBpxw', 'BN6W6OQnVoE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18545 ['QCbUlDMu7Hk', 'MdsRmMxkF4k', 'yaUK4XvVGTg', 'TiDdR-6bIcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18546 ['VzHL56yq8bI', 'vx5iuWuE2Ng', '4l441DdEJfU', '1rhsnmWLeGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18547 ['VswY2mI7Wbo', 'jHEBYrI8zHE', 'FsnRM2irjvI', 'ZqnbgQeeRbM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18548 ['APSbmhJam74', '6L8066DGqcA', 'q7s7C4oNlFo', '6Q5N1DfzGj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18549 ['c-85TtcfVSI', '5r4jLwjj_Ik', 'sUh43prJYMM', 'YvFY7xU2kGk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18550 ['Hxf1seOpijE', 'oVhhEku6ECA', '50QEapyTPD4', 'kSdH9z8snac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18551 ['-mB_XLq6g1g', 'wwHi10qX8u8', 'N8Fg3L1Cc5E', '3b3s0TvjGwA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18552 ['5ZX1-GAb7IM', 'lIBsL97sUmY', 'AiGGDpbgp6I', 'b2XAPiRUoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18553 ['cTJqIkSuf6s', 'xGHN0kphhWM', 'xhOsZuB_Zqc', 'JC41M7RPSec']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18554 ['UsdoUjuczY4', 'n7yLkcSfiuM', 'OR_YbeqV5tA', '_qf0UiKtB3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18555 ['cqolOXDF86g', '7TmKzUgWiRU', 'MNlzpCwdh4g', 'Xaq-segSEsQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18556 ['GcbCOmNiVm8', 'HLsRePLObfI', '_Ra1Y6K7nSs', 'knQuxZj9rTA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18557 ['tEdeb9eSKDI', '669Fk7afszw', 'tOb0M2k3deo', 'ba5xPgcHN_0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18558 ['vf3n40mDLHw', 't-CMJ6RsZzY', 'ALcCb2HJmG8', 'UrgzGbGVV8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18559 ['7dmT4SgS_EM', 'dW4eW0Xreik', 'I0q3IGmTkRo', 'U-L9YCIdLbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18560 ['HRxTN4TH-80', '9iYxf1hS4Yk', '4i1aizhCnfg', 'vhTWW5Bx15Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18561 ['vrNQbCbBlLY', '6CaZAITdAsk', '-ZHpNr_KRXU', '6QAZJ4H_5rA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18562 ['KyRJP_fDrbk', 'ppAT0f2YCyM', 'stobfk1Mfjk', 'm0FhT3UnXjA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18563 ['x85BtdoxRek', 'GmGWvBNO8JI', 'M0ygCD6WyXw', 'FiKY19GK6-8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18564 ['colnyHv9CAA', 'bKS_m7JObxg', 'vEN9szBPBkw', 'nB2Lf5TTmBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18565 ['6pHo6fPdPvM', 'd20qTsF6ll8', 'dUhE6H72Qpg', 'LaaC_q3QDUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18566 ['evy2azZk3kE', 'KXuB62SMFvA', 'zYUZEXCE7gw', 'hhohfEC82JI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18567 ['rez5KDmIZoc', 'xSDkn9PtQm0', 'dj-DWiV1z9g', 'Hnk45Z0EAxg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18568 ['2kcSUBkFbaQ', 'oYEzy8gH6q8', 'LzSWdj4izHM', 'g0WLA0BKxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18569 ['qp4Ubx7WOAQ', 'C0sSgrr5xrQ', '-FEPOSP7ay0', 'yG1bzzXDIak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18570 ['6TSluKI0X54', '9x7jWb4lE7c', 'dwSj0Rr3vFc', 'zopos1B6Elc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18571 ['k4ttuqKjiw0', 'Yj7YyxKyXPU', 'r_KdRKquXsM', 'qHRRWdWvjxI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18572 ['1SqihV_DnEg', 'efTVnvwI2PQ', '89eBh_Djflw', '74p3DLeDCHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18573 ['e6lTl9JIW5Y', 'c-8SLUH5pp4', '5tNOauvQWQQ', 'bYwoYjbPm-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18574 ['05JAmKFVy44', 'bNW18IztiZY', 'XjrVSk0_4vc', 'HEhogaw0vUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18575 ['EzP7PB2x670', '9JlifkCmUOk', 'IGAzIIZRczw', 'uSZQGP_i3gs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18576 ['JsHTGDW5dgw', 'X6Q53uXgaHc', '78S8DnvLQDY', 'K5ilD6nEJ-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18577 ['mtapmFDmImA', 'DG5d4megH8g', 'OPimGlHcSRQ', 'tvcJENqxr1c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18578 ['S0W_zIUYwrE', 'emDU4QvdwVk', 'nvBPPOzcW-A', 'GiTmjE7az74']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18579 ['RFbWkL818XQ', '7eZTmLV9gcY', 'YyYEzAY2e2I', 'lbB2VQYIMo0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18580 ['c7IL4fDqs_I', 'OJuVsBojdvo', 'FvQgVl5IBHw', 'rizanOQM61k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18581 ['_KaRkSyELy4', '02Qntw26enM', 'N4eMppEnPE0', 'DvOA0K-DIFM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18582 ['6BitLl5Bnxw', 'VG6-MlmCgzI', '6II4JGJDyZo', 'YeIXmKPyTVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18583 ['tdrz4EkIsow', 'ASgLbz48BaY', '5xBfKiQcMZQ', '7EvLwfwRrqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18584 ['QrJVAHIkpCo', '2UY_-oF1vqo', '5fPxUI0Fl-4', '64auWicQqZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18585 ['pvxx3aokwCU', '4KqSdK5KM-I', 'nSinUcyFFqg', 'oKab6-syQD4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18586 ['BYwS1dJRTi0', 'tFVvupXoRoM', 'qRgefptkDeo', 'wIP7AqIOU1s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18587 ['UzDVZzIIcy8', 'Z0O2r0Dl2T4', 'UOAv5b6MGxw', 'L9j9fCHHPeg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18588 ['cfeTMVWFHLo', 'nj6N7m8SeK4', '0nk7utNkHOY', 'Q7oWXOByo28']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18589 ['7lV4IvuW2lk', 'Th6Tf6kA8RU', '45iNSkfzOwM', '6iyinlZEgS4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18590 ['76ON0Ixrr9s', '2nsZhXxes68', 'mU6cfEWw5Og', 'RtXe5T7NFrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18591 ['RiqtelZs_2I', '3ZhyXbwFQAM', 'NVo-stvk_QE', 'ylKvglDzBU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18592 ['MWS-Uxf1MRw', '_5w5TVK5B90', 'XYQnMxWnetY', 'uT-S_JC_GzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18593 ['c9h4p6325Xo', 'MwE7REVj8JQ', '-M-6VinyMiY', 'o8FsD7l5er4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18594 ['l3pK8prEnrQ', 'rkQPSAHNoeI', 'K_G_k1WTdoc', 'nqd7mXvHupU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18595 ['J8pkQfYlJA4', 'ba3QPheW8mI', 'A6ilKRqIDH4', '6KXd7l5pThg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18596 ['IUjzBX2Qm4k', 'qlWEAm4AUTU', 'EY8boPZ1hPs', 'DQrdOgRb-oA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18597 ['8zGJ9N7c6pE', 'b-7oO1Rw-fo', 'pWZqzEpygE0', 'zR4ebAuqy8w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18598 ['4_s5vHgfxnw', 'MsjeOXuUYG4', 'N-dzfI3L5ic', 'J1-Qvl7u2TI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18599 ['lXrypwLQO3U', 'qRCjs90-1RQ', '4mtfOkzOvBI', 'A8P5zzHCjJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18600 ['6UJhTZgnVro', 'CIoEXRnAr-Y', 'zx_vcwOsDO4', 'WYxXUBP_XaM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18601 ['YB28WMv7wUE', 'DRU-IFx-7yQ', 'cYSW6Y884dA', 'f1_YKSYgtbI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18602 ['2ShO1jZYZeA', '0u1sk49gAU0', 'u9n4R78UBtA', 'VCrnnx9jTqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18603 ['dEc7tV30KJo', '3zPvfVmL0nE', 'r9AxQfXYLEs', 'XOsHEjo-RSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18604 ['9jeEfi6nDak', '9PQZSLa_A8A', 'BjAL68IMlp0', 'vtVfl5Ff5lw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18605 ['Y_eh6C0EBP8', 'Zq92ED3IvLQ', '4cg3MsrvJqw', 'RQbNC1J4Jfk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18606 ['38R9Vnwt890', '3Wdxjm-h36w', 'WcC9sKxJ1gI', 'wDpz90boBzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18607 ['-mA_bqD1tgU', 'GQz_u0Vc8Os', 'Sj5MQtqDw8Y', 'nSBDyxxscks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18608 ['hRQJgZVxRX0', 't6jlx6jAb-Q', 'RceCfg1FQq4', 'XILyHZyyCik']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18609 ['-EVRXQpt1-8', 'YLlbLSNxdQ4', 'H-bTMbePj0A', 'pqsU95TNNP8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18610 ['-ByoSbgzr4M', 'O3Cvn4yXrao', 'VV85n-ebuUU', 'Al_OdIuqoe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18611 ['msnm_tYXcYw', 'kjmmzA6i5rk', 'KzydTOkZty8', 'lYJAqOpp6RM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18612 ['lTOzGIOIfq0', 'XfdySM4X9Xo', 'r1W1z_31Obw', '92k_81uqMSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18613 ['C25xvcl4YAU', 'RXGDlFry3Vo', 'C8Euv69GR3U', 'nP05Sf4Fgac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18614 ['gFxLnprPgv4', 'eAFKjP7o1as', 'zd3lShuZNmU', 'Ubj0jlheyvk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18615 ['vxIF3B4YqW8', 'XcvY-NdM8WA', 'DyPmDDN8m78', '1ZaxqZMs21M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18616 ['B8pesuUc8Ek', '1PN-bfs2EhY', 'ZmgkpmzvL6c', '682ODyTqKyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18617 ['5JQIsqc8HBc', 'nbIwdOQ7D8A', 'jcZQhxb5lyw', 'KJHqQ5aKu8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18618 ['i3zayf6Hiog', 'qdWTfyysMN8', '6F8qv0JBWkE', 'LRUdmYcXFuM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.5003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18619 ['VSAbMy1Rlio', '0S5zWt91Bwo', 'UDS6PrY9ZIM', '-7B9tPuIP-w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18620 ['xVi1wNljxjk', 'AZsupJ68Hp0', 'DA8lw6Mq0DY', 'QRKc90kuAaE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18621 ['rh0vBy1JD8A', 'rNUtYf6EdW8', 'qXgSlhWbWLU', 'kMmjr8deHis']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18622 ['hTNKYJ6suII', 'ryEXhKy1QUI', 'I1fcUe9MoMw', 'uXMMzpgrY2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18623 ['5jT_i7S9QSM', 'DQ_gcdLhAsY', 'PB3i02Cjf1k', 'pKDnn0CBIe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18624 ['qDSvHlHbAqM', 'hYlSisv-VRU', 'L2-EGNKzUAQ', 'B3lq6U4PDZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18625 ['Iz611KubW70', 'LR3U4b_fVBc', '-m5ZlWziIeA', 'UJA5AWbt6HM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18626 ['cHGziT0hrZU', 'ABVYSaLu_VM', 'yHd5DzIbWL8', 'kbCh5HrmgN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18627 ['99ZgIQwLC60', '3OWArQGgmm0', 'wFTlySgdWX4', 'W2KaBnoGxek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18628 ['PJRG2bwphUc', 'TqWmuwAYmnI', '3ZyuBJEbmJM', 'E2gstPe3Im4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18629 ['aVNcweinmEM', '8KIoQ2HZ0Hg', 'TWV3YLscSaw', 'C3Jhu77uffQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18630 ['PTLOLz9YzmM', 'kkjNpwNcMWI', '0EzWmAPwoTs', 'fyLctn3jNUs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18631 ['Xus0LI3QV2A', '1Xtkou9dtyA', 'aBEiuYSSEH0', 'm-eyGzf9Ux4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18632 ['D_usHKfOXCw', 'pyumNmhV4_s', 'R3urUtvSgkU', 'MyjxrBI9k4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18633 ['NlUf1ppoSG4', 'P240GHf9Eq4', 'JYYfw3id3ek', 'KDuusOmEMHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.8190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18634 ['ZVvX2-ldhvY', 'eZE0RmJESFU', 's5wdG7xbTNg', 'dztizAgcQ08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18635 ['ZUcHBeueBww', '0H3FAoDgzhI', 'QpX9dSCFxRI', 'kjn6I3AurgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18636 ['9ZryMX2UtAo', 'B4lGhVjoMTk', 'O40E8bpmONQ', 'Js_3Aa214xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18637 ['qwI32Si0ipE', 'AnErEDywInE', 'JUrYWttZJBM', '2SenLjPbGzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18638 ['BRTHyoVgZT0', 'WIVu5PapmX4', 'fHNAxa0QaOM', 'lBtAULJAFp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18639 ['MvnC1TfNiPY', 'CJjyrDGmxIY', 'mBG-st0VUXs', 'aUH12rRIVDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18640 ['OoRUo92emGo', 'fD1xB9lDbPQ', 'Npbs_4DZgEQ', 'VRfi64fecj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18641 ['ySY5J3TDgag', 'nv1hWkBbG0g', 'HtCkwxfAmzw', 'P-eIhvCaK-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18642 ['qni67aUJbw4', 'Nt0U-CXK6O0', 'jFek2xLbEww', 'I-C14nCneBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.9251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18643 ['uYCAxX2F6DA', 'Qe_KwKVDgoE', 'I_wT76iYBdQ', 'MpjN21Z93JY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18644 ['O0y-m0pCi5E', '-o0ZtQIkM60', 'GNjsxLdSwHI', 'P4aTFrJws40']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18645 ['6807299U5eg', 'iHYOaGNdweo', 'OMApGp219Zc', 'AaajkQEU3A0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18646 ['7LlnLjZOqVI', 'EIzBD62ja8E', 'BfMKdrK9D8M', 'aURLQXt_6fE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18647 ['BkoCi-IZccI', '2SQxfaWAJJg', 'lBSS2AbA560', 'Euu6zlJQSD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18648 ['h7DOBV43UPQ', 'NsYVaRI6rXg', 'x9bcsYF_by8', 'DVuWm53IlVw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18649 ['Z-Vb1Ay-zNA', '1y1lEOGBcWM', 'J9ZlahUawkg', 'IqGB4nQIAcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18650 ['GYCfrx0ruz4', '2I6pPRWKsCQ', 'H4tyvJJzSDk', 's59pQGs7Q3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18651 ['QQTWFTNy-WA', 'tKawN2sxhYc', 'fvhbI-7e89s', 'hSK405L-DlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18652 ['qMd2DTyF9EE', 'bHNdoIWxXDk', 'HMQfp_qtF-M', 'A446kjocnCg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18653 ['yeu6OEIKwws', 'vTXb8P7sAFY', 'V9jIsOTC1lY', '7OjXHfVoI64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18654 ['3gh1oldZ7Zc', '2wZCoeq9Ppc', 'AgtY6m-b3Gk', 'ura8EjHjGC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18655 ['R0b3pU4AKNc', 'oC0e8GXYy_4', '2uvHgwAljPA', 'JI26wmUPcrM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18656 ['t-yy7v7P0IE', '3C-5_z01Olc', '0M7nETLOsKQ', 'yuWjB3XA8tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18657 ['1QSD-dzEv7Y', '_GxqvILlmAw', 'R_HAtyDbw1M', '8Nrp4jUZeGE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18658 ['PP3kNqPM434', 'XI9CNsX6JSE', '3tbFP_JKzXw', 'Rwt8j_USbWI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.6336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18659 ['_miAGxDX5FM', 'st92BzeUzFU', '4lcZkOMhKv8', 'Zz1Bz1a7yPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18660 ['raM8Lp0aGCk', '49nqh7uI9fw', 'ANaaOqwO0Uo', 'SlnjJv305Vg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18661 ['IjP5kKfgBiI', '9Cfs00bZRCg', 'ApDJYsi9UGg', 's1QeDT7jqHQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18662 ['XPGtOugQ69U', '7YWMPBHKdyY', '9Ijpv6e57a4', 'xR2p3UED4VU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18663 ['C0eCERYt4bA', 'R77XPtKgvy4', 'WJIrkvEq4EI', 'hqQvatf1RUY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18664 ['6zgvEiJJrM8', 'e4R2O7XpIXU', 'PwmXO0J-PAA', '1JwoLPCIGhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18665 ['0zolXzR9Oi4', 'zeUEOxTd8IE', 'JPZlyvPNZj4', 'G2uCAwYS6w0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18666 ['1lgqqW5TsJk', 'UHvYrO1IGCc', '3nbB3F-OdSM', 'AFWy1qyyMHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18667 ['jlIbJVfnHB4', 'gMgN50wSnNc', 'd9r_kYpOvW8', 'PRRcVdXsBQg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18668 ['ORikRIu7s1o', 's6U8DtBK3Us', '_yXtw_z2xf4', 'BXcEsM8ykhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18669 ['YIhfk4Zaevk', 'CpHRQ-f4UtA', 'RDW_kz4SXo0', 'aCTm1TcL7z8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18670 ['RtgHU1UMo5o', '4T2KBwRxi_g', 'GFJNgqcX7u0', 'uAYPacrJnyQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18671 ['-1LrH01Ei1w', 'vd1dgdxlA94', '2xGRCsW6-Bk', 'NqDxpJ2uR_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18672 ['BsnjK6DypAg', 'DYpjbiyPUho', 'UNJswfXKJ3s', 'Z9hnLYpypCU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18673 ['UfEGX0rNOvA', '6C0HoQe4Y-Y', 'oFCzd9bJo9A', 'qVdBBOpSoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18674 ['oD0Xp--xxjE', 'LEG7xkYOsWA', 'LM2C1eIUX9M', 'CyiPyjYX6AE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18675 ['EKZvq0dUk50', 'TzPuAqjoL80', 'p9nbp0Oo1U0', 'ZJZxWLYzNh8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18676 ['sC7T0sEG6ek', 'wwbATvWFaLY', 'rUIGOcQMaSE', 'Rf7vygfb7w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18677 ['xZukWGb52BI', '7vC1iriZlX8', '2ZYzviKuq9w', 'si_IAMPOXlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18678 ['Cwbtn_h6TP8', '_y07ENAx2_E', '3TO4C7SiC7I', 'uF1KTW5rT-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18679 ['-7wUQP6G5EQ', 'tpamd6BKYU4', 'uYYpqx0rzok', 'EPvnkbo5wrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18680 ['AJw-x30L46E', '5P5XAclO8ko', 'AwcuLXAPFDs', 'pHzjKCj9INw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18681 ['2gc1L3g1itU', 'RI126_DmGLQ', 'gNpzuFPu6q8', 'PF5LgwJjYuA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18682 ['qsFfUzErXqw', 'dBAeAk7dXnU', 'RI71ebbU0PQ', '2zpITTJiw7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18683 ['Mp1MHSeHa0o', 'Qz8hNRg-7G0', 'UeYmnV-B8so', 'vK9x7UQ9Y7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18684 ['PqTTIfja0y8', 'xxCnmao8FAs', 'F5zDEHggiMg', '1W2Cz2Jj76Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18685 ['W_MZo88gzrA', '07FxCXxknY4', 'aUx0xMF9pwU', 'je96vkMY60c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18686 ['tIRHm8VhK_4', 'YpOHemscGCk', 'z7vNtEcM9Bk', '2_kLD3IbF2c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18687 ['5rsQHo-6DI4', '08mf5GxT820', 'darQBSIlol8', 'IN71kMOAk_k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18688 ['1l7BjFDQLUM', 'eWNERam16Hg', 'aeDZVfGk7bk', 'QKkhwAAGLIE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18689 ['vOU-qA25xNM', 'too9MtXBwts', 'OKZF0oG1E14', 'D8-x1T8M4gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18690 ['I-xPuRe9vF0', 'eyFBIA_HOmE', '3VEMHWnewuc', 'rccs9c1gteQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18691 ['16TsDMjHzYU', 'rOOBAGxxjBk', 'mq_b6QKVsuc', 'MC0Aeu7RLSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18692 ['F9LJIyqQFe8', '2ctgUIqyaBk', 'ZU6sI1Plq50', 'h2f_CKjQQg8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18693 ['YZH-PZBir3E', 'KkW6ZkmAlEw', 'KmBaE7ozWow', 'THfTLXBLpJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18694 ['gAURHUoIK0M', 'OheHnFixwVk', 'navn7jCBp_o', 'dLUobee5JEs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18695 ['QIzSxE0WlKE', 'nYO8n62Piys', 'MROotmz8a-U', 'qknDM3pcoD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Step 18696\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18696 ['x1x54MgStxQ', 'mQM3Fd3eN9E', 'ZsmfIMEzrQs', 'WaddbqEQ1NE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.7003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18697 ['qFrvkOOR2HQ', 'jZi0VVWt72E', '06Brdf83RZE', 'p1DNl8BF49U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18698 ['fZjQBgPD1Ys', 'Ve6Zy1BXBbY', 'Occ4uW0lw0k', 'UC_XpUcIQ_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18699 ['Kd7aHdOwh0I', 'nzdlPYd8XUs', '2x9735gU01s', '_qP21HqOmA0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18700 ['HIDXdH6R6T8', 'D712KM8PE3I', 'qET3h3w35EA', 'V0zQHNmz0gU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18701 ['3OUNEL8XaR0', 'H6qzijVEqZQ', 'tv14XEQcY0c', 'HvuHSr_yncE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18702 ['u3yOMK8SuRI', 'AobHGHJSd-s', 'Zon9WGTwAME', 'ZX2fVPmUidA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18703 ['m-NM_tIWjxs', 'MVYSWTF11Nc', 'hgJK2ZDgWtU', '5NCUtndrsHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18704 ['Ou2rEaq28PM', '5h5NdW6cYY0', 'UUJ1DNycpiQ', '4zZiWBp0b08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18705 ['40xkia7fwEM', 'kp5OxEzxuSg', 'B9ME0Vcm_xA', 'sZwZ2fOWWSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18706 ['v9TTtjEngjY', 'IL1n6jzABVw', 'FCzMqo8kh1o', 'XRQyoAk-Qz0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18707 ['Hn46VuvS88Y', 'Lhw0H3P4zUE', 'eBF0zRHCbZE', '2YAyM0aHFRU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18708 ['XDBxMQrRaFY', 'I06TOd9pXng', 'Wdtku1dqJo0', 'DsAp3b1poeA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18709 ['CYZZIkEw_jY', 'WT2iyJmKkc8', 'AFwmMFq_xlc', 'qlqJF5yPmUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18710 ['etmmUjsRNRs', 'AeXDtbfpQlQ', '60OIHit4Q-M', 'NC5tIv4-8fg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18711 ['cS2gRhH6it4', 'hZfCziBaGTI', 'QT1SjY9mQxc', 'wMelBK3yArA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18712 ['mQWht9mv7sE', 'sVF7NNvdoJc', 'IISJXKl1Ih4', 'IwdjPDw6o5I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18713 ['eStzDzEopDI', 'TworrkXAPuI', 'VlwbDjggUKk', '1bSP4wLfMpA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18714 ['Q8X6geEBR2o', 'yrme-KRBvzk', '2i4UNf8tjvU', 'EUmfsCvmkgo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18715 ['PfpP3WjY118', 'jhsce15byHc', 'gwBfZJ5IGOA', '9UD7qz7DuVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 11])\n",
            "Loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18716 ['_cg_IfaD1C0', 'yYpfb_xV--4', '-VclCul6FrI', 'AgJH6Ul1EFg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18717 ['x1KyLxsnJY0', 'MwK9HYjeeN0', 'X96v9LlsjJM', 'Ux1vBolJf5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18718 ['XM4hxyK-Ddo', 'YODoF8e7Jlk', 'cs-zcTX2tRA', 'CdgQIiMdBa4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18719 ['J2BDMndrvhA', 'oNqBsQiNoAU', 'KqtlecvEOGw', '1kYDbl5Y9Sg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18720 ['pdIAN6lMXSU', 'j-93krRXAaY', 'Rdwtr2IX8ek', 'd1VB1vA-UsI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18721 ['BUDb8YieUgU', '2unse6chkMU', '9uToez74x_M', 'Ha-FS_CHmGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18722 ['zcc7dJIY7uc', 'A8CJ4YSsUgs', '9HQNvz4eZPU', 'BUzsQ6WohH4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18723 ['4ls_8xIjBzM', 'iFSaNmZyPQo', 'av-1Ih0S82s', '3QNFY4MKTy4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18724 ['8GKbDSu9Xd0', 'kVuG_F3qCuY', 'B4KIQtk7fT4', 'BWvKAcOV_co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18725 ['lpHa-S_x1LA', 'V1M3HiUz0ZQ', 'b1j-hD9zs6Q', 'xxNroISqkt4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18726 ['MX0wS7MX3Zo', 'Wd4T3iTsgrI', 'r0I-G70gyo0', 'YErpnsceZw8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18727 ['p20KE0LhL68', 'QSaX7QfeWog', '6VJ_auuKzss', '_zQTlTCqMzs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18728 ['saEDf6EV9wg', 'j8z9a9A8LV4', 'ce03XKuyDtk', '4T_5clu_0OM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18729 ['1a_nvi4sW64', '4Lk8pUeLCwQ', 'HVA9-fjtv6U', 'QXe9BpTENCc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18730 ['v8bBrrXUpdo', 'PWVr9weg00U', '0Q1JLNfm8oU', 'FsCQmTluSDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18731 ['yZNgqVInQGw', 'B1ixRtiUJ-U', 'jP4M9V_Ka8k', 'F3uf_RleI3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18732 ['b9yT3nGcD_I', '3PuzzYmTDA4', 'INBx8CrIWcg', 'sp77ueBkqS0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18733 ['id5ibIqjRto', 'n615BjoN7fI', '6N1LWG4aztA', 'IizUHzmcPGA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18734 ['jOkHEMsCCFc', 'HkXSX7Kdhms', 'dPM24O4my-Q', 'qOSdHmfwLF4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18735 ['BDH7Fx1APR8', 'EHm7vLZewS0', 'bZuXMxR2S4U', 'rY9zjr9T_WI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18736 ['7lG2zPKo9e4', 'E4a3s8NRqUM', '_RLsXrr0fQo', 'U3TpCc2zHrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18737 ['d2gHgzfC-Oo', '2WxUIkF2zEw', '1OIfQHKnAcw', '20Vh6z6Ie0E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18738 ['8Yt55huZGZc', 'S48GsFznk50', 'CGYflJRiLt0', 'kpsYSXR1wao']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18739 ['JKbUVdMJAO8', 'rnuGOQ-aSjs', 'DKBbLySEGic', '9NJEKpPeWpE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18740 ['Zlbo8ygfPSM', 'N0q5vPAsHLI', 'ILE12hEW5Ck', 'mpikDeSk-mM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18741 ['0u5-WiBKam8', 'Wvh59Y4OzUM', 'jjg0TCq3wbY', 'DGON0D8E17Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18742 ['MzUgHy7SyS8', 'LnczSOwV9Ds', 'cu0k3Uclp1I', '26jTWRMRoxY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18743 ['FYux89o7Hhk', '6XZGmRuaOfo', 'BqIZipifARo', 'PmiH7RnCkhI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18744 ['YNdexakUGOo', 'XscNEv9tX5U', 'LadgIxZu8Oc', '4kZ0EZg5JRU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18745 ['cMhajmOBr0c', 'Qw468qlDaAE', '6ieXDFjLKNo', '5gh5H0QqJl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18746 ['O6xMQnKJROc', 'YNv7mzbUUHc', 'Kt2MwCHV3Ko', 'pn6toTLXAck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18747 ['fSJ4qAPHaVM', '3YuO2UOYKRk', 'PBMfPDei93s', 'Q789S_9JCio']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18748 ['eQTK2fo3RoE', 'XmMN-6g1L8w', 'W_979HkE4EI', '05OJDYeHLMc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18749 ['lSbCqHZy_l4', 'ynWPvcGXFrM', '40i3_JH6FYw', '1jATjKL2vAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18750 ['D3q_stCeCA8', 'YGWweVRzFrw', 'qwOLhVbuhpM', 'cGUhG5PZp0A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.5686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18751 ['kh6rmFg3U4k', 'GFbSHWBjuuQ', 'Weu8nsJRMqE', 'tllFsEPv7Ls']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18752 ['_m-N4i-ge28', '3-_QS346VWo', '9QwaP-cvdeU', 'Du3Q6NdsSso']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18753 ['ZkGQhIbEDrs', 'laVgKAcv8XA', 'ChqJYrmQIN4', 'fRpJfrfjoZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18754 ['FteW_2gNtD4', 'F8MCOgWhgvY', 'G2JDDwIuNrQ', 'C3s-DmHtDUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18755 ['nlWXsfjHeA8', 'GQPOpFX20Gw', '0RpkkfkUBRU', 'C6-JxDWYJ-A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18756 ['hm0SeoNSGkc', 'kSKXtXXAD70', 'AEyeITzfPa0', 'Ki7Bxz1CThI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18757 ['iHXUaVWi7kE', '3cEQfNZ_F1w', 'LTG-uVV_6q0', '7zP5kNyDn88']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18758 ['xe9vDoF8TQM', 'CSzMTqkLHyg', '4tF0Lt9VEp8', 'maeSHVZX8xc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18759 ['EyO5vB4eqo0', 'SFHoTmcgw8E', 'rmKh9uaikTU', 'pWHkmo9Kn8g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18760 ['pzpg2-jYu6k', 'gp1DYuoQH08', 'KWpsFxRTGkI', 'V7RPmwxyhBA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18761 ['xvryKn-V-JM', 'Tp8PG2xae8c', '7fVfG0DrLjI', 'G22YfD5xxMU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18762 ['UcNVLU-cRNg', 'II1oyaWPiD0', 'I_kUf7vgVNM', 'CWKBzt-v8w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18763 ['hM88FG1_D5Q', 'qxWVr67g6yY', 'agw-ujSdX0A', 'JPVRBbdykSw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18764 ['yreWOyWr6Uk', '07xGXxIHOL4', 'wcLPCMoy5hk', 'hkWOAj09_dY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18765 ['L_fWnna7Np0', 'XxKlsW4H0qo', 'yQN9gj7Vk0w', 'jZkHpNnXLB0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18766 ['fw_cFbj9eHQ', 'Dg8BLvkzdr0', 'RmyyW-TMkVc', 'AsR5us-IS00']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18767 ['nc6h6rC3wdk', 'GuJdy864xWM', 'lh6ACdwNlyk', 'w0A-4EbkVz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18768 ['bZJoTauRldE', 'Phy-_ko0zWU', 'RPuCtUVfntk', 'NmMJgUo19Gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18769 ['HQ9HlWProm0', '28pkN4m1x6I', '68DacKw1hlE', '4q6e_ZDFOZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18770 ['blsYgo-B1k8', 'L1s-oPHsOac', 'TEoDtxjlctA', 'LbPRGDwlfqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.7747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18771 ['Simd4JoehW8', 'BfUoopDpmmY', 'clefr8E-iZQ', '8r1y_Bz4VfQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18772 ['qEGNzCWQdqo', 'BscoQHJrNm8', 'P4zWSoib5BU', 'FoFMRXlNJ6Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18773 ['Mhvgz5AjV3U', 'ieEPKa3HiGo', '6dFCMXNlmzQ', 'v1EDTMRmJlY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18774 ['fWypK9RHJJI', '40sAH2ZB0Pg', 'Wnl0qbVynL4', '_6C2ffY_-mc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18775 ['Di7Rs4QmYKI', '9QYo50tFm6w', 'DaeJYtWgcoI', 'k9w2aaNKenE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18776 ['Ycid0vBwqUg', 'MlnK2sa7mm4', 'EijTwCm-pRM', '6og50XOZeIk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18777 ['8WPG0dD20lg', 'UkqayNnk00w', 'KeSbjmMeyrY', 'iuNpXisjsLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18778 ['3uz_ZrGsIaA', 'Vr7wbGcvFts', 'Sl9ZkYViEIs', 'XEIP1OUXU8E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18779 ['LKUYtvUHn0Y', 'o1E579RL33w', 'vWM2qG-nU-Y', 'P0vjXnnIiR4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18780 ['t-L_PuzR67U', 'Bx3nzrmGXhw', 'hlbjpc48Vrs', 'k3A5xX8yfig']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.7133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18781 ['oZScu7DU5qk', 'yesyhQkYrQM', 'ZE0f_S44O7M', '8q0An6WY7_c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18782 ['F7JllgnefSI', 'aC3IBcRNyro', 'JIoA1KsfioQ', '1j13NdQiw8c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18783 ['2Gja9wBkz6U', '5UXnulANF8g', 'lnnlghshsVo', '5w3s2T0VBug']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18784 ['DlVgHV1UobM', 'aRGAnD12qdw', 'eiFyXXqd9Rk', 'rTBQmP6Vt0g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18785 ['fer_4HvG3aY', 'qVgVh9t_7ac', 'dsU3B0W3TMs', 'bTVl2GeNfqI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18786 ['br4A2uNud50', 'mLaon9oK1OA', '0JbGxIR8JTk', 'NsR60ehkHGA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18787 ['G9gsCU85c8k', '-r2-9oyIzkQ', 'ZfSlWX1C8yY', 'CaCjiFUL6Fg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18788 ['YDBxdZchOuM', '5D4siJjh1j0', 'vvfs2TUj-D4', 'b9rgWct9ivI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18789 ['8zDbEfC6Uf0', '6lPw0wKu7_M', '4QJktFv916o', 'Tsmx6Pb7CnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18790 ['zXxJymYt8Z4', 'mvZLlJpyDyc', 'MIexFfOsuJs', 'vEMNk-lbGTE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18791 ['xIbSUwO43Ig', 'Xf0aZ3a3Toc', 'u1a5eyk-9ig', 'pOZWVSiRwv4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18792 ['t5RqDGLiDvo', '7pdrGzdWMzI', '-NmjCyqIavI', 'sEGxoHiAPiQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18793 ['Akg1n9IWSrw', '0NTzOtVmoiU', 'EoZH1gyRlr4', 'PfO7ZVdzfZ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18794 ['IJw2o_Yg00Q', 'rGgvqyHKI4Y', 'k_ET0i2y0Ow', 'wPmTJWybq_E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18795 ['pSt8NwXyDlg', 'mlpTCec4igo', '7h6nTyP7d9o', 'yRWndZvIAHc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18796 ['iBh37YAaHMU', '0bP2MH3LqvI', 'hmkPWxTIwwU', 'y5I5pq0bXmg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18797 ['FCvs17jk10A', '4EwWBI-tHLk', '4PGzlwvXMnE', 'A4jSRfZ6yd0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18798 ['ou3LJpAM4mk', '2Q20hVyYjBM', '5JRvGMTjEzQ', 'tWByqbOvYQE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18799 ['YcfGSJB1YvQ', 'iVBNoH6XgW4', 'JvqCsVj0I4k', 'PaQGXIh94uc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18800 ['SwdhfGXkMCo', '3otUlQ4wvLY', 'JU6GUqRqbtI', 'AVogdV8khxc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18801 ['OI7S7vaBT4I', 'HplcVmJhuIc', 'Vy00ycBpqpc', 'Ur8O3h8S0K4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18802 ['jlmCu2GMoG4', 'uQTCfT5XDzQ', 'oT6ud0OdR_E', 'KgMD2_Yhw7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18803 ['q7U8p-m8J3s', 'maZ3b5w6xVI', 'JxwRvkjNJQ0', '03frQGyrgQ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18804 ['Qa-Qs9CtOOw', 'PvHKu1XRSJ0', 'Zs3arUuPciY', 'MVBQrBAXgw4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18805 ['fEHsR679g1M', '_G3lYKAITu8', 'EUNTykrvpok', '-eDAoheZrY8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18806 ['70pyoqX0U9Y', '8NIxqHJrL68', 'JLYb7DwCaQU', 'uGQ7QnKqeY4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18807 ['_IP6zlayY7k', 'HXwX9f9ugZ4', '-wVWjl9Kq6U', 'GyxH8ep_Vx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18808 ['F5e-SEICJP4', '5bsUYmXIgMA', 'sGVzzQLcT0U', 'kOREaTKeyZw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18809 ['vG0QJ3bjfqk', 'C5Zs-Lb2rIM', '6oqbYipROOs', 'TcoRmHHHNgI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18810 ['Uo-Okq1D8Xo', 'BkOfrw3c3EE', '7NtM1MM76s0', 'itgeNVRhBKs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18811 ['7ZXz3Xa7APs', '8qeTEfOqB0A', 'ccsgja0XsWE', '52odOK7G2kg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18812 ['q7sK_xrJz-k', '0EOQco76eXQ', 'FGZ0sLt4dXA', 'PQrYV7hJWDg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18813 ['kbAMGp-TKJo', '6jeq5lP5Up0', 'Lg1HG6D_0Qk', 'eayGg2OlHOw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18814 ['ihCl2ImrOYE', 'T2zoWLYzEpo', 't8SLY7xn7Sc', 'yIFP8fkq8GU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18815 ['eCyMTN6Hg5k', 'nZmhIHZINL8', 'WCl93HBuj60', '2gvyOxKuQPY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18816 ['LAeWwMC2EaI', 'KbDLu4VozGg', 'PF6Mn51Nkvs', 'hVVrl9FkKnY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18817 ['8MKemM0h5mE', 'hUcuXIvDN2E', 'j6O_U9EseKQ', '3QqVP0odOw4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18818 ['iLIBaMceZQc', 'yNIZaqTHUnc', '7J6U-HE3Lko', 'nzpnWuk3RjU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18819 ['ZsmxO0wnqdQ', 'WtN6uiDikRM', 'KSye2ifWZ_Y', 'XscK8V4Veac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18820 ['x9xXU30ktcY', '0ISHZQJdeSw', 'o2bqT0ZTz7E', 'xVab_CbwecE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18821 ['5rjQU4vOIlw', 'kZYBpOwNGZU', 'fpdgtpBOh-c', 'fjxD32KIHgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18822 ['cQWJeYfyw8Y', 'BaMBwXQwK3g', 'OyouRYAq-tE', 'tvqvuGywD8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18823 ['bm5IT7e2vvI', 'uUoEB3DBSjo', '31iD2VPLMxQ', 'dNQh2iLVAoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18824 ['apA0IY_5-2g', '-f1DNyngKVY', 'pHj8U-3RHc4', '7qaRlUc4fb0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18825 ['90NsBZvepy0', 'TJyzBaMwXFY', 'kvIt_9P79Ro', 'kR2yBlL6nFU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18826 ['40vmsGsFBsw', 'QZNrK337wow', '5KvjUzQbMT4', 'i8bt6Mb0rUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18827 ['HMJe5jS0Yt4', 'JqmOqYtQqB8', 'jD0nqkyuHPg', 'DOb8htND5_o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18828 ['T7khbuOBHbo', '4Mo7tdV2LZk', 'AEwkS57P4eE', 'ZAT2_-x59pY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18829 ['2zo5z1I0CeM', 'XfLIbeSJSHE', '1V7ReAk9k-4', 'Nz4iLzJBTBo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18830 ['0QAaln-hjPw', 'Ife1WaGirdQ', 'lIEnbqr3O34', 'nf3LGAL1LZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18831 ['Q0KwG3ynscI', 'BjIksWR4oKw', 'z8Wjdss5uMg', 'ICtri0ElFZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18832 ['MXdVnDVjSL8', 'q4PfLl3JVfg', 'M1ds6tRFxhs', 'ZUg7rRpFGvA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18833 ['Mv90uA0tmgc', 'x6U1gX5a_4M', 'Aky0DF507fw', 'ovVrS-q3Rzk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18834 ['IlUcHzBzZvg', 'bY_EvbARc5Y', 'IQxr3xwAbKk', 'G13NEVAm6-o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18835 ['CPr0YRTcaKg', 'MHgPpImV7b4', 'NjoKxRwQxCE', '2U8Dvh7nwFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18836 ['b6hr31Qaemg', 'jV8kq0MpWMU', 'jzij1UX73kU', 'Ezodz2aZnzQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18837 ['1pR0SgbqP3M', 'OKquGBKOgME', '7Msk_hkz6zk', 'E29kpquu8W4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18838 ['r8B3-yBc-4U', 'cWOohqFud6g', 'hHqrcLiKJRg', 'KxVbdGPAfjE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18839 ['aT7LGemDB40', 'ET7yQfaiF_8', 'AHmcuClSTL4', 'F5xnAYHuGlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18840 ['hzznbzry5R8', 'rrWQd5SZK74', 'hjrl1KHEuqE', 'G6ihF82lvEA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18841 ['LnL3KFKGqHE', 'iaRDUksPv50', 'BI8YQ3ueD24', '62L5kn1qFeY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18842 ['-Q9MTRXS4bE', 'EgwGYmAH0BA', 'NgniX3tg_Mo', '6-MdbipzKS0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18843 ['9JeN1ld-3fY', '11fNNN95_og', 'pS1X6Au1EAU', 'KxZ0yDfyaJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18844 ['CzHZNJEV-3o', 'pELIBvAnbkY', 'mhru3GXbkHY', 'mFcHGbnNtSQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18845 ['WNv-YNn1cZ8', 'vrxT5jhqu0Q', '0RcMzUdXDRQ', 'ZtcHktwEfAU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18846 ['YlgCFc3OvmI', 'nPlDt1R8Qfc', 'bt8iHoIf2mo', 'Y1ItBiA8nKU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18847 ['DQzg3cZeYSw', 'UxlrI-9RtWg', '8PcfPX11Hjg', 'Obtx-A9Lt5c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18848 ['8WnXfe3ud4E', 'NHA1l_Czm38', 'qVgnzJuGDBE', 'VgwsGjRk61M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18849 ['bJVogLOURmc', '0VsjSa1X7iA', 'fa0lR26K23E', '7XMqcbZKNNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18850 ['LfbGHMumxIQ', '2ZfthfWQowE', 'bzOeufhFITk', '3UHHjbO0ThM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18851 ['KB79k456DhI', 'C-NYmja61zE', 'WQsuFvw43RA', 'YvT7qFbUOO0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18852 ['IO5QJRyoqO8', 'CxgVq6eovRU', '2cxvYC9QZac', 'Jvj2WqgVy78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18853 ['vMU7ZKY2Eso', 'GuYRF0no7hw', 'v88cAXP03As', 'XW6tS4zAZ5E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18854 ['bpaq5wQKOkU', '8zcogfmAD_o', 'WY73T0xaY0A', 'AI9P6HoiJy8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18855 ['ax8hXst_b5g', 'yqb4GenP8gs', '9z4YXc9rjTo', 'm7i4g_o-znQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.6203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18856 ['0i8VM_EooCs', 'EBpa2CADNJA', 'yfaxqwNHe7w', 'Ts04bBeY1d4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18857 ['UoxHwOl2gN0', 'MVq9PYtypy0', 'Bd0PbyrG6H4', 'L8zjEoQFws8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18858 ['RmDfwz0OG8E', 'rJZgUpzqAyY', 'n4QSYx4wVQg', 'On9epzZ_ceI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18859 ['jKjj66pRXZA', 'm8-aK8egg84', 'BkjpjAohg-0', '5dG1oPahyto']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18860 ['Y-qOOR0izlE', 'XWj7nP7kfdQ', '9VE1-3q27Qg', '4H1nc2Xv2Hg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18861 ['DLJGT99uEh4', 'PSYURntIjuc', 'ZdqPnWEANuI', 'CPX6f-Awx-0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18862 ['jaJdPUAv6N0', 'hSSzn4bIwZg', '9gSOOPDuD4Y', 'BKQYrrJVg6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18863 ['xZTlnE6IcYQ', 'n1PTn_NH_K0', '9PMoI31ncIs', 'Y3WXrp3JFxU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18864 ['hj7VJnNq6A4', 'SWyF5TSxWso', 'o-ISARPUGlo', 'SHYGoXwgKtk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18865 ['mwwnfWgV_5U', 'pZgzjL5wbtA', 'LqP4F4a-HOc', 'whIj6mrUGzQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18866 ['JZnOGRCBW0I', 'SsVc1TAVsSc', 'kko1uYyqJ_o', 'nnUva-yCR08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18867 ['5-tx4Fgqetc', 'mFp1nrnlGx4', '9m0tNvskmTc', 'JpMHnsdsCiY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18868 ['RBniJk6GKK0', 'c2akbbdS7I4', 'w2MeQg3W7Po', 'Jq2w30NYstQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18869 ['nZ19mW-TMRk', 'BdKiPR3kdjo', '9FLDpfkbxZs', '3dzR3ZWOe8Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18870 ['sc7KNFUEdfY', 'OEIj1UX5ZRg', 'nH_lVl3a3Uw', '1Rd1w7Ty1ak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18871 ['ivymRS3iEZk', 'qCUJ-8AlecY', 'C6roSYqchkk', 'xydcedfPePM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18872 ['3vEsFxolnFs', 'aeujZtBvMFY', 'P25JeM4lPGw', '7cvqeU9Wh-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18873 ['EieK70X8lnw', 'N5BAnG2zoUY', 'eWwWwoQLtVg', 'JRfU_hF1wdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18874 ['gy6R280ZUMQ', 'a2Wuroc8DQU', 'FTdcanPJw6E', 'DE6bdmnmPtg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18875 ['LUtBqNS27AQ', 'LMGpKPavV4Q', 'ocCIB2bPq_Y', 'FYFapDVOFHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18876 ['0u4gY1bBUwQ', 'pbVYSktQ5jE', 'vZ9IanI59gE', 'KRKX_UtYV9c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18877 ['yOVaak2hemM', 'gb8PG-5i5YI', 'DAX9uKYlDvw', 'BTMWpYzpu5g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18878 ['EwDiNj_5PEg', 'CwmUMySSNQc', 'dIPW9gLGSx8', '2YQPwRLB1s0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18879 ['HS_ikHx4LIQ', 'O73wigUotGo', '4PNPgaLKFlc', 'WqC-fx3uNVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18880 ['CuUu6L5hhMs', '6OcoDIrbMtY', 'YTYj8Bk0qM8', 'wT2Y0DCq5LI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18881 ['Ip6FptuXHyk', 'AzGtPHlrlzU', 'qRLRLp-KTFs', 'Bx1HZVX4UxM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18882 ['HFH9tcIK_PM', 'YXDHyD4HU0E', 'aW6greyYuO4', 'O9Ag-dE-yfQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18883 ['C-7ubPOCeJk', '7OgH3B49_E4', 'LwmwCpAVPWU', 'W5BB6pubJZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18884 ['338iZ76huSQ', 'yWU0zNEy2_I', 'UoSID1KzWuI', 'VM-U7MyZAck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18885 ['z9UJD6O7EAE', 'JHkcCXF5vII', 'AagemOzvoZE', 'vtnuHbHbveg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18886 ['YSrTtw6ku2E', '0EvpBtracsk', 'qjJ41iwU9LY', '8wty3wJfmEY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18887 ['VAqPLAgn9NI', 'wj4ukZFNEgs', 'bpKbpKZB0Q0', 'Wh5JSj89tW8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18888 ['ymOjaaxRDLU', '_VmCPixy9GQ', 'DroAzooK4yw', 'tt5-i1R78ms']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.8122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18889 ['D9893od03Sc', '0Gxn9FtaJFc', 'wgIf0FX6WzI', 'VZjE27e9X7o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18890 ['NuN-ug3dIkw', 'uHgpDP_4Lsc', 'OLy3C8YpMsY', 'FKChZXXhufE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18891 ['aTeOMq8ave8', 'InKK8z21UYo', 'WhEd8h7J0Lk', 'O9_avJFKIQk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18892 ['w6zHc6nRJ0o', '6c1vNidtVTc', 'E6JR3htwgyE', 'mOFyRCMlXIo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18893 ['BBSApRvkaqY', 'uBENjCPS8LI', 'rgWm0-a0kAo', 'KN9vuaQvld0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18894 ['fhs7AkJsYao', '-3Kv4fdm7Uk', 'LaeRCg-NdeY', 'qie2k2gZ7wA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18895 ['bHiRX6QYwEk', 'jIoDR_eskaU', '1i1sbQOILb0', 'XaqVAF-ADWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18896 ['O8rHjrG3HM4', 'ypg2ItQIc2c', 'eWSA0xubW7I', 'LoTRWc9WK9Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18897 ['awax48X8YlU', 'X2gHQb5ubco', 'JU4CZ-GApu4', 'LGi38MqlPFA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18898 ['CQlh4k5pXKA', '8fInAz_GICs', 'wLQiZ-0VW4c', '-FlvaZQOr2I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18899 ['cGorUmWMrwo', 'rVdI-aD9pq8', 'aqhhfkXKJ1o', 'bKm2_67xtVs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18900 ['qXSG2uq2tNw', '6QHfXuVLhe0', 'J0lA7ZDfPLE', '1h2sb2xeCt8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18901 ['NZn4-gP2GiI', '26IOFykrJrc', 'jd94Ox7KJ9Q', 'KFB1raoIhoU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18902 ['SkIDF7iNJQE', 'KSFND-AdqZs', 'C5MhO2HM2Wg', 'O66lIRbF4Gw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18903 ['EsssGCL-Axw', 'GLIXnXZEOxY', 'tr2iVjsu4xs', 'xZSioXdxo4Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18904 ['588osm3C4bw', '0RDz0rLakwc', 'JR-1k8GHYAw', 'K1PzpuR6CqY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18905 ['CWQvCCRuU6k', 'KrmG43H1u70', '1dt9eL2rmSY', 'aOGNUGgTQ8k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18906 ['4o0bARRMYQ8', 'Jjr0_CbcYdg', '-1OlgJWehn8', 'oARFeTnImOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18907 ['kVaQA3PhSio', 'sGAYO93RR5Q', 'piyYJ2l_h8Q', 'BAUQY0e25DM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18908 ['g-ghr5fAVpE', 'NzvkMWY4EjA', '4vGLTrW04UE', 'c5NGOcNyF4g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18909 ['t12O05LVSBA', 'JEJLTct-014', 'XQB27QPic3k', 'pTzINk_nVHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18910 ['hDzmNYd_eaA', 'wKE9STHwX-Q', 'tBKOvAiNOQE', 'NmwmOY6iBFg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18911 ['tZgww16UyU8', 'wMHBhCVv--g', 'MPe6ztPtF0Y', 'I5KHYgtrVBw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18912 ['aY8-pXDdwiw', 'JXS5eW7g4HY', 'okAn7kjxmes', 'cYRsnYEPIiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18913 ['9rgB0wKU1-g', 'XFuw-m2gYOQ', 'oZoJ26C6LrU', '73YTz8RC2Fo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18914 ['pDgWT99uaJ0', 'cCyfADwHiWs', 'OH8urnIthoQ', '0s0Uy0-zBa0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18915 ['hhVFK9tYu84', 'B3WaJ_3M0vw', '2KkNk9Ao7G4', 'f6H0TMWDaZg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18916 ['dbftWJH0OvA', 'vo-o3dG8Oq0', '7p_Mnxl4Vq8', 'Qu76GhRO9Yk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18917 ['0NZY0GHQBP0', '_8OIugVSFeE', 'EN_FOFkxAEw', 'NZ2kFIaW05k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18918 ['sgTZHSTnU40', 'agK1OkzW5Yg', 'JzRb1OVpat0', 'zPhuyMYy9EI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18919 ['0298WjE3_tk', 'TFLt7mn57ZI', 'URM1QgX5Ar4', 'MmqRlHntd0Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18920 ['JRmfjBDKCpE', 'fe10sxFSz_I', 'RSryuuvUfDM', 'yGXohnxCLCA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18921 ['je1amtXOKF4', 'ZX7EzqMBjfo', 'tcOHcop3sCQ', 'TIAj-fi_R7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18922 ['axb48YrvRmw', 'VHYxygh1STA', '_43OOP6UEw0', 'Cd7JefC6-Zw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18923 ['I6eU2qRjJ7Y', '3noh9LiQNrs', 'uLp6z37bfVE', 'D6xrH93lnoc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18924 ['fcpVyvn5vKk', '8oTTgXIO0-I', 'lDGQu122JdU', 'zGBKakEGSyc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18925 ['FE2kALvHjEU', 'z_fEIZOv0JY', 'YSXrSxC68VM', '-88me9bBzrk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18926 ['jqiD3VeM_hY', 'sgwvhvkNELc', 'Y7mTjfgcybQ', '3tyb0cXoX2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18927 ['JDrnf3vldLw', 'p2jnUySmuvA', '24cmo2fEQo8', 'caFMauLQvd4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18928 ['DGlP6oTqe5Y', 'aUvHaURNgY8', '4refolVb_uQ', 'BMgYWTTJv3s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18929 ['h6Y0KDtUNHw', 'DA3fNvbZoBM', 'AjjQqd0eLzw', 'idUZsNLnyDg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18930 ['UOKWQ2EHJQI', '4TXy2i036LU', 'kf-U7I0-DdA', 'z31iCbkqYyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18931 ['nZOgoVEud_w', 'JZyw6YUsGzo', '0bRUkLsttto', 'cGrQw46ftj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18932 ['qVT6GX1KHUY', '8hSmQpOPXJE', 'XI-tRuDZ6HA', 'pQWpa484HQM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18933 ['DW3z-ByrfWY', 'KMQmM12G9Z4', 'ZoAfkpmztww', 'AqSV_WKZxEc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 60])\n",
            "Loss tensor(0.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18934 ['aGMdcxeF6Ak', 'EwoCbcSXlSM', 'tnJb9WyhCUc', 'OxxRnDpN9cc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18935 ['qbexOeoH5hg', 'yFh6J72KnCM', 't8os583-_JM', 'oRVivXC83hA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18936 ['7ZW8xO37bA4', 'Z2c1npe5AYY', 'qUWYzx7pBSw', 'B1vY7kxQ9Xg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18937 ['FaD9qs2ACpI', 'tsdNl72WVs4', 'jKWl63gozLE', '33LJ36nAozM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18938 ['fWfQxB2pVrc', 'nAKUDXMeWeQ', 'I0skZ6yT36E', 'gffng5G4X4w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18939 ['D8zK7PHIkgA', 'HNf9eHqDT1A', 'Wh_g-Eiw9Kc', 'KPymcVenomk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18940 ['CBUAy9Zl6ZE', 'sOJSjVp6UTc', 'DHo1z0_ZUNA', 'tWseBEYhE1M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18941 ['FNnKFUkFJ5M', '39MksqVeLdY', 'J9PJI1UwIQ4', 'kVYXcbvw9u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18942 ['whZygh228yw', '4a1a-lmDVaY', '6k4lcF9IGUk', 'tnSM-SnE5Lk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18943 ['doHRurF8bf8', '8dE1x--TuF8', 'YVEqyQjyy1Q', 'sOSU7p9pLjs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18944 ['1ToIyrmWFjw', '_5fwnVeZbvI', 'en56uOGTwzg', '7ym-LzgwSPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18945 ['GbjtSTTEFK4', 'eXWBC3XfiXY', 'ZzyWbehtt0M', 'HpkPTa1fQDE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18946 ['wv6YaiCGPi0', '7IndxxjZe1c', 'fM8elJ4jkic', 'LClTjcyNJSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18947 ['iQJvAXOohoU', 'YyHmz1vcob8', 'fBEGBuO3RXg', 'ltZCJ7aPtO0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18948 ['giPa2vVEyVc', '1cqcTbDxsHM', 'e4abjaPD9R0', '0VjPCd62oKg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18949 ['IwobTmzjOiQ', 'Tfc6184uCIk', 'EptdhC17avY', 'YMq4wE6KxmQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18950 ['IFimpFwvbz8', 'US3ZL2zhXgI', 'fvw3Bi0GONA', 'XfLI8gHCuFE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18951 ['bwHPVG6vbNQ', '5AdeNHlPnvs', 'fYk2U9yJvps', '2aPVOidHLXI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18952 ['BEhIGoq9tow', 'kepd6_X_vS4', 'p1-07VdP__Q', 'vQ09gQBt1IU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18953 ['Xn0wIqnt_44', '9L6ePkWtZI4', 'NNeEzTVATHg', 'L9xj_v65UhU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18954 ['XE4NRSDLYG8', 'WIuLaxWIAAI', 'HEclHruM37s', '6iZ49s7eH5g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18955 ['LFYRuK8YstI', 'PeWXdkEUPbo', '9GRNQKSsbvU', 'QzMsoz4XIkM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18956 ['JvvnL7UnCGA', 'I2yA-F-_A2E', 'BcVapmCbULQ', '8XBsesSEbbU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18957 ['BiPwCMlghhQ', 'vpU4XIISXtM', 'U4MdEIQcZxs', 'C8VECv8kicU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18958 ['YtYjdkTK5oY', 'RJViDdqUYyo', 'AareFwTIg1s', 'ZF8uHVu4Res']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18959 ['c1hLduV1p88', 'OhZmxS5DUKU', 'sZuhztdaFYA', 'LYO7_GxyaZc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18960 ['2KGnpMYHBGI', 'UtZofZjccBs', 'ZnBvXFDWpWo', 'ZgooDijn2as']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18961 ['-5xOcMJpTUk', 'fPYxUa1ZVAY', 'g8XTU3OalGs', 'PRzBkZSSyY0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18962 ['O84YjlJ_Qw4', '0SNhAKyXtC8', 'dKJk3JavNzo', '-XN0NtrnfMY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18963 ['Z8L3jychP14', 'hYy0na5oUzE', 'mOmYcOBqhwo', 'd0Uz_RnRV88']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18964 ['GcYeBWujhjw', 'lDCDayKyOQA', 'HyyHwIK9SSI', 'EXRKJRL0TDU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18965 ['0KCVgexi4yU', 'LCzldLY3E4g', 'NQXQsVawPhU', '0m9-5BkL4Mc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18966 ['vKjC5HTH22o', '55vMO5LzMHM', '0_hH79HnEdo', 'HHTgjmgTV6c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18967 ['5CtvEcPtknI', 'GQbUpJFArKI', 'adYFXYPqo2M', 'mwqluX7sXXU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18968 ['Z5x5BLzQKZI', 'qAr3mFkEvco', 'n3EeS2mVU5w', 'M61BBJpvvx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18969 ['Z6q5doznOcI', 'xXRGgPVnkqk', '6QfM3BRp-78', 'k4kbpRRRgcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18970 ['1Ziku4FLka4', 'hdlnugbWjKA', 'eSIxvnEQ6R0', 'DXeiJpZXVAI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18971 ['nVsAyArtEh0', '2sIfE3KOi5s', 'HVsXJDR1_Lw', '1RwhRTe-OKk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18972 ['Z0htOHTOtHY', 'EnewI6fNhVA', '2SI_uNBcSyw', 'fsXfBoNcLeM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18973 ['xWmcax3aX5U', 'k-J2-Ou1Fm8', 'w0yHqPxybQE', 'rsCQ1PIGcm0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18974 ['zkYXE0-JsY4', 'a4BjqKd8FsI', 'hLwMYygjRfI', 'VeXcCHo5iMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18975 ['JUwu4xOs8K4', 'TEWYFkjH2jc', 'PQ7cX2Cnusg', '7LlKoQAvXUc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18976 ['HHZGjS4g-w4', 'YxQzJweGS2c', 'NPXZIqxKvXA', 'WySgNm8qH-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18977 ['g0aOPWwNMFQ', 'ZHsAU90h8oc', 'gDzi8N3BYMw', '3tSPMzvuQpk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18978 ['qfwTbBprDVU', 'eVjcfdxSFKQ', 'J7jVR6y6REA', '6KqFiP_ux5U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18979 ['uPGasFKZSBo', 'KZ8gBHLNmH0', 'DaiVfxATCEE', 'T7bG4kIEw-M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18980 ['-YIT4HBM__g', '6sWVG6GyJBU', '7MuFNZHhrOE', 'M5sptjrboqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18981 ['8pl1D6oG38k', 'RD8kf4453cY', 'a-P0p_UtagM', 'BzM0qok5Cns']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18982 ['PcdpjUIa8l0', 'dYVy7moyQCc', 'fKni4PUSxu4', 'VJ-dpTx_3Cg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18983 ['TyMZJqYmrwE', '9BHvpWP2V9Y', 'VTagIq90b7s', 'bBfi3iEu9fk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18984 ['2BGzxAuetOA', 'NLQts9t7d8k', 'Z_0Ta-m_-hU', '5QtjEBcZR6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18985 ['H_2ZPxy80Eo', '9dBWFEpcJIo', 'A-7dmBdsFXc', 'gsBXngKgy-Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18986 ['gOhONZR_F7c', 'VB82vMSTYK0', 'jtwRKyQ8-lg', '9-R70gSqvrc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18987 ['5iUwBOf4yek', '0PMFAO4TIU4', 'WhX3jQxHZWc', '07-vpXo91XM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18988 ['AtWf5OAE8aM', 'wc4UEh8wvCA', 'ftKCLRd9_no', 'GNu_hiHGEp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18989 ['rs5ecH8Lh3s', 'GOTy3yhCylw', 'XHczpbtBhk4', 'XrjkzI6TVwc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18990 ['kGo-dAQXtsA', 'mB2FAS0DNkk', 'rfQ94EXIpTc', 'PTl5ixI1Ogc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18991 ['6gTrMRQPZMU', 'VjbRot21Hq0', 'tOnjlUzqSC4', 'jrwhxVnvMdk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18992 ['FSQ3E4XbpPU', 'PFtcnQqLdEc', '-5f6hjZf9Yw', 'Q6dVti1YVwM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18993 ['drqKxGmdf8Y', 'ZwfzBagtpV0', 'ADxuhHNZVCc', 'oOlMzQpK690']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18994 ['-nlkWWphiaM', '5hEt87nd7os', 'L_ghM-NrH58', 'eWqD_VOympU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18995 ['ZaUaqnLdg6k', 'xIdWJyhWueE', 'vYP60jdTupc', '9r01cpNx2vk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18996 ['3XRjrSOVBnQ', '7V0G65FK2VQ', 'atWaDoSyGgY', '5Tq56BN8PCQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18997 ['_dF-ZGquRNY', '6AC84nr6ckM', 'W4nQpOHIPEw', 'H6Y_7Ax34-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18998 ['iMTHDuW_xKc', 'CZoPTJNmiCw', '_gWEpDgPAho', 'fp0oCFL6w4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.5018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18999 ['PufDOSkxwzQ', 'gEvCUcZ6w88', 'ORt8LSgn-uA', 'OrsfEkAhie4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19000 ['KV99GJg0tvA', 'AFwtBviVhhM', 'Vbx6TFxSPYY', 'oSg1VJHiPOE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19001 ['R-aMYx9f0Ho', 'bSX5-VPL8rE', 'OH2SQhJqZDg', 'w0QJT6ywza0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19002 ['-0SdAVK79lg', 'OII3VJoE0WA', '7k3OZ_fPXuM', 'WFPGA_BYkKU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19003 ['gD6UoStqCsg', '78BtX0oNXHQ', 'R6mhBqTU0Tc', 'oSDZZHN77PI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19004 ['UcabTrKowlI', '9xV0nmojVeg', 'GAohd8KvONo', '3TP1itJqv-E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19005 ['9gCeNCnWZhE', 'v6A7Iggebm4', 'zfkPKRn8ah8', '4Psyk_xyBl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19006 ['9vbsI9xFuo8', 'vEl7ImwLlrA', '8ZK1ajW598M', 'mWuX--EEq2E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19007 ['wQN7fRaPl2A', 'gkB4KBHBV9g', '8vFJX7NcSbI', 'lnJdWXRgjKo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19008 ['4ZwGxgOwBUc', 'JnfMv9ti9Sw', 'heZw1TTrtTU', 'SbUwQctvbHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19009 ['rVymW4Nb4NU', 'tGv_L09pf6E', 'WSMdqFEjGXE', 'O1EmHJyz5ds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19010 ['Pd4WnsXwdqw', '7JMN4DdhwsM', 'AOgbZUl0y0A', 'pYXx0xXZiXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19011 ['FKBryvLMTY4', 'hbCaMcbT8to', 'vNPL092rPgQ', '_R9Ma9rjEWg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19012 ['kOBh4NZ4wZQ', 'ZEN8_GtW_UQ', 'ZiHlhUvmgzQ', 'd6w3d9S1LVM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19013 ['VjXt63pqUgw', '4ezo771lGts', 'TWm0OilO0uw', '3kXukXBvDQQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 58])\n",
            "Loss tensor(0.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19014 ['Ail32Z1T4QM', 'b98BJ36K1wo', 'kTyI2unrdv0', 'wLITXWAuZy0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19015 ['GzRvq0gJbj0', 'h-2KO5ufrcw', '2MpzHv5KNZU', 'zw5dkiklbhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19016 ['a-11dtG7aK4', 'YgX85tZf1ts', 'TbA_TZn35LA', 'tUJ_ZniLjhc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19017 ['DAPGvg8qOAU', 'HvOSaS8sXQM', 'wz-7sy_Rin4', 'Rhn6K9HCbC8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19018 ['w4ayJNZ5w5o', 'Pq1jBX0RW2k', 'sxgMEmp5aGE', 'cjTrK-kA6x0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19019 ['BS2ZnUhmHj4', 'QNQ3sAMxZPY', 'BQ_KrefFiTw', 'LKurVRvkmKc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19020 ['RcfaWoTywcA', 'vWiq7n4yTAw', '-XkbErI_7EU', '-R0267o4lLk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19021 ['BxbB2_N5Xtk', 'WPguqXCBQCI', '9hCnEfZFZ04', '72_Hk1cdoxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19022 ['bztxC9EFfCk', 'deIj55UAxeo', 'NxpnW_IdkSY', 'ZQwpXl8qnnk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19023 ['V1A4wBgvPgI', 'NnmJ1UHWlas', 'EOaQnfDjVyo', '4yJZ4VX8XQI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19024 ['Zhurw43-Y1g', 'kbquMoJrhC0', 'BtdzVnXZ0i4', '0ewWspUqB6Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19025 ['2FQKfGCwjSE', 'AVmJF1uaRuE', 'Fa1c4qfBqzE', 'PZZxVIIOQPo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19026 ['H_5wh4aMQe0', 'CRUd8kY3L70', 'HtSznF9_784', 'vStedb9LiDk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19027 ['7RUkkhkqyUw', 'VfARCp38XtA', 'ITg9o6Gwsbo', 'ZV_ZbmjPpkw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19028 ['4kKVGPDCIK8', 'cqeVEFFzz7E', 'mPaRs96jtFY', 'YuiQRYaF9SA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19029 ['GOujNXEtDmg', 'I11AcD1sGes', 'Ac4M-EkdkDs', '_lq8nEXh064']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19030 ['ETl0hYRlVmg', 'iS8YQGp2_ng', 'P65yE_EXLd8', 'ckOe-8qdaew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19031 ['ClNTn1wtq7E', 'f5eMUCSZCjc', 'SG24NL2Xi3A', 'QlaW568SeDc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19032 ['5xIBQGMjiX4', '1AOe82obwcY', 'DgqPgNqW2hE', 'rWitVrXe5tg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19033 ['2x4694ExyCU', 'QDTCAxyXt80', 'lDsQWSf1h3I', 'XzTBNfQ7_GA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19034 ['nFoktpUVeVw', '0ZNFJz-eZTU', 'Yiau7DypQi0', 'tG5C-Smp-eY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19035 ['hPIh5RYA-5M', 'aNjtfIoVzas', '0jFQ21A6GRA', 'T7A0RejsZIo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19036 ['W7U-glgu4GM', 'b2-izZk5_BM', 'hNKTrKk4hZs', 'CrkxrgTiVyk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19037 ['BHu95Y_kVQA', 'un-OXLWhvDc', 'P5uIpVLEpm4', 'HrwpdRe7meM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19038 ['rzVNYg3nClo', 'CMfAu72qma0', '4sD0Bvt3FKk', '40kbMyL2Wgo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19039 ['AT_076RUWPs', '9cojCCMSABc', 'rn_v88OiRks', 'cJD5JFWnxNo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19040 ['7l4-QmvXxEs', 'DTnCrtCro44', '2KwSyaLT_mw', 'v5SsASLy2c8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19041 ['gBuLpP4klvI', 'Eop_sG9FVgA', 'In44gO8Ej90', 'xSmmTveNPSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19042 ['1ArUx6UCxe4', 'iEQwupwwp0s', 'Mwy5Y0S5jfM', 'AnMR6SOBa9k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19043 ['Q0VVfneN8MI', 'LTDle_h2YD8', 'Nlg8AbWRV_c', 'tpnvHb9ZhlU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19044 ['WeDA1mDFSCo', 'SNhfvhWPXNc', 'u68Ghaf_Phs', '4L9KyVVsQOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19045 ['AElgGuUSSKE', 'NDJEKij2qOg', 'XXBVsNt2Qr8', '0RgGrVklaao']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 56])\n",
            "Loss tensor(0.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19046 ['XgLUXNAC7b8', 's_BKo_1LzJM', 'oN9_GYDkNcM', 'SLdVSirZMSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19047 ['d6nURbq86zM', 'aek3GoFr5MI', '-e4wXAy1iVo', 'NSS9_2FFVeo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19048 ['JKihzveDE5g', 'K0x_DxNxtbk', 'DB38NRSHw9A', 'rC4PNZ1XOmU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19049 ['k5kPBsMFlOc', 'Ok-ia7ziJy0', '36ToDxW_hns', 'Wdl7A3de0L4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19050 ['hQ5OBio4Cy0', 'WsDb16qzA5Q', 'BiqPn3d_dKM', 'bqMgL5qmZ-k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19051 ['VrqBeY3kfKI', 'R4ulZgTCw-k', 'Ysrlv2UlG8A', 'rGEJVUcFA2U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19052 ['vjW8wmF5VWc', 'lqeAf-DqE3I', 'zrb76mJOZQQ', 'j3a60_lwWjE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19053 ['w_z9oSn-eIM', 'gqkqzqCHM3A', '0fiOM---7QI', 'ZOzavOPeuJQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19054 ['01PzcPKT3_E', '9M4IT3lOU10', 'IQbzpgmi4Ec', '26HLgXWF-Co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19055 ['8fibq2VXibw', '-BHPu-dPmWQ', 'i_NNY_mgxIs', '_GQnXfIGNKY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19056 ['HdRPdh-cSTw', 'SkFG5SoXsVk', 'A7RgbrJYe_s', 'iFWtsT5zRKo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19057 ['ehJKd9HLA04', 'dql-sQqgVXI', 'KubrAnJ0o0o', 'vNPx6RS8PiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19058 ['KrK8Giu9ZUc', '7Mv4eKPe850', 'DueNcVFHI0k', 'AlVr7-ntuqw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19059 ['uCCdUB7D10U', 'AJeRSlZuZbk', 'GHQlBD-6rkA', 'lDABsoatahM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19060 ['imIFtW4O5S0', '6vM7Kv42Uv0', '0Wdh45yt7tY', 'M4rXhyyvERM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19061 ['JtLNRHVGQuw', 'jhQpTVVUQ9E', 'xl4FJzeU0YA', 'zD4PXuUkwsc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19062 ['CN2QSmhP-HI', 'cnvmLwFZr28', 'E16FgDFQI_w', 'TTytcT_1dmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19063 ['E_kgtQ93Q1s', 'Kojo5khAAS0', 'jQYSfy4DzIc', 'DpS_TigOHWo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19064 ['Pk5NZe-ah4U', 'A_Yd5huF2Pg', '-hYRFCQdbLg', 'BlhUt8AJJO8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19065 ['coG_EznBmzE', 'Z0OTDXtjK9M', 'C33WdI64FiY', 'M_s-49rNCdw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19066 ['sd1gAgsXMsc', 'mLm8upEhc_s', 'qDjeY72KaSo', 'LbQ4zHxhoSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19067 ['by57LpTlGbs', 'bqvl7IbPteU', 'xKc_9B3RiOc', '-0Gj8-vB1q4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19068 ['SSO7F_Ex0s4', 'dvDSgmqbrM0', 'J2R8Ab25reU', 'mCjsuxzcl2k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19069 ['NX3KJ-tVdMI', 'TZGDukKAVS8', 'mzDq-abtAKs', 'TabaOeYq2ek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19070 ['bkzGHRpx5MM', '5z60cbPEEaY', 'G6A9NKeK8ko', '-CUp_Tmg2Y0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19071 ['8kH-dzSBthI', 'oOiwmRV1PBk', 'XXdPZMsrBd4', 'axqtExFY5-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19072 ['ogOTksL2Vas', 'tAdNaRRFFXg', '3u9OO9Og0Gc', 'ItLWKIhe58c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19073 ['YBbvQ0RPrG8', 'Ls6qMcgpdlM', 'tQ1Nl4Dy2aI', 'vEt13GxzDKk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19074 ['MocXmVbat3s', 'sH_nDqYVq5E', 'cf-IIqhveKw', 'ScAlKYCgHV0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19075 ['sm7eBFHtdeA', '2G5bSYHcJSM', 'rLtXML8Y5wo', 'U8yqYlErUz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19076 ['v582kPp43Mg', '0J_TdiZ3TKA', 'JOkuwbhMxbQ', 'Hij_QxDkIJI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19077 ['puAclKsCbes', 'hoPnrbKOEl8', 'gHWMKew9Xq0', '0ONdm4sW47c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19078 ['BSe5J0KlN3k', 'HrPnGYGrvm0', '8HHrlxQuZKE', '_JTHtcRHxnw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19079 ['S2yXmXUJ5xU', 'Jj9orXFko0Y', 'xsLJe043ar4', 'ZocCGcJcGJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19080 ['7DIPyJB4osY', '5jQIuYPAODg', 'PpJKo-JPVU0', 'WEXJSNm_T0o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19081 ['8FZb_R2UANY', 'x14jW4c8YnQ', 'cQX-WgT0ACQ', 'xJMTA3Ay5FI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19082 ['TqIptTnXb20', 'tz2TlSMmTp4', '4vWChPYkuwA', 'v0tYHz5mk4I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19083 ['Wvg5rlMbjJc', 'B7V_grbxflg', 'F8wGRd9332s', 'cp8t27oT_ww']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19084 ['7YtKrL6ScXA', 'ULHPhjaJ6p0', 'z2kTJ6pQ4Uo', 'rS8oECcQBCk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19085 ['n3QsFeGadEE', 'CgK0DU3KFBc', '2hgvuYGc95o', 'hH6thMA3640']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19086 ['AjLuenrAsbE', 'H18aK9HhNSM', 'rPAB0ymJGco', 'duMRKOb4E2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19087 ['1o7iTDLNTFk', '_kPmYc1nXuQ', '7yK4-hsVX1o', '-r7iz-9v9bA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19088 ['wRWxsKN394Q', 'kaabXWuPWRg', 'Fsv_syCvzsc', '7y9RfZXJZsk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19089 ['00M9FhCet6s', 'Qj4r_MCC0mc', 'ad6UhYwTXXQ', '9nVpyqfyBSE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19090 ['QyMcSnNsAPw', 'DKflAAykh6A', 'nJ3tuDmcdTs', 'CAbNGe1PWoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19091 ['Lq0LMMZfHCU', 'WYbD9YUrf_4', 'ECP7EJka6N8', 'jPOWgfA0zAo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19092 ['8Bu8CkR1xZY', 'oYECB7KFJgU', 'p7VmMa6cpSo', 'Aro-HcWNsHI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19093 ['m3uiITzeM70', 'joLyjgORwDo', 'GMFWnMRtfNI', 'hHS5C0RKa8A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19094 ['1JpeDWbgUO8', '769EHEG4Mqc', 'ZPK1hSPI540', 'dqQgzsNpwoQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19095 ['nXfqAzdu8IY', 'QrKJs6lBfmM', 'fDMbNCdGXBc', 'AU1l1i0H0j0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19096 ['WE0JqjuhaQI', '1yWGmdevTuM', 'snJDZAnTMwQ', 'xJYBA7VTkHA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19097 ['1ls3ectO1F4', 'O25IKwo2HkE', 'pejDm3j4Y-I', 'kcTwJwdLTSo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19098 ['MkPhe7TLLZ0', '8kx5ST65Fog', 'cXEJWtj2kT8', '-taO6N-rxv4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19099 ['q87TmUmVg0Y', 'ywuR9AfpA_E', 'KjMRf4egAyA', 'LH3mAtCou6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19100 ['CphwhKgYHaM', 'wxKtBDKasgM', 'Gc8xf7CJiFY', 'eZ8yopmYtPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19101 ['jjNxc9Zf9s8', 'xx3nnVzGXa0', 'I1wakVlpP6M', 'yCDloqQe65k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19102 ['tV2m7HFJprU', 'QiD3AkQz17E', 'nxdHojfss_A', '9KK6rg03bC8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19103 ['ktw_J6ZW0MM', '4i9DgH80kDg', '9TkW1M_ZRr0', 'SDTsifbpGMM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19104 ['gjujPd1lP8E', 'ui6ERk-AySw', '5tRNPTLRZqI', 'gXOyw8a4_Xs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19105 ['wMi_0eEIpcM', 'JSqyTVjYY6k', 'WgZ8KAnnTb8', 'aYrjw3gjGuk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19106 ['_Rpn2FUAUgY', '7jWRIjFaoeU', '_2P_EJsnBls', 'JmbrGzgxrJ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19107 ['4Bc9OoagYmo', 'OZjpYGdvMX0', 'KikHXfUanJk', 'OEpMpYMjO9Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19108 ['-8cgbhIR_pw', 'rE7S4nLrThs', 'dS8AZdmn8Wk', 'hu5pjj1KzK8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19109 ['NhVkzcCL0SA', '3w_LsKl-3Pk', '-6HBGg1cAI0', 'B9K58KYq-Cs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19110 ['PN3Lx8RutmI', 'kg8FwhL_fqs', 'rrAIuGMTqtA', 'wBozBh7BR6k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19111 ['x-ob6_6f4jQ', 'qh-4EDX4agQ', 'NZYDLDIyZr8', 'ODOrls3MuZI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19112 ['Ie5FO_BetOE', '5a_Qxd4ECTo', 'fxznho_kNPY', 's_LMd1_XN1w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19113 ['kT0KMsfD4d8', '2-K-7T8ZIWA', 'VAqgpoyD2jc', 'a_r8wKJ8ePw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19114 ['3XeMR8lX0dg', '8m-a_6wLTkU', 'xmSMAmnoRug', 'qrzNABqN420']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19115 ['rkapTdi8NTQ', 'SwRjY1-ojAU', 'AVsNJgR_K6w', 'pdOskdFwRPg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19116 ['CRDDdjDinYc', 'JlzlNpttvVM', 'vgpV6F9tge8', '35b9UHjagaI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19117 ['VkXLtUx-RmI', 'NcsYdCbKgcc', 'sYJiHxmQWjo', 'dzPPmuFUicc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19118 ['15z-gbPxdXg', '9ZAmdxKLnhs', 'hnlVKC7rxdg', 'w-YAUcPl-HU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19119 ['g2H8i_TuhgI', 'mfZMcNmLxWM', 'l8P2wU-JyI8', 'yRU7DifuAXY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19120 ['UCBocxMCdck', 'zgI-Lr6Pbcs', 'P8nK4i8XscM', 'em7akjDUsWk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19121 ['1Is1xfDjZrw', 'W3DwueAy65k', 'J_Raltj-6dk', 'YWf3I4jKusI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19122 ['BEwNrjvNiYs', 'gW33LYEvoaw', '3nfiGGQykxk', '1j3pXUr8R4M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19123 ['5XNalwqtkFg', 'lwQVcLxFBIQ', 'dcgwxlK3VVk', 's72505MIhz8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19124 ['XJXn88r9ys8', '_cf0WYQcNvk', 'drJaSu3AWhQ', 'w8c7JFU6by4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19125 ['0-7PyzhzuYQ', 'pwX5SArqGKU', 'vBw99ghST1g', 'R60qQ3ag8y8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19126 ['KurvLmoKCog', 'o6ZQNr0Tpz4', 'Zc4rX7nbRW4', '2dyEnOo3yJ8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19127 ['hkWcUtga1lw', 'SGFYFPs3Fic', 'yScg02DM-jY', 'tRA-5inwlMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19128 ['RV05BW-2WIc', 'TKSFbf-wQ8I', '2xtOqrNKH5s', '0QYNC7J05XI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19129 ['Py8Vd0-qxYU', '6u1ckcErgcQ', '9UOPRQhNzQ8', 'iDvva_WCo-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19130 ['2ZB7DUGOdZw', 'opu2tXoVNKU', 'JDWPJ1AiDKc', 'LGW99kSaf6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19131 ['p2NPfU5QARc', 'OOik9i9wrU8', '4GlH0-KhInI', '3tK7PpCo0PQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19132 ['fESsP6ZnVKA', 'ZUkh168Nyus', 'MM0seezR2F4', 'loyHHBilYPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19133 ['2RMOegT2Jn8', '3PwR0D7CuwM', 'a4jcJ7QZ-OQ', 'CVLqZyUwqv8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19134 ['uRA5Ue30fsY', 'AYln23c8g6w', 'Ximk6BHj9nE', 'RD-oizm_35M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19135 ['lOIzOWKd47E', '_oNLyxk08oA', 'KChjW89XOF0', 'uqAY4lCUcRY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19136 ['oswsd_r-GI8', 'IbD0zpcimgM', 'fjj9NJX8GB0', 'FDYIdBZUl2Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19137 ['PpamaOkNqoI', 'liuCTk2nPG8', 'dqJSTTS7HTY', '1hWAOReJehw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19138 ['QzO6ylLrTGg', 'argBwTHDDVI', 'X0MN34Us6eE', 'CyFsI_EYFQQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19139 ['Ob9iaGon5ak', 'uZHE9b1WDuM', 'iCHskFoUvbw', 'xtGmrLOsjHk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19140 ['s2GctT6NuyQ', 'pG6yeC3yUY4', 'AD3aI9avJ8Q', 'HzXWXYxXyYA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19141 ['sl37XQfkJCQ', '1KN3GrwhY8c', 'UFyOGqmITjM', 'vNZ3JS1LjDc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19142 ['LQYd-dsz62M', 'PrMKUjFxrvQ', 'IYumekd1VMg', 'ByF0pp-dVEo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19143 ['Le4aGNS8e0c', 'MFxMPOAbUPA', 'mixc4NV5IBE', '9UCLvFqkFxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19144 ['KPG9s_s8siA', '1KmsVHx7E2c', 'OBJM1TqPvu4', '3KdyWJ6wTOw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19145 ['tdTT6rmkk9M', 'nT_R3O0OK6U', '-i9uQMysy_A', 'qAgZ__fk9LY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19146 ['ojwVhlh-P1U', 'TX9PGFdqRak', 'TObYoD2pGb0', 'T0OFKHj6878']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19147 ['cmJj7SxQEp8', '-lPXTBXa0tE', 'iS-iTbHndw8', 'y516mYOT_9c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19148 ['cF7317DK0NQ', 'nUs5SJyQPnM', 'ExghbCGRBx0', 'Mf6Ql55o7Es']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19149 ['92sRFZvCnWo', 'qbIPQGY8RRA', 'OoJGMj5H7Wk', 'hCELSy7hVKE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19150 ['ZFimyfPWltk', 'jWQu301CEp8', 'AAoqx07aTRI', 'IIK0EuHyb6w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.7918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19151 ['JaGUY5ULTok', 'zVA66aZOBH4', 'TcJ7rdYMHiQ', 'PKsdjH0RmsU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19152 ['N4tTZn8WlDM', 'D0L-M4trkpw', 'ViF7A7XODiw', 'BT4env-Tw2o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19153 ['ARXTRdKCupM', 'TWm_2QncYXg', 'MVAXHT67Na4', 'tw0BGErgupk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19154 ['yZRTQX8pcMY', 'qFTMEVccUMg', '7pYavsK9sPg', 'OdLCoLVRCmk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19155 ['V3Vvp5HS90k', 'vpcEBryyej4', 'NBnz0xV9nb4', 'I4Jp0kB2Ns0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19156 ['xUMzNtC2ITA', 'OjvWDzPGeic', 'qjH068GOmQ4', 'zU4mwg-HHoQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19157 ['QfM5-WqvquQ', 'nr9oLIsbDyQ', 'L_nC2BvhRdQ', 'PTCsH-ffeq4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19158 ['AAFsg91kje4', 'wQhycJsKSPE', 'ZYUAY6EN05Q', 'FscE_AHEmFk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19159 ['MV4tgzc9X6s', 'oh5XmtSAOuM', 'YDh36ZdneAU', 'oZF73R89bk0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19160 ['fmHbWq-7-iQ', 'mcAsO331Z9s', 'ZHzhdhKEjMc', 'zixIuxzCCvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19161 ['on18CWdmxn8', 'mZNNWTrvGoA', 'i70a79YhlMk', '0c1YU_VtFRE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19162 ['P2UqnWU8d8o', 'ROA6DMBPlNM', 'U6aLiMIlqCc', 'uARzr9CAemI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19163 ['GjE_iD2BbFg', '17AtKbQ7glU', 'xlxxWFENWr8', 'ROM--1yVra8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19164 ['O1RmrE_HfpE', 'wEHRmd84Dwc', 'W5eOW25vvbw', 'L_KkjB0Wt_Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19165 ['8ynjAtF5VnA', 'QVpsAY9oR_4', 'ER1fTL9-pQw', 'KoP8T0QqzeM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19166 ['vmz9kAEiTSc', 'A-oSBMP-Zy4', 'MpWGx5odhh8', 'GBLKj2d0iC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19167 ['UtCRBs5p4EQ', 'Bd9TjPP31U0', 'HfBh3lZZi8Q', 'DU5pD63Pv30']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19168 ['_h2rFVPCSPE', '2M-CFCo-rkY', 'OVNVaXZ9D0E', 'Orge4_UlvNI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19169 ['fiAcNMpd2vM', '_XrolyeJXDw', 'Cchf2QH63bI', '4hulNRgH6cI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19170 ['EZJzzWEDtQo', 'uGfd3xanwro', 'IYiHhVWrh0w', 'JN_VJCJhC4Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19171 ['aBXntqgPo6Q', 'qKXhSGaudtk', '_KGUrOb1qgU', 'D9TuP8PKD6M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19172 ['Ae8o_FMI0Xs', '2JnlmS1zzls', 'vZUup6rK728', 'ZMd8mAKe-k8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19173 ['MiWskwqOMrg', 'W_zgEkvp4xU', 'U0sjbOT6hY4', 'g-ZOluGhMoA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19174 ['7xD_Ib3VS_w', 'ot6SpwD1hzk', 'HkCYA4ax4jI', 'aHZdDmYFZN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19175 ['CVgLrsBPt4o', 'VfEJHqtsuIo', 'PFX2OO75sRQ', 'e_W17jp40G4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19176 ['AY_yCk4eTTI', '7IllUjk5fk0', 'oTXKGrB3bCA', 'K6KbEnGnymk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19177 ['19Pp9QEw17U', 'CAL5CgkKkR4', 'm8poFnEbvW8', 'n1fY-23ffl0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19178 ['bQ9vpp_yXvk', 'ZhafwFYgltI', 'Cy3HWnwMLyI', 'AGsMCWB1tTk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.8243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19179 ['XWVGQbfpA0k', 'MP7KPlqoQW0', 'nvrMO6TDu2g', 'ITYv4126yhk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19180 ['WRZGYDh7qRo', 'QUtyeIooCy4', 'PemDZNVE370', 'gz-4W-uEzhc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19181 ['wsdH6cv4YkA', 'zRpPf62Zvto', 'Byk9p21g51g', 'BSLriWJ7hn8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19182 ['0trWdhSvab4', 'Vbcy6KBJsAA', 'O0sDg-yLvlE', 'oZrMoZeJ8Ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19183 ['2VFVe0RCn7g', 'e7WPFeDPFB4', 'wg_kYW4xvz4', 'RGTWqZoswAo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19184 ['6jZ8VNANHwM', 'cbq6Q2htPRM', 'B9IAl-ygE2k', '3Z74i_FWs3o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19185 ['1IMi7yfZVVM', 'myGef3nriL8', 'ojdqgnmcgYM', 'FzG8ZQAhKrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19186 ['GwTXkfuc5v8', 'eW8se7t0s-U', 'MtVLmOvQopM', 'cOsm3r-xKEE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19187 ['6xxu6f0f0e4', 'Ztlcnd14Kn4', '-0xzrMun0Rs', '7nrOZXbpXBo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19188 ['Jsk3ZUGvP-o', 'JDBu-3VCyWc', '3IYd8cCmUkQ', '0vFPs6XsU_Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19189 ['1j4rFfU5XKQ', 'gTO00a-LFYs', 'OmjfHQB_lcs', 'j0UMI2DrnMA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19190 ['92QYLjfo68Q', '8iPpgyEh8WM', '2cxs73i3l1M', 'Lwvf17xUxhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19191 ['szWQPoOH2Rw', 'OHZZuO2vY50', 'cm62raVagEE', 'J0RzvGnQxD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19192 ['wXWpkfGfZD8', 'Zt8x7tvP9Qs', 'Qt8Ze-k2h2o', 'tWexzTJPxQs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19193 ['-Bu7YaslRW0', 'nyjXFx0GSX8', 'oRHKVmQ138Q', '0TV9zvfwFhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19194 ['a2QxlP5DAYQ', 'bmVd2Zj8_Cc', 'WBBKiXYVEdM', 'p_dE26TA8ig']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19195 ['MkTQQ0m8Ys8', 'acEHGV7Gq6U', 'lPFsijo8xYs', 'mu0dlj8ibA4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19196 ['ABSLnckbB8w', 'T0uoYE12cnI', 'JWNWCKdfpzM', 'QZoclbefgak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19197 ['y3Pqe5DLvok', '8pit9UV69S8', '5hyRWertUbI', 'qmR9O2oZCWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19198 ['8OsmFmhNjoA', 'GrbrWNohr6Y', 'HSrzR9hhEe8', 'IT5hcf0KhYE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19199 ['mWL9_WIbykw', 'Q8f6y2IcVg0', 'ZZrvO__SNtA', 'dsf3agfkJDY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19200 ['YOG_PPvTvW0', 'zbCqre50eLM', 'cd5BIQoHyPI', 'Qy77eJc72UQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19201 ['hheF-AgCqIg', '-pUfYFcsgG4', 'qKOsbyT8GCU', 'WrpWb-Zumnc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19202 ['xt6V3Ic72nE', 'Nuks8XFdGMk', 'ESbtW0CUmp4', 'g_bgmnJ1b_g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19203 ['WhNun_U3cRU', 'h0-6U948u7Y', '7_0g3tEcM0w', 'uAgizG1hYw0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19204 ['qFo_gRhW6dQ', 'NWL-P08eM-U', 'cT-KZPVpU9M', 'IpYw4nKPx5o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19205 ['GRdzFvQezUE', 'SW4cW2oU07U', 'fWwV7o4VjEQ', 'jjYXRmE19lQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19206 ['WsaOJT2SsPg', '8yiJOImd6k0', 'DMwvY--3XD0', 'oRUdvu3Qo-E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19207 ['CKEPPcaCjbw', '0rNr_qnoPQ4', 'Aak-VLHtFPM', '8MF6nFj02sM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19208 ['9zW-E0XdWdw', 'w41gqTFYh08', 'tDVOUsG52Jw', 'bxZeGrM_0ac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19209 ['KB4e9v_5uTE', 'pCW5ab3SNcQ', 'FLFmcZiRuzU', 'lZavPVn7O4Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19210 ['-bgHkxwoliw', 'tjQTZM-sqS0', 'ZLXW4ewrVpQ', 'RxmGtt0YzYY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19211 ['FHC7gN3NnX8', 'kAAGkKPVgZ8', 'CRIFRYhiKUA', 'b4FomUpNaJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19212 ['M9mc3HYL_GM', '8tY6nioUQIw', '2MZUbxulAI4', '0Ubu4BqSWmU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19213 ['RF3rog2YjYw', '0_XItMAYkwc', 'lnYOC9tKUBs', 'j8FYy5YfK7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19214 ['XzRxO8n3WRE', '6Yh7Cdm2GgY', 't5P_HJrrD64', 'nkSRzaqpOCQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19215 ['bkQrvXXIRng', 'A2WdjyKQ57A', '4ymXDU-48EE', 'KKgYvcfrxj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19216 ['kmZFn-CQ19A', '9InBmD_Miek', 'Gde1fn1Y1uM', 'h8JS_FEF_fY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19217 ['n1HBKct6rto', 'E_34BmDVnOI', 'OMcoFfaCaGM', 'AVG-Wmdd2yU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19218 ['VMWW9OX1EJM', 'K_ZuxYxxT60', 'chwqnnaiYXw', '4X2aUZFZlzc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19219 ['Z19W44ZI15Q', 'Fy51z2RwH3E', 'YB_PzRgHOeo', 'f_NR19LpA_E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19220 ['xBDcJKb-9vk', 'LjihfG0fit0', 'I4Rhe1XViYg', '-_OzT7Xyvok']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19221 ['9Kut4r8hswE', 'xeHt-R5ScmI', 'JFJuEOZx1K4', '0Olm321vgk8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19222 ['Yd8JBTdUvrw', 'm-S-yqzlOj4', 'E7D42u8a5gc', 'OFJG5Wo_knI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19223 ['4CkJjhuYRmY', 'LyTwxJiSt7A', 'MrMXYO2fzJ4', 'gAQiARaliPA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19224 ['icomsHXY8YA', 'jbyVJdDlo2Q', 'ue1sgGEvkwE', 'uDqVzJtaxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19225 ['VCusyLPrFCo', 'K-zkbbliQcI', 'bl-eQ8XD5CY', '7ITwarmdyfI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19226 ['CLx4iYWSB1c', 'vispMqNJ1j8', '-tpq_bzSKes', '7KCikXm6hic']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19227 ['SU9ZP2pbqyU', '_IkLUOsNHAA', 'Z-G7nL9tiws', 'LCMQXFKMLIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19228 ['7kEeYQx2VLE', 'WI2d5vDJeLo', 'v2Ng8iGwf40', 'mBRr_TqLDf4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19229 ['qV_VxEAXXDU', 'EsHXnkZ_W2c', 'bcybO-SMY5E', '30tNWUyJCog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19230 ['Bx726MYz6Uo', 'T0oF8MyYhBM', 'VwkRHbqpHqk', 'SrLhnoBMyWM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19231 ['y8gB3-yw3tE', 'nVSDv46ARvY', '10dur7jhFQM', 'bf8JlTKzOs8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19232 ['IyJ3a5uuCOs', 'Ovk5EfFj7Ws', '8y36aT4C_c0', '-OUIEnuNd1I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19233 ['JSdALuTneBM', '3VTinB14Pmw', 'hgitRq_0410', 'TSl5LrM6LcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19234 ['fxdWwzdeY_o', 'jx27p7k2lSw', 'GX-QhoihLeI', 'nu_Bl8Pz6PE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19235 ['cWvkOY6OKss', 'zayC5mUo7sY', 'HfzEa06vDLg', '1Ccis4FDGwY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19236 ['LRz6Y6oltQ4', 'XUD-9HkQuTE', '_b-7P-XsnUI', 'iX53Jb72Nwk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19237 ['r5xTmK2Fq1w', 'RIe1omxr7nc', 'XOLVI1bgxqk', '-_6RxZyi30Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19238 ['752bW5cjXzw', 'eSsadT6mh7g', 'dkGXJ6BlCd4', 'PAX2PMha2dU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19239 ['dAAwzwexvUQ', 'UjDh1OlOwuE', 'm--xEFqqrLc', 'euAQCWBX6ns']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.7511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19240 ['vDrbslhtX8o', 'bqPCtwibgPg', 'AJj6GGLaIfI', 'f8nysknTFUo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19241 ['nL4zx0-mi14', 'SKQbQXPjmvE', 'TgCv5a22YUU', '4S4NDnNTptY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19242 ['rsvHQCTgHvg', 'KlVO3gu-j70', 'aryufzYGhbM', '25RWrqQol7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19243 ['SGcjdZ19R1k', 'IwqD859w2_E', 'sHbGsZUsisE', 'UcS5U1mpbAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19244 ['zNgRUFOj3HI', 'Qe71m678qEU', 'D7z2Q-hH25s', '_n9boKzVRhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19245 ['fvpDYGzdRmo', 'J4DrdTy52kg', 'M7fsgHyiicM', 'DpAfyjjQJyk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19246 ['oNggxSyyyq8', 'L47F51OmZXo', 'ggBivmG6yHQ', 'oMgSuyPBINs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19247 ['4M_k01zIbVM', 'TLMEsc_42Gw', 'Y0_Ixl1d7oQ', 'uE3BHXXiCFs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19248 ['HtRjRuKnvjI', '-cLzki-B06o', 'WAxDN-FyPn8', 'P9fh7rOIKcM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19249 ['3obJKn19jTE', 'CfRzy-RtqnQ', 'w4Z1QuBOMWU', 'oTzTZqDOIt0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19250 ['3_M9ZMo5TiU', 'hlquKjPgxmY', 'WO_Y7djT2k4', 'Ypuv3htJlpg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19251 ['MKikHxKeodA', 'XnHAH2aPHk0', 'Pzp_oTEn0Yk', '3R8xDvhJk54']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19252 ['PIIAyM4H1UE', 'cLIump75aC0', 'xKrdOZAp2w0', 'mwLrABPxvgA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19253 ['h9zF09TMgLU', 'hIEj8msjg8E', 'r4nPBNL3D0E', 'gWRfk8nCcPs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19254 ['VdYakZ4Yciw', '0x6chChxzV0', '81SgTHg66QY', 'sU08gu2zJ4c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19255 ['3NAqH9LYDyU', 'GBMlv6j0WJ8', 'fX8A5Uxc8R0', '-UuEBhule84']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19256 ['oag3I4VRXyM', '9ohu45KlgYA', 'PkkhCW04O9k', 'b0dVykd2i6g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19257 ['14hTDUjCr_g', '63jbksEqycQ', 'IKq2OF8jq1c', 'zmbwvsdXlBU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19258 ['iaonijK95qA', 'ao-TFiShaWU', 'YrGQKTbiG1g', 'hgGCfJoYDUU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19259 ['J48F0e0guSQ', 'CXCbBSUuugs', 'Ck_bvV8Aa-k', 'NxdQtpceXaI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19260 ['TPdqEmS1Dr0', 'nsxaoH9DjDo', 'B1va1NqaA4o', 'XykUpCigu4w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19261 ['CYuYfvQv4eo', 'VCIN1OJkNbg', 'TokHdpvX7Es', 'gp7j9o2x9co']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19262 ['zPMiMXCazAI', 'BlsbeyimUDE', '1DNoynuGLV4', 'Hp-lgcs4VXY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19263 ['nbb8vmfjHJs', 'tc7crRl2JqA', 'guRyU4B5LlA', 'Zbmm_hXcrA0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19264 ['xuxKtxzq2Cs', 'tlDBOenCGV4', 'afb7pI_01O4', '_2wFjBoreaY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19265 ['_vwBe9ZXWXE', 'UfZP677y3Dc', 'n16ZUTfZtDM', 'd1nz5tZckSA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19266 ['Ou7vteWmqfw', 'bZXQlQnleL4', '40D4L5Ndi6k', '5MOJnA715fA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19267 ['y9hdu9iMBG8', 'aCA4yiPfFIg', '09lQmg2wvsY', 'B5XTBvnpwqU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19268 ['n_REM0fSVrA', 'tPVsTFGWU5Q', '7-mNJ4IUY5Q', 'l6LUPlmua6I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19269 ['wraN7rWUsfI', '4Vg0PQuHTk0', 'AF7sah5a_DE', 'tju-t_Bz_W8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19270 ['OseeYF_ud7g', '5mmUQUwr6tI', 'qlk02ytcnPU', 'Ex0ukzO5z9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19271 ['-6pcgdLfb_A', 'FGoDfNZezh0', 'ZLxhZcS3Ppw', '0nNmbkU8GBI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.6742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19272 ['ABr4Q_ecoPw', 'CKkbZCb9Y18', '5F8zpfwFKl0', '9ZUzftiN2uw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19273 ['nBiHncFD0dM', '5nJr7iar6ZM', 'D-PxXM2I5gY', 'KzzKguqINa8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19274 ['bLjOJRg2P_Q', 'Hl8OrRlMwi4', 'KCs_VPmsnKo', '_pU2KbHMN4Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19275 ['O8EMm4QJjeo', 'GAoGADilmV8', 'W3lKc2hj4XU', '_nrz_BawPMY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19276 ['sRxUm-ziCBo', '6HQqly6duac', 'tuoBmxts5Xo', 'g-9SK0or81c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19277 ['X28GWrn9LlI', '_RrA-0lfIiU', 'JFGNmPzPXeA', 'WmTDKYYH5OU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19278 ['yl6LJDi0gi0', 'X7qFgrAl3OU', 'Vx_vqfpRdUU', '9mqA4YdX444']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19279 ['MeA8CSKAuvw', 'WWIT13tTW7c', '95ThRxhl-ug', '11D0JdB7_4k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19280 ['iePMcLYozYY', 'CnTMm-bzssM', 'Hc_UM8l_sTg', 'c9tRbWSk7c4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19281 ['UVMBRVJTvzg', 'gDm4IphrlYg', 'eiyyoUt64Zc', '-zA6LL78KYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19282 ['WoWF7gGzGVY', '7_Sr2zv1sQc', 'kMNL4Y4XMhc', 'pz8P96myUZk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19283 ['HWe3TSUcvHc', 'cdUk-F-5NCI', '50fuQm8B2Yg', 'BC7dI3lQ2Cg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19284 ['vyNstX5b1V8', 'sDX_95H0f9Q', 'DhnNZn8JjEQ', 'DUNOn71oGCw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19285 ['nSLxQLYYoNE', '1FU5odlgLmo', 'AuZNuyR2OJs', 'dSJpZQ8u_xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19286 ['i6k1yiyO5jQ', 'KCytKo5LzCc', '_Slo8QXYOp8', 'zu_1zpF--Zg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19287 ['r7Ve8ExE8YY', 'S29WiN-bTWo', 'Uvn7waPvseo', 'GuQFhmGqdog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19288 ['gxzU5EqNL14', '_WYwB1qRgLM', 'lRC2lurjPBw', 'Nep_3Y81E_w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19289 ['mMT1kEejAG8', 'iSw-5EjXgXc', 'hFqZZrj0rnM', 'w62KGC7um_Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19290 ['9Qd6AdTq3Ls', 'Ts3ZcUaELzA', 'Ofry7lyQZDA', 'Guu30szkA-0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19291 ['1nUqhH8bAPk', 'sgVqMKtUMsA', 'e5SK6olIYcY', 'CrbZHPkHeV4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19292 ['HuVgc2jf0Ec', 'VZfrDZhI7BU', 'KY5TY6ovKQg', 'CwImmV7q1MY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19293 ['l1coM570kVw', 'itT0_RhSipQ', 'xCLzxuZE3yg', '2zjtZYqg3Ow']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19294 ['q9Gh-zh-5Ig', 'wKoFJHb2BoI', 'ZleHXDirD58', 'KE-TVQhdCbs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19295 ['dalyCstquy8', 'GWxiiDBK5s8', 'rNKJXwMz9XQ', 'NwfEO8cjSK0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19296 ['UJAk1nNdo1I', 'YwUa3OS92ZQ', 'WiAFUo2nxIk', 'SGF4N3JHF7Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19297 ['b8cgQBzBXi8', 'lFv1MJSSWNs', '6k6tF0s0lNs', 'AaVUuKl8294']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19298 ['pnh_C1w4yGc', 'tEZU-ZRhSoY', 'RDCXvJPzT5k', 'HhQTvaZtURY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19299 ['15Mw2jyyHk0', 'XjUmXwVlDDo', '8BJljuSm2Aw', 'D3f5VIJYR7M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19300 ['d9Oa-2_r2j0', 'LybSS4amIS0', 'S_Z7o4OmU30', 'evscfdO-oSY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19301 ['AkHaDKuiE_s', 'fAHYe-qmFnU', 'TArWNq2retM', 'tJHFSRTPyew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19302 ['uoZ9Rs4E-6Y', 'IUD_ZYOh2MM', 'V5HMIxuAtv8', 'hk-1KRWTM-4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19303 ['qEJ_jxZzt7k', 'Vwekk3EOa-U', 'wR7n4Gg-_ac', 'VNjYW4OXqTs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19304 ['0K-zyeLuKho', 'Yt1czlnCUCg', 'DysXetu2I0E', 'aKhM6zyL--k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19305 ['oJyyNWuyig4', 'WCifI6rwOoM', 'HJuR9WJ1iRY', 'r2gYE6-cGx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19306 ['gVMoI2ukbtc', 'm1ov6te6jK8', 'S2u5IE0n1ws', 'vG0FGgJlDGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19307 ['JCsuOzlwJqA', 'AkbCw7oVkw0', 'lAMiOhScSPg', '-v5hgCh3M2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19308 ['5bn7PPKcqSA', 'QJzveo6IBsU', '0wYi8B9PXDY', 'qIxpfaeZ-zs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19309 ['OgqDO1wxQ8E', 'CM7jMnBXw2Y', 'He63KV_9Pwg', 'qI-Ji4gtBPM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19310 ['KnZeEWVHaLc', 'WjPHxUtF9go', 'P2F4iNqJmNU', 'dSs4xfvATjc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19311 ['SvsCM0fLM5g', 'gNjeps3EbJA', 'xiN6XwZNEJo', '8zCZzzAaC4I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19312 ['bTLgeqCaYMY', '1heMbyumHAo', 'EkMgPJfSL04', 'E4To9BC2jx8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19313 ['2ZgEbNi--8Q', '_9OUh0uwDec', '2T1P9ovsl4A', 'R4b_-IT43P4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19314 ['HtXtfCR-MUg', 'PdgswSjYhMw', 'BYnYTgeM6Go', 'O6QyYC7Tt2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19315 ['BXv69uAoHk4', '4HfU5OQUqq0', 'WT_wvvEvkw4', 'odzi_VK8m3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19316 ['RPqz3vJYMLQ', 'dMfKImuNJjA', 'Emc18GpAeRY', 'CudxWnS7ukw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19317 ['5DNl3DX4rr0', 'ItSLkF6O3Mk', 'UvCY9FHpKC8', 'dHDosntsNho']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19318 ['55qucu8Zs_I', 'Jcd63Ev7JXA', 'HYjSrwSm0T4', 'kUQ1xfK82Q0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19319 ['0F-Z0zF1504', 'kgf4GdKlSWs', 'FMjUGdTn7lU', 'yIOUPSGFqoY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19320 ['BkSCfcTBMRY', 'u_TfWvyYY0Y', 'UPPHkyd7lwE', 'LWIHz5kao3g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19321 ['qlklggFvAZs', 'JzJCn-puzS4', 'ClK_qf_Twm8', '59Mt7J_0KT4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19322 ['ib8pMT_ug7o', 'KzvdKLdBw3s', '1_YHHL_t2GI', 'fEfe8jznp5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19323 ['WyGJdstaxK4', '7chwYGGSkmE', 'vqRFzhWik2c', '6Kb0q9J8lPA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19324 ['OTu_vWZV4QA', 'MSHbLrVlrQc', 'yi4-kGV30qs', 'qrY7PW5guxk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19325 ['t9aSL2MwEDM', 'zOvFaef41iw', 'lHlOSsnP48c', 'S7igso5_MBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19326 ['LFW4yPH1z3M', 'c3T1gWSVp6c', 'xuepy6SFOf8', 'qyCea2TuUV4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19327 ['BZyf8LPltYs', 'eJFZuX0WHgk', 'WKL40jfQD3g', 'Ss1bubMNPQE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19328 ['liagR7x12O4', 'i_G_0vgEYJg', 'DU3Vlaa8rU0', 'MdYXznF3Eac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19329 ['cnmedj0fYTQ', '-jpbCWcz2pk', 'ULXbXpLcoVA', 'OiNlYrlJE4g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19330 ['N6YT8_jlt0E', 'fPIG7nrpgec', 'QIjShFhrp6w', 'rnOIXOGfSUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19331 ['YZx0_GRtvJk', 'CEJXvm2vH_4', 'rG_6MS6_K6g', 'A_NkQM85g6Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19332 ['XjGm3Bn4j5k', 'BojCkFK3pNg', 'Jdy08IPLKdw', 'aPafZ1Mx-BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19333 ['e8xkukid_2o', '2xQuWif8axE', 'jXi1dFAB0n8', 'fQiSoVDFRjo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19334 ['dwAo0dKCyBI', '2o1p83UjJFA', 'CRxIJ7YbcZA', '8nJ2MhvhnJ0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19335 ['4ufDENm_ECk', 'mOn13E68Td0', 'brEMnFXsTqo', 'uQE3fLdzpKs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19336 ['SyJT8XsFsmE', 'W0aT3SdtnfY', 'gIFg6jvXgb4', '1GCOnj53QYM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19337 ['yVWk3yq3Abc', 'kH-F9JzC7eE', 'en0haa37gnk', '1ILLsA6gqHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19338 ['AgVUGzrzJ20', 'Pn8HqUbNQAc', 'VpIhbDN58mA', 'QBMM1ocXkhY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19339 ['WvaIypMvAHY', '8CY7G2NrlxY', 'KjJj5-HvSvQ', 'jR_wBfxgZwE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19340 ['yTq3Kr3jkvs', 'MZhaDGgULtc', 'ksImihlU3qM', '9mIDP_OT1uM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19341 ['Yk2ZrS0ZS6g', 'pL71P2hVjMc', 'lDnYXLGEEFQ', 'kw2wPVxUgQY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19342 ['5LX2Unga1p4', 'NJGo2fmUAII', 'AgCSBCsHkMk', 'LHTA8VZGoMs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19343 ['Arqvnp6yUCg', 'Fg8yzA7zifw', '4mC6K77Y_Ho', 'Pln4GLIMqKY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19344 ['UsHtZ7Bzi0s', 'Pv8ZWvM8bhw', 'pHFHsubQVpg', 'Gw0KmZ3kbjs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19345 ['BxQSEvHdyjQ', '9Rx57dlJtIA', 'RIiN9Ed1fqU', 'bJ6e9Ja1ahQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19346 ['zyXa2tdBTGc', 'ztfegVzqeCI', 'VpikuLP_9qQ', '-sRFfU8k0Zs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19347 ['zaEdWwSamS0', '6yB6plsrjO0', 'Z31gI08SMzI', 'IOzWDVGWRng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19348 ['LPA8RDzl-Ss', 'asT8yaJPP1s', 'bg_QoesbfOA', '69oU6LfyQ_4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19349 ['nb_7c2xPKYA', 'mx7kjFY7ALs', '5FbQu7QTme0', '79tuMIiWMZ4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19350 ['E3F9bzeCgTQ', 'w-qG-P9E1U4', '_yzcCFe-uo0', 'yKx_RFUTPfI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19351 ['XkBXsaSXDJ0', 'GopccU3Am1w', 'zwfo7wnXdjs', 'ciJOulWFhfA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19352 ['POOu05eUvqE', 'b-Y-AjW6MJ0', 'ZNGJN30LCwM', 'khQN5ylb3H0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19353 ['bciw4Tqp6h4', '1uHF1-8TcEk', '0LE6Ll1rVlg', 'cabjr3xtcR4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19354 ['VCozi4GDpxQ', 'qOTk01gmrRo', 'sZQ4TeLueSs', 'bBy0NCoCEHc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19355 ['T78nMdsJMmk', 'iMmYVLSb1IY', '2ZogsGp-T4o', 'GMtb7U-8IYM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19356 ['91AmOKytRUM', 'CrjSYvGWusQ', 'RXk0lQJ7ttc', 'mhqHHQ1gSvM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19357 ['3KQy3Cajo4E', '3pU34vUoO9g', 'Dv21JlCT4_k', '31O2j4aAgYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19358 ['qwGT6wvYdLo', 'diSfkEkTVkE', '940MNbCeobw', 'vfMEPOl1Wqw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19359 ['3JYQgXudiH8', 'EmSZKb0LdVM', 'NeSIT6sqLRA', 'Hob0LAu8afQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19360 ['fow1TC_MpHs', 'Sa3Ky5sJshU', 'SkZ7mGbs3SI', 'ItstzW7xuDU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19361 ['yhS-6Y8ToR8', 'OAl2EjbdQG8', 'm-xxD1fGPnU', 'AuvFmMpgj70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19362 ['WNmAlKrAPjQ', 'j9UZv0GOJ_I', 'ow7xqVk8Wjs', 'afavVsmFWds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19363 ['W00eTCOgUNs', 'CRHEuoCnI74', '42QgE4mM55I', 'Q75y0TIp7Ds']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19364 ['WZd2nT2Afds', '_94ra2KoZGo', '71KE7B1vvdI', 'TWnrcjA6VTk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19365 ['eYngZ5It0b8', 'NP5iO_HB-f0', 'WoXgPQQjcJU', 'erHadqauC8A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19366 ['An-4jPvUT14', 'tV3rvUSlVnY', 'AAWe4zRLVVU', 'ZSItez9gTyY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19367 ['AHrUfa2H_5s', 'r-PBeJiE5sc', 'EQHrQIaQNv8', 'G_iJif-fC6E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19368 ['BMPmavj4keA', 'DZ3EShJzOOc', 'wL4HaT8rEVU', 'GcOOmVSM8Uw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19369 ['PqN7aT4dVN4', 'm4bBsvuS4EU', 'GW6pti04qIo', 'PBqNpMpD76k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19370 ['Q1LJotkUbUY', '7NnvEryyYdo', 'BjqhHeJD28U', '6ragcEJVErI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19371 ['yx7BZ_djE-U', '4dilYyxYLmM', '6PWiDlWmPs0', '7FkuqqdWRhw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19372 ['Or4CALipjig', 'HDSV7Pzq8CA', '3w3fD54bNvU', 'ac_8oRMgDz0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 57])\n",
            "Loss tensor(0.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19373 ['476vNb6thyM', 'Ld5G00HlbQs', '577NM64YL18', 'D4GVgBX1eYc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19374 ['D3ht_xXl5S0', 'EO_tdzbN75Q', 'vQcB6NI7cMo', '1PSzSTilu_s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19375 ['rQcecqZtGvE', 'q6GBCmLxNIk', 'SwaqANBpZGY', 'XgOA5oRkL2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19376 ['iQAXwX28LLw', '1tz4xNRRR4M', '5at69yM1PoU', '-cQ-jUTEgck']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19377 ['ZOGMpGQQ3FI', 'ZFG9jHrLtBE', '0kQjfwXjFuY', 'VtHkxrta5xQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19378 ['AVPm96vrUQw', '1cwGW0cBdRs', 'EQVZLtlDkHw', 'j43Dwqzd8w8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19379 ['UhwJrftWAFg', 'LP1yZRsRllQ', 'BurGML_ZqSA', 'BHDhHO7J-Oo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19380 ['EKt_KEbqQfQ', '9ZinCW4jTeE', 'muwIU0BHXE0', 'C3o8pEsAu5U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19381 ['0OhtODbKajw', 'aq3vov8-fw8', 'Kqo7am5oq0U', 'D2w3qHmJrdU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.6409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19382 ['as7MhTe961k', 'KEp2NhraIZI', 'HXG8DnTpyPc', '7NF2kcEfMBI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19383 ['AJTU5RhF3S4', 'WW4_c2J79QA', 'vrMmkVV4SOE', 'ndjLkbP6Y9Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19384 ['iqOPJWWKo90', '_mQ6KuA2p6k', '8oUI02eK3SM', 'UDN11Q90Fa4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19385 ['7Ht_Vu1D8nc', 'VzFpg271sm8', 'i8PFu7AiwaE', 'SLcIv8CNk20']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19386 ['chfTjqlrFQQ', 'sQMzHk9MRAI', 'Uu8m1oOWkiE', '7uKkUTml-DA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19387 ['WKYUiLace9Y', 'Hrgl_1rGGU4', 'QutCXtWmzIs', '3HtfWSbmuAc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19388 ['3rbWoeUg9yo', 'M9MgZXkYRBs', 'gpEU6RafUf0', 'oSoP9Is0UH4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19389 ['HCCGZh-TxK0', '75_dMqpSM4o', '6o6DsSnbpxE', 'XhV4zf-Xlmk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19390 ['yfXvz2FyZ_U', '-i9gpG3vPwA', 'ymGg5TA2YfM', '-SD43H5B5hE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19391 ['YbLR6dgY-K4', 'hKSg3zFB2dE', 'JHvLuYk6TfI', 'Ime3FHuQG4k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19392 ['PduP4CpaDtY', '3rvqiSZB4pA', 'qwz7oLASJqg', 'rKRI5UcIICI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19393 ['P3ZPbGjHFXE', 'g0AXzsecS5M', 'nEOPm7TeydY', 'A2pgKzeDRqg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19394 ['SOzuJU25uGc', 'nvRd4xgEWbw', 'hbqdthlv6CU', '68XchGI6H-4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19395 ['2f1UXGix_Cw', 'vp6p45b-038', 'r4JRDHYukZ4', 'TIASpLtI8ks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19396 ['5ieMy-PAKA0', 'KlD1u-EDx_g', 'yn4-OtUmyWo', '3B-YYTbpFZE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19397 ['_1woPC5HWSg', 'S7TYAcOEPt4', 'flLjMZMydXc', 'uKGo4phKqLM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19398 ['QBhhtVMiQBQ', 'NlCfScKw_Mk', 'y6iMm7Pltq0', 's1JHUf3Q_F0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19399 ['C-1i2GlbiIY', 'Bl-lCgr5hGY', 'JCfZpSEH77Y', 'hBQFoDI3NMI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19400 ['9IdAIIywBfY', 'ByOqw8M2U-Q', 'D644BWAUOXo', 'gigxzYegRqM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19401 ['5DDg2CzAmgE', '5-aS_pyXesM', 'DEnayQZiPGc', 'Wil8e6kBxe8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19402 ['PbUyPbafFh0', 'sUjAb0SfppQ', 'CwHSb1NOi4c', 'AUPmWhim37Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19403 ['614LdgrE13A', 'XzwhTltRQcM', 'd61plJ66vE8', 'D7Cvisf3jf8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19404 ['vKNGqQ3GRB8', '-f6s6kQEHFY', 'qMbGFWz9who', 'hTAWbHXCJ2A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19405 ['uNUx8rqcy0M', '2umjh27MkjU', 'KV4noVyGHa4', 'bl8PgmZ9iOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19406 ['KabP9iNokps', 'MyH8zQw9csc', 'm9tnNkon_iw', 'YFXSbPFaxcA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19407 ['u3pYqyLM0f4', 'xLQF7S41XLE', 'ZkfKOLp5SxU', 'H_He9_zHk8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19408 ['-zOybsEdM5E', '7_q36NyJtQY', 'QHmGUrpOgAU', 'nT1YAP4Vy9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19409 ['s1l4Zjqoqdg', 'dh9XweTn6rI', 'xzU6sJot-Gk', '52GYcHTcCgs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19410 ['lI8aGjIb8Jg', 'ew-7SwLcHBg', '1MwaXCfUvX8', 'P996TZp25PM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19411 ['GF8QWSW0UbY', '4W3Ql8JbEN8', 'r_TgaHCsYB0', '1WlvXneu6oY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19412 ['UkTWmyy7ia8', 'DdxW_JziHTA', '3XL825fK6UM', 'Ehks1uuwR3s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19413 ['vsDriIwNAmU', 'swIXVQtP_TI', '3w4nFQrUQ8k', 'ZfR3_QJF8f4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19414 ['VlgOLOoctm0', 'Ir82jewhXCo', 'YnE5ONaXtLY', 'DLDZrtwyY_Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19415 ['5n8I-br2n1U', 'cn-SilfYLZo', 'W7i4LkdSfjw', 'sL01xTmV_Fc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19416 ['cY3g6N5Sokk', 'feC0L9MtghM', '-Umconw-CRE', 'A6HJBIU1rD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19417 ['YE2rN3xknlk', 'B_kAtTBUDIA', 'EkmHGd0U8yE', 'BVt8RgNrwbQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19418 ['A5fPSkTvjmY', 'PlQibWaPAcM', 'ymuRKv9iJm4', 'LAHWV6fZwUk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19419 ['X-uVubaJ3II', '244y56-vLWE', 'nU7x170OvJ4', 'paeNnR33i5Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19420 ['cG1dpyC8gV4', 'n3X8RGZsGg4', 'sDoV3sMgDhE', 'lSb7Y-_3to8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.6454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19421 ['iqEQBCrOLWc', 'XYOnq7ju7o0', '8jDanS4ZzRc', '-0vPFx-wRRI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19422 ['-1UWSisR2zo', 'EGIeykrN4eg', '8Ha5qGnT7lg', 'sYIymaJi6tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19423 ['Tt3BnoJw8ds', '9K8EePrEDdo', 'iUxy2s5d60o', '-VI2IRq17rs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19424 ['7JE2eBK1f9M', 'hRbukCd6N68', 'WmyhSRhWh3k', 'OEjgIDubFbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19425 ['Ca3b8qNUbsk', 'TnJE6W6Z6mM', 'N_LKZjw9DLk', 'U4UtZeTl2DE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19426 ['nqcVA89BD6I', 'SEHE3WGui30', 'xrqDoBor2dk', 'c9JyKnsegog']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19427 ['rLQ93N6RJC0', 'BBmXMoI9Qus', 'pte5jvRKwsA', 'uTfLf1Y8hhM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19428 ['1ACn3u5UnBw', 'T9dKp1EN4p8', 'VDYqYuPzW8E', 'ohikUtjUN7c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19429 ['OoyxPPoPmt0', 'K9zE9x2ccJk', 'NwA9JSlK_lM', 'n179cK8EubU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19430 ['GUwBLItoJXk', 'cJ80eZY03Yg', 'WditOomsdRU', '9Y8NR6nDxjk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19431 ['vmVOWilkmOA', 'BquHBzP5Ep0', '4TDtUHo5cSE', 'KUE_I30--AY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19432 ['KdNhYvN4Xoo', 'JOhK7oq9KtU', '7_80oVTLkGU', 'iYWvaxU5OXk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19433 ['C7WAx3n57Hk', 'jBmP7xTI_TA', '4Gow6qZcNZI', 'iUHqyjf3NcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19434 ['9YnYlDFKn-U', 'zYM0gtd_PRo', '-4NLarMj4xU', '1SO5RJLWKAs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19435 ['qaQjG9SwORU', '7AC9RqECN5k', 'gTX4SG70cEY', '-hSMzrWZCAE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19436 ['2vQTq4QLP8U', 'yfZ0z1C3blk', 'sfmAeijj5cM', '28wBrNjHXOM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19437 ['zWJC_qr2610', 'DTkKGYCRMlc', 'OzaVvthCvtk', 'YAYp2E5vMNw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19438 ['UQKLBsZJsww', 'UxT3KG4AHAI', 'echeYDYFhlY', '4QES-SJ7mP0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19439 ['ZM0imDMXuw8', 'SEDfsU63w8I', 'tUZB_Xf1m6k', 'YcWJUHWt-64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19440 ['GWcMqKYOJR4', 'xzgnLpKkvdg', 'qW4kBJsudLI', 'L5UDz2PJ9sk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19441 ['_78P-0zWJtg', 'BEZdszHKGTQ', 'n_boIyhZqWc', 'HwGK5RvNOFI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19442 ['RDNatVYvpeA', 'YNoR-SR5t1s', 'w9EGDo9Yybc', '6lPgzqrvHHw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19443 ['L0oun9F67tg', 'e2tZmQI8ICw', 'hBT0bbJl1dU', 'TA-O_bVnvLY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19444 ['WMtztIW1f6k', 'QUB_vpjogmo', 'AzWIKyRnhG8', 'GG6XkHATIyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.8097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19445 ['Ns-iXXKmzzU', 'l5QPXVIxxwk', 'Wu-Oh9OJIlI', 'MfX7Q0ucts8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19446 ['l0fCHZhKEDA', 'aO0QzRPiEC4', '3sIlpn9nvKU', '6YXjJ6ABnZU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19447 ['zdtVT2xwrHU', '3EXXs3x4Ius', 'DC0C-KO9EJk', 'Lc6OfmzV7Pk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19448 ['54yI3In3DrU', 'LSaLPObrnZw', 'RdKQGIzKZ_c', 'L9GXrmmlYhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19449 ['CxTFgimfNfA', 'grisjVTZeTk', '1JqNiV03kog', 'BL181hSAG60']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19450 ['9gkppwB5CXA', 'RFKTlhbnfXA', 'SUclDZHax0w', 'B_ohqOgK6T8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19451 ['xUVvBF9BWdg', '6-CMq6xw0fg', 'hlHb9HwNxk8', '-qcTD2o6I9s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19452 ['j-TVVmVmygg', 'D3FyfFIKLVc', 'KLFoZA8btu4', 'TCRxCAYyduo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19453 ['-YATTKBtmRA', 'XdBf_omYIO4', 'kdxW11WBlQE', 'HQb2jhmw1BE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19454 ['_u2cNlW5DxQ', 'hTlIqICkbW8', '3OLeJZF4oI0', 'TPYNIc_M1ng']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19455 ['2z1elo4ucis', 'KoAGZ_dB8MM', 'ikEuQPSBY-0', 'Pgpd1yxLcLI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.6624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19456 ['HY1KdNS19CM', 'j0FynYzQvcM', 'oGbNzR_lpSk', 'MHkfPjW0aRg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19457 ['YW4AKwkpYxs', 'yO7MWuJ7zLA', 'hrCf8rMBtA8', 'c6Fiz5IznkU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19458 ['lNg2y6SRZPo', 'WCiS9IDILQg', 'G7pD1K3jYg4', 'ATDi-irUEWc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19459 ['h-3DrDQC62k', 'R5KBk76b9HE', 'YxkYVsE0UdQ', 'AVVfOYSmexM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19460 ['67S7s_jFXhc', 'lYtoy8sa-Q0', 'GwxSvUoYSZg', 'cOgNXgF21u4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19461 ['19-GI2LzOtc', 'Qz2PIXM60iE', 'B-1QW7g81gA', 'Gow0TlxIx7U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19462 ['4gEmWJCPZGo', 'sgJT5lIFttM', 'CM2rKZmcR0I', 'bTlp5Qr99RY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19463 ['2zrPFxxT1VM', 'Xm2ciX0_UP8', '2IpapScfsT4', 'Y8ULUSXWTcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19464 ['ksYM8YzzWXo', 's3Q8pVDY7ZI', 'fU9woCZqemw', 'KDzy3ZL626U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19465 ['F2ekiX14ID4', 'M-RX7LqL50A', '2qO-OQtOBK0', '6cQjwXNY4sc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19466 ['9kt7rsziUVQ', 'XUzaEsoOlWQ', 't8uF3PZ3KGQ', 'EZAwPnGOJPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19467 ['nBSMh7pgn2o', 'aWK9CcvOK9w', 'gkMbHlNAFig', 'bqeVxA97TQU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19468 ['15CZ2h5VL-A', 'BdhaR2QUGqY', 'A2NtJ12KIuU', 'lV0-LMVpZLg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19469 ['ql7aH8wF6JM', '2y1QnNBaxAU', 'LK6zk03lPlM', 'mQ1E8rx2dnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19470 ['qtnE1hnCD0M', 'eISYX9koocM', 'CD3OyaDW348', 'B00nfVc4FPI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.5587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19471 ['AmAThmRphk0', 'tmabzx6yxqs', 'qeoYWM1uYPI', 'R5JRh08zgMo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19472 ['_KYo_89lgf0', 'nnc6m1pBJ4c', 'Fa1KdG8niq0', 'smU92Nu0FmY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19473 ['eUZ-v8GEcNk', 'UR3k09hOxI4', 'C6m_OWe-JE4', 'hwSOjoHFLn4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19474 ['evG8CQRCdV8', 'FFQVVwFjy7s', '0oIFGARD9xE', 'CZuH43NPynA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19475 ['frqnZb8Ssjo', 'gCSShNsw-_A', 'BsLFQV8HVZE', 'hvmCuosF0Xo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19476 ['qcjzfHmQvxg', '0a6uLBmqZgA', 'fAfk9yrGhWw', '5pIdH6p3kuo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19477 ['WTVC7ZI9WtY', 'O28kY0aN8VI', 'Q2Omtt4A8ls', 'VHyXvbg6y9M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19478 ['Inuq5W98ktA', 'XjoRxeEyjz4', 'mRKud6yP4iU', '8pYHLfKqHL4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19479 ['91Qp8XUskXo', '6nWWTNVRDjw', '23xC7lTBikU', 'GuHDy--gWiM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19480 ['fXhN3_gGpQw', '3e6GleQ9sl0', 'S8WTaKLpmmg', '7RtQpW2dSU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19481 ['4Mm5mBgktG0', 'A_oaLt-n4fQ', 't7oAteGa55g', '6jdeSAmkzEU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19482 ['kMK10SknFAI', '3bg0iy-ypcw', 'R6k2BkwZt1Y', 'UO9HtZMrbBE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19483 ['yBYd03Hr2kQ', 'YddV91xnUz4', 'O2HttJtcec4', 'R6lRMU-zBLA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19484 ['VSf3_XpiPkQ', 'FXVu-YwjhxM', 'nY4tpb8O_Rg', 'VlXi2TxMXbc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19485 ['AzhfZ8rNhRk', 'pKFXFu8st9I', 'HyJ2YaNrA3U', 'Brc_nOquNbY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19486 ['65KYS3lIRII', 'UhcoWyEQwBI', 'd-KxsdWX9xE', 't3758pixHZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19487 ['1xhwyUVSRQk', 'svNayU6q3Dg', 'HFVM5pVTwkM', '9ZeoYezrI7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19488 ['5xAzHL8Zlcs', '3sRO6iwfUxo', 'ihJT65fZaHY', '0a91szM1Ivw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19489 ['XWhmLbnrtd0', 'fhWzjWZqzvs', '2juYRZnhF3g', 'ZVMIk3xYaYo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19490 ['NSyqj1DXZKg', 'UinQGYfmZhE', 'pcOPueObfWs', 'f7OQTtTdgrA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19491 ['3TQmts_MxyQ', 'RS43EP1EXz4', 'lfCWGQ6URds', '-wymN80CiYU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19492 ['4jzr88nEdCM', 'u3n2OcpEC48', 'UEOUXjX5R2I', 'mqyeBqaUeN8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19493 ['entThp930cw', 'BsVsoZ4ojp0', 'QqRrZzOY2xw', 'UxrAsZ7Z09Y']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19494 ['0hfU27A6tus', '1RhYdQnZ_hw', 'DYp8940tHso', 'zTuxNA1y6Os']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19495 ['UOC4VWQpnDM', '4M0njWKFsME', 'tMMjurLqYJQ', 'vnwKpQeza3A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19496 ['IiBgER0W8iA', 'dzW5M4sCphI', 'p2fXNAPYD20', 'Ux3YosKD-9I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19497 ['Vx4aO4-nr0c', 'gEYTdeQiFv8', 'I368EWBLIs4', '9aE33JEIGOg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19498 ['VuWr1HXHoZg', 'mMf4vJFT8Fw', 'thHSYzhoLo4', 'woyCm7d2UIM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19499 ['CdFutCUKTXI', 'fUC45bzOOJw', 'O5IulN0n6d0', 'SSVlD_ZDb70']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 51])\n",
            "Loss tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19500 ['YFhbrSUb0JQ', '8MbxazeMw2E', '4CrPPlHN9_s', 'Pf9AaTV4-yw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.6062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19501 ['1ypKEH2kd7g', 'W7KbboEOmeM', 'ODRAYQE9GXs', 'b12xqPnM0So']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19502 ['ua0hgl8fi0I', '5qVc9y3TNnY', 'NdiSW-p2I0c', '-BIMKnb3tlo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19503 ['vBkDLBO-Aok', '-T4GeTHKtJQ', 'tUBTRs7Avk0', 'oBBTqXQFTiA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19504 ['8hO1S9VIfPY', 'p4T1pddBia0', 'Y02VBGoTi9w', 'x1S2oreZBWU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19505 ['Zmtw8tP-KFo', 'IhNPDueFVSo', 'I-Z3gB6pfIA', 'qtNTHnXOQew']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.7044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19506 ['IC_Wpalzzm8', 'IcPbxJRbe5g', 'bxF2vxTzlvo', 'p2yedR_jMTU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19507 ['qDiTICmdUQg', '4LZSSya3ZZQ', '7avMUhHOCR8', 'e1KHGfMekek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19508 ['4ueN2gGsH5Y', '1FnT0RrfMEA', 'TZlFTbvfKPE', 'u6tgeRXOxnU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19509 ['AVuh8-CucrE', 'w3QIsHxQfPE', 's1eMgmzCMDM', 'Xxe6vTEwFvs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19510 ['FXQxobF8FWw', 'J7d3nuS9wqg', 'OwukabRF7I4', 'W2EJai-3k2w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19511 ['P5IxlG4-CY8', 'OiAJB9uydS8', 'HTQySJM4Jhg', 'u0CgRmXMXNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19512 ['ikJKSqnTylI', 'uJPW9BEhU6Y', 'mJuJfKbcJcw', 'D_QEW1Lnl2Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19513 ['I5CBPhpimtg', '58f4AsxOYhU', 'lRTeWmoeen4', 'ZFg6KpT5ehU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19514 ['Pm6vRblouxc', 'xseL3oZc7pY', 'ZahBai58_Ec', 'PE1ges9nn6A']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.5205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19515 ['m9MQdg0k1t0', 'RoDS0k7qrIo', 'QtjMlA_7dds', 'bTuKGXDrqdQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19516 ['pIE-3sIPlvY', '3tlaELkmRqs', 'iTWZsfVCyBs', 'N_Wx35sNqdM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19517 ['d352jaSSiFw', 'FkpJaXzgMBQ', 'macnXLRXbHU', 'q-sJu8CoZts']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19518 ['sbOBTkrivXM', 'nvvXOfLs-ng', '-m9pH0WXQto', 'F1X7egd8Us0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19519 ['MMGAKKhqxKg', '8Z5xnSxUmGE', '1LA64TXatWk', 'oynXCFZWxnI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19520 ['E6B81rrUlnE', '2Ui85-AOLyo', 'xx1RccwlF5g', 'zj2G-KVw4N4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19521 ['4q-eGdrqiIw', 'yPou7kokTgA', 'RFNRR78dh-8', 'chw8sAKOM5k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19522 ['lymmNwQA0WA', 'Vo6eT8eMMfQ', 'YqZNMFyPJOQ', 'P97w3AdePgQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19523 ['3zntWbS9XeI', 'UY2_Q830lqo', 'Wu3LKQG1fwU', '4b8gTARnmVE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19524 ['7FHzw4HV75Y', 'y6NS77HLjEE', 'qfVIeq7s6tw', 'dO3VsX4rKNc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19525 ['HOIIp5NyFx0', 'bAJrcYJgllE', 'sxMYFYDNF_g', 'f8QGA4vN6HY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19526 ['X7LrhZX4rdU', '1BVSYfNCcv0', 'TkHZdMJPwKc', 'hVPQu1UJ2N8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19527 ['4Yc71_dU3m4', 'weJKl-6TiDQ', '2CzfBZ1mYBs', '9ZWmZdgrE78']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19528 ['iQ7qeIrssds', 'IJcLW4arT6s', 's25X6KwBpxw', 'BN6W6OQnVoE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19529 ['QCbUlDMu7Hk', 'MdsRmMxkF4k', 'yaUK4XvVGTg', 'TiDdR-6bIcY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19530 ['VzHL56yq8bI', 'vx5iuWuE2Ng', '4l441DdEJfU', '1rhsnmWLeGw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19531 ['VswY2mI7Wbo', 'jHEBYrI8zHE', 'FsnRM2irjvI', 'ZqnbgQeeRbM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19532 ['APSbmhJam74', '6L8066DGqcA', 'q7s7C4oNlFo', '6Q5N1DfzGj0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19533 ['c-85TtcfVSI', '5r4jLwjj_Ik', 'sUh43prJYMM', 'YvFY7xU2kGk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19534 ['Hxf1seOpijE', 'oVhhEku6ECA', '50QEapyTPD4', 'kSdH9z8snac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19535 ['-mB_XLq6g1g', 'wwHi10qX8u8', 'N8Fg3L1Cc5E', '3b3s0TvjGwA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19536 ['5ZX1-GAb7IM', 'lIBsL97sUmY', 'AiGGDpbgp6I', 'b2XAPiRUoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 42])\n",
            "Loss tensor(0.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19537 ['cTJqIkSuf6s', 'xGHN0kphhWM', 'xhOsZuB_Zqc', 'JC41M7RPSec']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19538 ['UsdoUjuczY4', 'n7yLkcSfiuM', 'OR_YbeqV5tA', '_qf0UiKtB3k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19539 ['cqolOXDF86g', '7TmKzUgWiRU', 'MNlzpCwdh4g', 'Xaq-segSEsQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19540 ['GcbCOmNiVm8', 'HLsRePLObfI', '_Ra1Y6K7nSs', 'knQuxZj9rTA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19541 ['tEdeb9eSKDI', '669Fk7afszw', 'tOb0M2k3deo', 'ba5xPgcHN_0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19542 ['vf3n40mDLHw', 't-CMJ6RsZzY', 'ALcCb2HJmG8', 'UrgzGbGVV8I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19543 ['7dmT4SgS_EM', 'dW4eW0Xreik', 'I0q3IGmTkRo', 'U-L9YCIdLbg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19544 ['HRxTN4TH-80', '9iYxf1hS4Yk', '4i1aizhCnfg', 'vhTWW5Bx15Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19545 ['vrNQbCbBlLY', '6CaZAITdAsk', '-ZHpNr_KRXU', '6QAZJ4H_5rA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19546 ['KyRJP_fDrbk', 'ppAT0f2YCyM', 'stobfk1Mfjk', 'm0FhT3UnXjA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19547 ['x85BtdoxRek', 'GmGWvBNO8JI', 'M0ygCD6WyXw', 'FiKY19GK6-8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19548 ['colnyHv9CAA', 'bKS_m7JObxg', 'vEN9szBPBkw', 'nB2Lf5TTmBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19549 ['6pHo6fPdPvM', 'd20qTsF6ll8', 'dUhE6H72Qpg', 'LaaC_q3QDUE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19550 ['evy2azZk3kE', 'KXuB62SMFvA', 'zYUZEXCE7gw', 'hhohfEC82JI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19551 ['rez5KDmIZoc', 'xSDkn9PtQm0', 'dj-DWiV1z9g', 'Hnk45Z0EAxg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19552 ['2kcSUBkFbaQ', 'oYEzy8gH6q8', 'LzSWdj4izHM', 'g0WLA0BKxOc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19553 ['qp4Ubx7WOAQ', 'C0sSgrr5xrQ', '-FEPOSP7ay0', 'yG1bzzXDIak']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19554 ['6TSluKI0X54', '9x7jWb4lE7c', 'dwSj0Rr3vFc', 'zopos1B6Elc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19555 ['k4ttuqKjiw0', 'Yj7YyxKyXPU', 'r_KdRKquXsM', 'qHRRWdWvjxI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19556 ['1SqihV_DnEg', 'efTVnvwI2PQ', '89eBh_Djflw', '74p3DLeDCHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19557 ['e6lTl9JIW5Y', 'c-8SLUH5pp4', '5tNOauvQWQQ', 'bYwoYjbPm-I']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19558 ['05JAmKFVy44', 'bNW18IztiZY', 'XjrVSk0_4vc', 'HEhogaw0vUg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19559 ['EzP7PB2x670', '9JlifkCmUOk', 'IGAzIIZRczw', 'uSZQGP_i3gs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19560 ['JsHTGDW5dgw', 'X6Q53uXgaHc', '78S8DnvLQDY', 'K5ilD6nEJ-g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19561 ['mtapmFDmImA', 'DG5d4megH8g', 'OPimGlHcSRQ', 'tvcJENqxr1c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19562 ['S0W_zIUYwrE', 'emDU4QvdwVk', 'nvBPPOzcW-A', 'GiTmjE7az74']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19563 ['RFbWkL818XQ', '7eZTmLV9gcY', 'YyYEzAY2e2I', 'lbB2VQYIMo0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19564 ['c7IL4fDqs_I', 'OJuVsBojdvo', 'FvQgVl5IBHw', 'rizanOQM61k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19565 ['_KaRkSyELy4', '02Qntw26enM', 'N4eMppEnPE0', 'DvOA0K-DIFM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19566 ['6BitLl5Bnxw', 'VG6-MlmCgzI', '6II4JGJDyZo', 'YeIXmKPyTVY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19567 ['tdrz4EkIsow', 'ASgLbz48BaY', '5xBfKiQcMZQ', '7EvLwfwRrqA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19568 ['QrJVAHIkpCo', '2UY_-oF1vqo', '5fPxUI0Fl-4', '64auWicQqZY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19569 ['pvxx3aokwCU', '4KqSdK5KM-I', 'nSinUcyFFqg', 'oKab6-syQD4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19570 ['BYwS1dJRTi0', 'tFVvupXoRoM', 'qRgefptkDeo', 'wIP7AqIOU1s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19571 ['UzDVZzIIcy8', 'Z0O2r0Dl2T4', 'UOAv5b6MGxw', 'L9j9fCHHPeg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19572 ['cfeTMVWFHLo', 'nj6N7m8SeK4', '0nk7utNkHOY', 'Q7oWXOByo28']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19573 ['7lV4IvuW2lk', 'Th6Tf6kA8RU', '45iNSkfzOwM', '6iyinlZEgS4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 33])\n",
            "Loss tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19574 ['76ON0Ixrr9s', '2nsZhXxes68', 'mU6cfEWw5Og', 'RtXe5T7NFrE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19575 ['RiqtelZs_2I', '3ZhyXbwFQAM', 'NVo-stvk_QE', 'ylKvglDzBU4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19576 ['MWS-Uxf1MRw', '_5w5TVK5B90', 'XYQnMxWnetY', 'uT-S_JC_GzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19577 ['c9h4p6325Xo', 'MwE7REVj8JQ', '-M-6VinyMiY', 'o8FsD7l5er4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19578 ['l3pK8prEnrQ', 'rkQPSAHNoeI', 'K_G_k1WTdoc', 'nqd7mXvHupU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19579 ['J8pkQfYlJA4', 'ba3QPheW8mI', 'A6ilKRqIDH4', '6KXd7l5pThg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19580 ['IUjzBX2Qm4k', 'qlWEAm4AUTU', 'EY8boPZ1hPs', 'DQrdOgRb-oA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19581 ['8zGJ9N7c6pE', 'b-7oO1Rw-fo', 'pWZqzEpygE0', 'zR4ebAuqy8w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 23])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19582 ['4_s5vHgfxnw', 'MsjeOXuUYG4', 'N-dzfI3L5ic', 'J1-Qvl7u2TI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19583 ['lXrypwLQO3U', 'qRCjs90-1RQ', '4mtfOkzOvBI', 'A8P5zzHCjJw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19584 ['6UJhTZgnVro', 'CIoEXRnAr-Y', 'zx_vcwOsDO4', 'WYxXUBP_XaM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19585 ['YB28WMv7wUE', 'DRU-IFx-7yQ', 'cYSW6Y884dA', 'f1_YKSYgtbI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19586 ['2ShO1jZYZeA', '0u1sk49gAU0', 'u9n4R78UBtA', 'VCrnnx9jTqs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19587 ['dEc7tV30KJo', '3zPvfVmL0nE', 'r9AxQfXYLEs', 'XOsHEjo-RSg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19588 ['9jeEfi6nDak', '9PQZSLa_A8A', 'BjAL68IMlp0', 'vtVfl5Ff5lw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 22])\n",
            "Loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19589 ['Y_eh6C0EBP8', 'Zq92ED3IvLQ', '4cg3MsrvJqw', 'RQbNC1J4Jfk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 38])\n",
            "Loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19590 ['38R9Vnwt890', '3Wdxjm-h36w', 'WcC9sKxJ1gI', 'wDpz90boBzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19591 ['-mA_bqD1tgU', 'GQz_u0Vc8Os', 'Sj5MQtqDw8Y', 'nSBDyxxscks']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 43])\n",
            "Loss tensor(0.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19592 ['hRQJgZVxRX0', 't6jlx6jAb-Q', 'RceCfg1FQq4', 'XILyHZyyCik']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.5542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19593 ['-EVRXQpt1-8', 'YLlbLSNxdQ4', 'H-bTMbePj0A', 'pqsU95TNNP8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 55])\n",
            "Loss tensor(0.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19594 ['-ByoSbgzr4M', 'O3Cvn4yXrao', 'VV85n-ebuUU', 'Al_OdIuqoe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19595 ['msnm_tYXcYw', 'kjmmzA6i5rk', 'KzydTOkZty8', 'lYJAqOpp6RM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19596 ['lTOzGIOIfq0', 'XfdySM4X9Xo', 'r1W1z_31Obw', '92k_81uqMSM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.5567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19597 ['C25xvcl4YAU', 'RXGDlFry3Vo', 'C8Euv69GR3U', 'nP05Sf4Fgac']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19598 ['gFxLnprPgv4', 'eAFKjP7o1as', 'zd3lShuZNmU', 'Ubj0jlheyvk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 14])\n",
            "Loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19599 ['vxIF3B4YqW8', 'XcvY-NdM8WA', 'DyPmDDN8m78', '1ZaxqZMs21M']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19600 ['B8pesuUc8Ek', '1PN-bfs2EhY', 'ZmgkpmzvL6c', '682ODyTqKyw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 53])\n",
            "Loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19601 ['5JQIsqc8HBc', 'nbIwdOQ7D8A', 'jcZQhxb5lyw', 'KJHqQ5aKu8U']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19602 ['i3zayf6Hiog', 'qdWTfyysMN8', '6F8qv0JBWkE', 'LRUdmYcXFuM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19603 ['VSAbMy1Rlio', '0S5zWt91Bwo', 'UDS6PrY9ZIM', '-7B9tPuIP-w']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19604 ['xVi1wNljxjk', 'AZsupJ68Hp0', 'DA8lw6Mq0DY', 'QRKc90kuAaE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19605 ['rh0vBy1JD8A', 'rNUtYf6EdW8', 'qXgSlhWbWLU', 'kMmjr8deHis']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19606 ['hTNKYJ6suII', 'ryEXhKy1QUI', 'I1fcUe9MoMw', 'uXMMzpgrY2g']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19607 ['5jT_i7S9QSM', 'DQ_gcdLhAsY', 'PB3i02Cjf1k', 'pKDnn0CBIe0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19608 ['qDSvHlHbAqM', 'hYlSisv-VRU', 'L2-EGNKzUAQ', 'B3lq6U4PDZo']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 35])\n",
            "Loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19609 ['Iz611KubW70', 'LR3U4b_fVBc', '-m5ZlWziIeA', 'UJA5AWbt6HM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19610 ['cHGziT0hrZU', 'ABVYSaLu_VM', 'yHd5DzIbWL8', 'kbCh5HrmgN0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 45])\n",
            "Loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19611 ['99ZgIQwLC60', '3OWArQGgmm0', 'wFTlySgdWX4', 'W2KaBnoGxek']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19612 ['PJRG2bwphUc', 'TqWmuwAYmnI', '3ZyuBJEbmJM', 'E2gstPe3Im4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19613 ['aVNcweinmEM', '8KIoQ2HZ0Hg', 'TWV3YLscSaw', 'C3Jhu77uffQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19614 ['PTLOLz9YzmM', 'kkjNpwNcMWI', '0EzWmAPwoTs', 'fyLctn3jNUs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19615 ['Xus0LI3QV2A', '1Xtkou9dtyA', 'aBEiuYSSEH0', 'm-eyGzf9Ux4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19616 ['D_usHKfOXCw', 'pyumNmhV4_s', 'R3urUtvSgkU', 'MyjxrBI9k4o']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19617 ['NlUf1ppoSG4', 'P240GHf9Eq4', 'JYYfw3id3ek', 'KDuusOmEMHg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19618 ['ZVvX2-ldhvY', 'eZE0RmJESFU', 's5wdG7xbTNg', 'dztizAgcQ08']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19619 ['ZUcHBeueBww', '0H3FAoDgzhI', 'QpX9dSCFxRI', 'kjn6I3AurgE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 52])\n",
            "Loss tensor(0.6037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19620 ['9ZryMX2UtAo', 'B4lGhVjoMTk', 'O40E8bpmONQ', 'Js_3Aa214xY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 34])\n",
            "Loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19621 ['qwI32Si0ipE', 'AnErEDywInE', 'JUrYWttZJBM', '2SenLjPbGzU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 32])\n",
            "Loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19622 ['BRTHyoVgZT0', 'WIVu5PapmX4', 'fHNAxa0QaOM', 'lBtAULJAFp0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 15])\n",
            "Loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19623 ['MvnC1TfNiPY', 'CJjyrDGmxIY', 'mBG-st0VUXs', 'aUH12rRIVDw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19624 ['OoRUo92emGo', 'fD1xB9lDbPQ', 'Npbs_4DZgEQ', 'VRfi64fecj4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19625 ['ySY5J3TDgag', 'nv1hWkBbG0g', 'HtCkwxfAmzw', 'P-eIhvCaK-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19626 ['qni67aUJbw4', 'Nt0U-CXK6O0', 'jFek2xLbEww', 'I-C14nCneBs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 54])\n",
            "Loss tensor(0.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19627 ['uYCAxX2F6DA', 'Qe_KwKVDgoE', 'I_wT76iYBdQ', 'MpjN21Z93JY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19628 ['O0y-m0pCi5E', '-o0ZtQIkM60', 'GNjsxLdSwHI', 'P4aTFrJws40']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19629 ['6807299U5eg', 'iHYOaGNdweo', 'OMApGp219Zc', 'AaajkQEU3A0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19630 ['7LlnLjZOqVI', 'EIzBD62ja8E', 'BfMKdrK9D8M', 'aURLQXt_6fE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19631 ['BkoCi-IZccI', '2SQxfaWAJJg', 'lBSS2AbA560', 'Euu6zlJQSD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19632 ['h7DOBV43UPQ', 'NsYVaRI6rXg', 'x9bcsYF_by8', 'DVuWm53IlVw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19633 ['Z-Vb1Ay-zNA', '1y1lEOGBcWM', 'J9ZlahUawkg', 'IqGB4nQIAcQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19634 ['GYCfrx0ruz4', '2I6pPRWKsCQ', 'H4tyvJJzSDk', 's59pQGs7Q3E']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19635 ['QQTWFTNy-WA', 'tKawN2sxhYc', 'fvhbI-7e89s', 'hSK405L-DlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 48])\n",
            "Loss tensor(0.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19636 ['qMd2DTyF9EE', 'bHNdoIWxXDk', 'HMQfp_qtF-M', 'A446kjocnCg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19637 ['yeu6OEIKwws', 'vTXb8P7sAFY', 'V9jIsOTC1lY', '7OjXHfVoI64']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19638 ['3gh1oldZ7Zc', '2wZCoeq9Ppc', 'AgtY6m-b3Gk', 'ura8EjHjGC4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19639 ['R0b3pU4AKNc', 'oC0e8GXYy_4', '2uvHgwAljPA', 'JI26wmUPcrM']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19640 ['t-yy7v7P0IE', '3C-5_z01Olc', '0M7nETLOsKQ', 'yuWjB3XA8tc']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 18])\n",
            "Loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19641 ['1QSD-dzEv7Y', '_GxqvILlmAw', 'R_HAtyDbw1M', '8Nrp4jUZeGE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19642 ['PP3kNqPM434', 'XI9CNsX6JSE', '3tbFP_JKzXw', 'Rwt8j_USbWI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19643 ['_miAGxDX5FM', 'st92BzeUzFU', '4lcZkOMhKv8', 'Zz1Bz1a7yPE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19644 ['raM8Lp0aGCk', '49nqh7uI9fw', 'ANaaOqwO0Uo', 'SlnjJv305Vg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19645 ['IjP5kKfgBiI', '9Cfs00bZRCg', 'ApDJYsi9UGg', 's1QeDT7jqHQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19646 ['XPGtOugQ69U', '7YWMPBHKdyY', '9Ijpv6e57a4', 'xR2p3UED4VU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19647 ['C0eCERYt4bA', 'R77XPtKgvy4', 'WJIrkvEq4EI', 'hqQvatf1RUY']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19648 ['6zgvEiJJrM8', 'e4R2O7XpIXU', 'PwmXO0J-PAA', '1JwoLPCIGhs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19649 ['0zolXzR9Oi4', 'zeUEOxTd8IE', 'JPZlyvPNZj4', 'G2uCAwYS6w0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 44])\n",
            "Loss tensor(0.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19650 ['1lgqqW5TsJk', 'UHvYrO1IGCc', '3nbB3F-OdSM', 'AFWy1qyyMHE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19651 ['jlIbJVfnHB4', 'gMgN50wSnNc', 'd9r_kYpOvW8', 'PRRcVdXsBQg']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 46])\n",
            "Loss tensor(0.6474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19652 ['ORikRIu7s1o', 's6U8DtBK3Us', '_yXtw_z2xf4', 'BXcEsM8ykhE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19653 ['YIhfk4Zaevk', 'CpHRQ-f4UtA', 'RDW_kz4SXo0', 'aCTm1TcL7z8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19654 ['RtgHU1UMo5o', '4T2KBwRxi_g', 'GFJNgqcX7u0', 'uAYPacrJnyQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 47])\n",
            "Loss tensor(0.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19655 ['-1LrH01Ei1w', 'vd1dgdxlA94', '2xGRCsW6-Bk', 'NqDxpJ2uR_8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 26])\n",
            "Loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19656 ['BsnjK6DypAg', 'DYpjbiyPUho', 'UNJswfXKJ3s', 'Z9hnLYpypCU']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 36])\n",
            "Loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19657 ['UfEGX0rNOvA', '6C0HoQe4Y-Y', 'oFCzd9bJo9A', 'qVdBBOpSoN4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 50])\n",
            "Loss tensor(0.6244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19658 ['oD0Xp--xxjE', 'LEG7xkYOsWA', 'LM2C1eIUX9M', 'CyiPyjYX6AE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19659 ['EKZvq0dUk50', 'TzPuAqjoL80', 'p9nbp0Oo1U0', 'ZJZxWLYzNh8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 19])\n",
            "Loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19660 ['sC7T0sEG6ek', 'wwbATvWFaLY', 'rUIGOcQMaSE', 'Rf7vygfb7w4']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 27])\n",
            "Loss tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19661 ['xZukWGb52BI', '7vC1iriZlX8', '2ZYzviKuq9w', 'si_IAMPOXlQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 24])\n",
            "Loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19662 ['Cwbtn_h6TP8', '_y07ENAx2_E', '3TO4C7SiC7I', 'uF1KTW5rT-s']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 49])\n",
            "Loss tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19663 ['-7wUQP6G5EQ', 'tpamd6BKYU4', 'uYYpqx0rzok', 'EPvnkbo5wrI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 28])\n",
            "Loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19664 ['AJw-x30L46E', '5P5XAclO8ko', 'AwcuLXAPFDs', 'pHzjKCj9INw']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 20])\n",
            "Loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19665 ['2gc1L3g1itU', 'RI126_DmGLQ', 'gNpzuFPu6q8', 'PF5LgwJjYuA']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 21])\n",
            "Loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19666 ['qsFfUzErXqw', 'dBAeAk7dXnU', 'RI71ebbU0PQ', '2zpITTJiw7Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19667 ['Mp1MHSeHa0o', 'Qz8hNRg-7G0', 'UeYmnV-B8so', 'vK9x7UQ9Y7k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 41])\n",
            "Loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19668 ['PqTTIfja0y8', 'xxCnmao8FAs', 'F5zDEHggiMg', '1W2Cz2Jj76Q']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19669 ['W_MZo88gzrA', '07FxCXxknY4', 'aUx0xMF9pwU', 'je96vkMY60c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19670 ['tIRHm8VhK_4', 'YpOHemscGCk', 'z7vNtEcM9Bk', '2_kLD3IbF2c']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 17])\n",
            "Loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19671 ['5rsQHo-6DI4', '08mf5GxT820', 'darQBSIlol8', 'IN71kMOAk_k']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 16])\n",
            "Loss tensor(0.5169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19672 ['1l7BjFDQLUM', 'eWNERam16Hg', 'aeDZVfGk7bk', 'QKkhwAAGLIE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 31])\n",
            "Loss tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19673 ['vOU-qA25xNM', 'too9MtXBwts', 'OKZF0oG1E14', 'D8-x1T8M4gk']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 25])\n",
            "Loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19674 ['I-xPuRe9vF0', 'eyFBIA_HOmE', '3VEMHWnewuc', 'rccs9c1gteQ']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19675 ['16TsDMjHzYU', 'rOOBAGxxjBk', 'mq_b6QKVsuc', 'MC0Aeu7RLSI']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 29])\n",
            "Loss tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19676 ['F9LJIyqQFe8', '2ctgUIqyaBk', 'ZU6sI1Plq50', 'h2f_CKjQQg8']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 37])\n",
            "Loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19677 ['YZH-PZBir3E', 'KkW6ZkmAlEw', 'KmBaE7ozWow', 'THfTLXBLpJE']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 40])\n",
            "Loss tensor(0.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19678 ['gAURHUoIK0M', 'OheHnFixwVk', 'navn7jCBp_o', 'dLUobee5JEs']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 30])\n",
            "Loss tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19679 ['QIzSxE0WlKE', 'nYO8n62Piys', 'MROotmz8a-U', 'qknDM3pcoD0']\n",
            "torch.Size([4, 1024, 128])\n",
            "torch.Size([4, 39])\n",
            "Loss tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Step 19680\n",
            "Loss tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "batches_per_epoch = int(ds_train.num_rows / batch_size)\n",
        "output = []\n",
        "sentences = []\n",
        "step = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for i in range(batches_per_epoch):\n",
        "    start = i * batch_size\n",
        "    # print(start)\n",
        "    xBatch = ds_train[start:start+batch_size]\n",
        "    # xBatch = ds_train[i]\n",
        "    # print(xBatch)\n",
        "    waveform = xBatch[\"waveform\"]\n",
        "    id = xBatch[\"ytid\"]\n",
        "    print(step, id)\n",
        "    input = torch.tensor(xBatch[\"input_values\"]).squeeze(1).to(device)\n",
        "    # input = torch.tensor(xBatch[\"input_values\"]).to(device)\n",
        "\n",
        "    # captions = xBatch[\"tokenizedCaption\"]\n",
        "    captions = xBatch[\"tokenizedAspectList\"]\n",
        "    maxCaptionLen = 0\n",
        "    # Find max length of caption in batch\n",
        "    for item in range(batch_size):\n",
        "      if(len(captions[item]) > maxCaptionLen):\n",
        "        maxCaptionLen = len(captions[item])\n",
        "\n",
        "  # Add padding to the captions based on max len\n",
        "    for j in range(batch_size):\n",
        "      if(len(captions[j]) < maxCaptionLen):\n",
        "        for k in range(len(captions[j]), maxCaptionLen):\n",
        "          captions[j].append(2)\n",
        "\n",
        "    # target = torch.tensor(xBatch[\"tokenizedCaption\"]).to(device)\n",
        "    target = torch.tensor(xBatch[\"tokenizedAspectList\"]).to(device)\n",
        "    # target = target.unsqueeze(0)\n",
        "    print(input.shape)\n",
        "    print(target.shape)\n",
        "    currOutput = newModel(input, target[:, :-1])\n",
        "    # currOutput = newModel(input, target)\n",
        "    # print(currOutput)\n",
        "    pred = currOutput[0].argmax(1)\n",
        "    pred2 = currOutput[1].argmax(1)\n",
        "    # print(predIdx)\n",
        "    # output.append(currOutput)\n",
        "    # print(target[0])\n",
        "\n",
        "    # for j in range(len(pred)):\n",
        "    #   if(pred[j] == 1):\n",
        "    #     tempOutput = currOutput[0][:j]\n",
        "    #     print(tempOutput.shape)\n",
        "        # for k in range(j+1, len(pred)):\n",
        "        #   currOutput[0][k][2] = 100\n",
        "\n",
        "    # for j in range(len(pred2)):\n",
        "    #   if(pred2[j] == 1):\n",
        "    #     # for k in range(j+1, len(pred2)):\n",
        "    #     #   currOutput[1][k][2] = 100\n",
        "\n",
        "    # newMax = lossOutput.argmax(1)\n",
        "    # print(newMax)\n",
        "\n",
        "    # loss = bleu_score(predSen, targetSen)\n",
        "    # loss = criterion(currOutput[0], target[0])\n",
        "    # loss = criterion(currOutput.reshape(-1, currOutput.shape[2]), target[0].reshape(-1))\n",
        "    currOutput = currOutput.view(-1, currOutput.shape[2])\n",
        "    targetInput = target[:,1:].reshape(-1)\n",
        "\n",
        "    # targetInput = target.contiguous().view(-1)\n",
        "    # loss = criterion(currOutput, targetInput)\n",
        "    loss = custom_loss(currOutput, targetInput)\n",
        "    print(\"Loss\", loss)\n",
        "\n",
        "    step += 1\n",
        "    # for name, param in newModel.named_parameters():\n",
        "    #   if param.grad is not None:\n",
        "    #     print(name, param.grad)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(loss)\n",
        "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Step\", step)\n",
        "  print(\"Loss\", loss)\n",
        "  torch.save(newModel.state_dict(), 'newModelCheckpoint.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqITETAPmOCC"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjyA9l9AFsjN"
      },
      "outputs": [],
      "source": [
        "def dynamicPadding(batch):\n",
        "  captions = batch[\"tokenizedAspectList\"]\n",
        "  maxCaptionLen = 0\n",
        "  for i in range(batch_size):\n",
        "    if(len(captions[i]) > maxCaptionLen):\n",
        "      maxCaptionLen = len(captions[i])\n",
        "\n",
        "  for j in range(batch_size):\n",
        "    if(len(captions[j]) < maxCaptionLen):\n",
        "      for k in range(len(captions[j]), maxCaptionLen):\n",
        "        captions[j].append(2)\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h-I-B80NIqC",
        "outputId": "89981c5b-fc65-4edc-ed56-01c88e605fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1024, 128])\n",
            "torch.Size([1, 14])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor(ds_test[0:1][\"input_values\"]).squeeze(1).to(device)\n",
        "\n",
        "batch = ds_test[0:1]\n",
        "# captions = batch[\"tokenizedCaption\"]\n",
        "# maxCaptionLen = 0\n",
        "\n",
        "# for i in range(batch_size):\n",
        "#   if(len(captions[i]) > maxCaptionLen):\n",
        "#     maxCaptionLen = len(captions[i])\n",
        "\n",
        "# for j in range(batch_size):\n",
        "#   if(len(captions[j]) < maxCaptionLen):\n",
        "#     for k in range(len(captions[j]), maxCaptionLen):\n",
        "#       captions[j].append(2)\n",
        "\n",
        "# dynamicPadding(batch)\n",
        "\n",
        "# target = torch.tensor(batch[\"tokenizedCaption\"]).to(device)\n",
        "target = torch.tensor(batch[\"tokenizedAspectList\"]).to(device)\n",
        "# target = target.unsqueeze(0)\n",
        "print(input.shape)\n",
        "print(target.shape)\n",
        "modelOutput = newModel(input, target)\n",
        "# loadedOutput = loaded_model(input, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1xlz2072wXa",
        "outputId": "007d6ade-b9f9-43ab-d225-1203a8c07d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([88, 5475])\n"
          ]
        }
      ],
      "source": [
        "tempOutput = modelOutput.view(-1, modelOutput.shape[2])\n",
        "print(tempOutput.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tYxn0JD-YI",
        "outputId": "611793e6-ba44-4fe0-e35d-b6acf02ac4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-2.5003,  1.9018, -2.6463,  ..., -3.2833, -3.7127, -3.0394],\n",
            "         [-2.3698,  3.4217, -1.9702,  ..., -3.4956, -2.8221, -2.8570],\n",
            "         [-1.3004,  1.9933, -0.7634,  ..., -2.0791, -1.3730, -1.9847],\n",
            "         ...,\n",
            "         [-0.5852,  2.4742,  0.2530,  ..., -1.0860, -1.1115, -0.5978],\n",
            "         [-2.2533,  5.3062, -1.8107,  ..., -2.6317, -3.4494, -3.4386],\n",
            "         [-1.3028,  2.9477, -0.4578,  ..., -2.1496, -1.6670, -1.1011]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([  4, 229, 783, 132, 571,  46, 200,  38, 229,  24, 313,  24,   1, 226],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(modelOutput)\n",
        "max = modelOutput[0].argmax(1)\n",
        "print(max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am69qnV7DBlK"
      },
      "outputs": [],
      "source": [
        "def createSentence(input):\n",
        "  sentence = []\n",
        "  for i in range(len(input)):\n",
        "    sentence.append(vocab_list[input[i]])\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Zkq-Fbk6WS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LsgbIc19CBt"
      },
      "outputs": [],
      "source": [
        "beam_size = 2\n",
        "text = [0]\n",
        "text = torch.tensor(text).unsqueeze(0).to(device)\n",
        "hypotheses = [text]\n",
        "\n",
        "newText = torch.tensor([0]).unsqueeze(0).to(device)\n",
        "\n",
        "currSeqPos = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJqo4vMFOyQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a10ca17-f99e-488e-97b7-a50ebca724a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prev text tensor([[0, 0]], device='cuda:0')\n",
            "_ 0\n",
            "node length 1\n",
            "node token id tensor([[0]], device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 2])\n",
            "Pred shape torch.Size([1, 2, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([0], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[0, 4]], device='cuda:0')\n",
            "_ 1\n",
            "node length 2\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 2])\n",
            "Pred shape torch.Size([1, 2, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427]], device='cuda:0')\n",
            "_ 2\n",
            "node length 3\n",
            "node token id tensor(427, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 3])\n",
            "Pred shape torch.Size([1, 3, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  0,   4, 427], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28]], device='cuda:0')\n",
            "_ 3\n",
            "node length 4\n",
            "node token id tensor(28, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 4])\n",
            "Pred shape torch.Size([1, 4, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  4, 427,  28], device='cuda:0')\n",
            "history tensor(4, device='cuda:0') token tensor(4, device='cuda:0')\n",
            "Multinomial_input shape torch.Size([1048])\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74]], device='cuda:0')\n",
            "_ 4\n",
            "node length 5\n",
            "node token id tensor(74, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 5])\n",
            "Pred shape torch.Size([1, 5, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([427,  28,  74], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4]], device='cuda:0')\n",
            "_ 5\n",
            "node length 6\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 6])\n",
            "Pred shape torch.Size([1, 6, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([28, 74,  4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13]], device='cuda:0')\n",
            "_ 6\n",
            "node length 7\n",
            "node token id tensor(13, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 7])\n",
            "Pred shape torch.Size([1, 7, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([74,  4, 13], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270]], device='cuda:0')\n",
            "_ 7\n",
            "node length 8\n",
            "node token id tensor(270, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 8])\n",
            "Pred shape torch.Size([1, 8, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  4,  13, 270], device='cuda:0')\n",
            "history tensor(4, device='cuda:0') token tensor(4, device='cuda:0')\n",
            "Multinomial_input shape torch.Size([1048])\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558]], device='cuda:0')\n",
            "_ 8\n",
            "node length 9\n",
            "node token id tensor(558, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 9])\n",
            "Pred shape torch.Size([1, 9, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 13, 270, 558], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10]], device='cuda:0')\n",
            "_ 9\n",
            "node length 10\n",
            "node token id tensor(10, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 10])\n",
            "Pred shape torch.Size([1, 10, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([270, 558,  10], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10,  64]],\n",
            "       device='cuda:0')\n",
            "_ 10\n",
            "node length 11\n",
            "node token id tensor(64, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 11])\n",
            "Pred shape torch.Size([1, 11, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([558,  10,  64], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[  0,   4, 427,  28,  74,   4,  13, 270, 558,  10,  64, 199]],\n",
            "       device='cuda:0')\n",
            "_ 11\n",
            "node length 12\n",
            "node token id tensor(199, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 12])\n",
            "Pred shape torch.Size([1, 12, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 10,  64, 199], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215]], device='cuda:0')\n",
            "_ 12\n",
            "node length 13\n",
            "node token id tensor(2215, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 13])\n",
            "Pred shape torch.Size([1, 13, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([  64,  199, 2215], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158]], device='cuda:0')\n",
            "_ 13\n",
            "node length 14\n",
            "node token id tensor(1158, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 14])\n",
            "Pred shape torch.Size([1, 14, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 199, 2215, 1158], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41]], device='cuda:0')\n",
            "_ 14\n",
            "node length 15\n",
            "node token id tensor(41, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 15])\n",
            "Pred shape torch.Size([1, 15, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2215, 1158,   41], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269]], device='cuda:0')\n",
            "_ 15\n",
            "node length 16\n",
            "node token id tensor(269, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 16])\n",
            "Pred shape torch.Size([1, 16, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([1158,   41,  269], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692]], device='cuda:0')\n",
            "_ 16\n",
            "node length 17\n",
            "node token id tensor(692, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 17])\n",
            "Pred shape torch.Size([1, 17, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 41, 269, 692], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229]], device='cuda:0')\n",
            "_ 17\n",
            "node length 18\n",
            "node token id tensor(229, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 18])\n",
            "Pred shape torch.Size([1, 18, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([269, 692, 229], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4]], device='cuda:0')\n",
            "_ 18\n",
            "node length 19\n",
            "node token id tensor(4, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 19])\n",
            "Pred shape torch.Size([1, 19, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([692, 229,   4], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174]], device='cuda:0')\n",
            "_ 19\n",
            "node length 20\n",
            "node token id tensor(2174, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 20])\n",
            "Pred shape torch.Size([1, 20, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 229,    4, 2174], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233]],\n",
            "       device='cuda:0')\n",
            "_ 20\n",
            "node length 21\n",
            "node token id tensor(233, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 21])\n",
            "Pred shape torch.Size([1, 21, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([   4, 2174,  233], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084]],\n",
            "       device='cuda:0')\n",
            "_ 21\n",
            "node length 22\n",
            "node token id tensor(2084, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 22])\n",
            "Pred shape torch.Size([1, 22, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2174,  233, 2084], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095]],\n",
            "       device='cuda:0')\n",
            "_ 22\n",
            "node length 23\n",
            "node token id tensor(2095, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 23])\n",
            "Pred shape torch.Size([1, 23, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 233, 2084, 2095], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557]],\n",
            "       device='cuda:0')\n",
            "_ 23\n",
            "node length 24\n",
            "node token id tensor(557, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 24])\n",
            "Pred shape torch.Size([1, 24, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2084, 2095,  557], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95]], device='cuda:0')\n",
            "_ 24\n",
            "node length 25\n",
            "node token id tensor(95, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 25])\n",
            "Pred shape torch.Size([1, 25, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([2095,  557,   95], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744]], device='cuda:0')\n",
            "_ 25\n",
            "node length 26\n",
            "node token id tensor(744, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 26])\n",
            "Pred shape torch.Size([1, 26, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([557,  95, 744], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520]], device='cuda:0')\n",
            "_ 26\n",
            "node length 27\n",
            "node token id tensor(520, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 27])\n",
            "Pred shape torch.Size([1, 27, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 95, 744, 520], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520, 4229]], device='cuda:0')\n",
            "_ 27\n",
            "node length 28\n",
            "node token id tensor(4229, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 28])\n",
            "Pred shape torch.Size([1, 28, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 744,  520, 4229], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n",
            "Prev text tensor([[   0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
            "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
            "           95,  744,  520, 4229, 2037]], device='cuda:0')\n",
            "_ 28\n",
            "node length 29\n",
            "node token id tensor(2037, device='cuda:0')\n",
            "New beam len 0\n",
            "beam len 1\n",
            "Text input shape torch.Size([1, 29])\n",
            "Pred shape torch.Size([1, 29, 4308])\n",
            "torch.Size([4308])\n",
            "tensor([0.0831, 0.1621, 0.2254,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
            "Indices_to_sample tensor([   4,   10,   74,  ..., 4101,  711, 3050], device='cuda:0') len torch.Size([1049])\n",
            "Multinomial_input shape torch.Size([1049])\n",
            "History tensor([ 520, 4229, 2037], device='cuda:0')\n",
            "Log probs shape torch.Size([4308])\n",
            "tensor([-2.4876, -2.5386], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "class BeamSearchNode:\n",
        "  def __init__(self, prev_node, token_id, log_prob, length):\n",
        "    self.prev_node = prev_node\n",
        "    self.token_id = token_id\n",
        "    self.log_prob = log_prob\n",
        "    self.length = length\n",
        "\n",
        "\n",
        "def top_p_sampling(logits, p):\n",
        "  # Sort logits in descending order\n",
        "  sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "  print(sorted_logits.shape)\n",
        "  # Calculate cumulative probabilities\n",
        "  cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "  print(cumulative_probs)\n",
        "  # Determine indices to sample\n",
        "  indices_to_sample = sorted_indices[cumulative_probs < p]\n",
        "  print(\"Indices_to_sample\", indices_to_sample, \"len\", indices_to_sample.shape)\n",
        "  return indices_to_sample\n",
        "\n",
        "\n",
        "def sample_from_subset(indices_to_sample, logits):\n",
        "  # Sample one index from the subset\n",
        "  multinomial_input = F.softmax(logits[indices_to_sample], dim=-1)\n",
        "  print(\"Multinomial_input shape\", multinomial_input.shape)\n",
        "  sampled_index = torch.multinomial(multinomial_input, 1)\n",
        "  return sampled_index.item()\n",
        "\n",
        "\n",
        "def top_p_sample(logits, prevText, p, filter):\n",
        "  # Compute indices to sample from\n",
        "  indices_to_sample = top_p_sampling(logits, p)\n",
        "  # Sample from the subset\n",
        "  sampled_index = sample_from_subset(indices_to_sample, logits)\n",
        "  token = indices_to_sample[sampled_index]\n",
        "  # Token filtering here\n",
        "  # If token is in token history then remove it from indices to sample and sample from subset again\n",
        "  filterWindow = prevText.shape[1] - filter\n",
        "  token_history = prevText[0][filterWindow:]\n",
        "  print(\"History\", token_history)\n",
        "  for i in range(len(token_history)):\n",
        "    if(token_history[i] == token):\n",
        "      print(\"history\", token_history[i], \"token\", token)\n",
        "      indices_to_sample = torch.cat((indices_to_sample[:sampled_index], indices_to_sample[sampled_index+1:]))\n",
        "      sampled_index = sample_from_subset(indices_to_sample, logits)\n",
        "      token = indices_to_sample[sampled_index]\n",
        "      continue\n",
        "  # indices_to_sample = torch.cat((indices_to_sample[:sampled_index], indices_to_sample[sampled_index+1:]))\n",
        "  return token\n",
        "\n",
        "\n",
        "def beam_search_node(newModel, input, newText, max_length=10, num_beams=2):\n",
        "  initial_node = BeamSearchNode(prev_node=None, token_id=newText, log_prob=0.0, length=1)\n",
        "  beam = [initial_node]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    new_beam = []\n",
        "    for node in beam:\n",
        "      if node.length >= max_length:\n",
        "        new_beam.append(node)\n",
        "        continue\n",
        "\n",
        "      tempNodes = node\n",
        "      prevText = []\n",
        "      while tempNodes.prev_node:\n",
        "        prevText.append(tempNodes.prev_node.token_id)\n",
        "        tempNodes = tempNodes.prev_node\n",
        "      if(prevText == []):\n",
        "        prevText.append(0)\n",
        "      # Reverses the array\n",
        "      prevText = prevText[::-1]\n",
        "      prevText.append(node.token_id)\n",
        "      prevText = torch.tensor(prevText).unsqueeze(0).to(device)\n",
        "      print(\"Prev text\", prevText)\n",
        "      # print(\"Prev text shape\", prevText.shape)\n",
        "      # print(\"New token shape\", newToken.shape)\n",
        "      text_input = prevText\n",
        "\n",
        "      print(\"_\", _)\n",
        "      print(\"node length\", node.length)\n",
        "      print(\"node token id\", node.token_id)\n",
        "      print(\"New beam len\", len(new_beam))\n",
        "      print(\"beam len\", len(beam))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Log prob\n",
        "        print(\"Text input shape\", text_input.shape)\n",
        "        preds = newModel(input, text_input)\n",
        "        print(\"Pred shape\", preds.shape)\n",
        "        temperature = 1.25\n",
        "        scaled_logits = preds[0][0] / temperature\n",
        "        top_p_index = top_p_sample(scaled_logits, prevText, p=0.8, filter=3)\n",
        "        log_probs = F.log_softmax((scaled_logits), dim=-1)\n",
        "        # log_probs = F.log_softmax(preds[0], dim=-1)\n",
        "        print(\"Log probs shape\", log_probs.shape)\n",
        "\n",
        "      topk_probs, topk_ids = torch.topk(log_probs, num_beams)\n",
        "      print(topk_probs)\n",
        "      seqIdx = log_probs.shape[0] - 1\n",
        "\n",
        "      # for prob, token_id in zip(topk_probs[seqIdx], topk_ids[seqIdx]):\n",
        "      #   print(\"Prob\", prob)\n",
        "      #   new_node = BeamSearchNode(\n",
        "      #       prev_node=node,\n",
        "      #       token_id=token_id.item(),\n",
        "      #       log_prob=node.log_prob+prob.item(),\n",
        "      #       length = node.length + 1\n",
        "      #   )\n",
        "      #   print(\"New node token\", new_node.token_id)\n",
        "      #   new_beam.append(new_node)\n",
        "      #   print(\"New beam after len\", len(new_beam))\n",
        "\n",
        "      new_node = BeamSearchNode(\n",
        "          prev_node=node,\n",
        "          token_id=top_p_index,\n",
        "          log_prob = node.log_prob+scaled_logits[top_p_index],\n",
        "          length = node.length+1,\n",
        "      )\n",
        "      new_beam.append(new_node)\n",
        "\n",
        "\n",
        "    beam = sorted(new_beam, key=lambda x: x.log_prob, reverse=True)[:num_beams]\n",
        "\n",
        "  output_sequences = []\n",
        "  for node in beam:\n",
        "    output_sequence = []\n",
        "    while node:\n",
        "      output_sequence.append(node.token_id)\n",
        "      node = node.prev_node\n",
        "    output_sequence.reverse()\n",
        "    output_sequences.append(output_sequence)\n",
        "  return output_sequences\n",
        "\n",
        "\n",
        "gen = beam_search_node(newModel, input, newText, max_length=30, num_beams=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPqpTW0X0gB8",
        "outputId": "fc15176b-6a78-4839-e826-89a7ba450506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0]], device='cuda:0')\n",
            "[[tensor([[0]], device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(506, device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(66, device='cuda:0'), tensor(651, device='cuda:0'), tensor(76, device='cuda:0'), tensor(48, device='cuda:0'), tensor(76, device='cuda:0'), tensor(76, device='cuda:0'), tensor(100, device='cuda:0'), tensor(4, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(76, device='cuda:0'), tensor(4, device='cuda:0'), tensor(4, device='cuda:0'), tensor(66, device='cuda:0'), tensor(18, device='cuda:0'), tensor(104, device='cuda:0'), tensor(76, device='cuda:0'), tensor(104, device='cuda:0'), tensor(104, device='cuda:0'), tensor(66, device='cuda:0'), tensor(507, device='cuda:0'), tensor(934, device='cuda:0'), tensor(104, device='cuda:0')]]\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "print(newText)\n",
        "# print(hypotheses)\n",
        "print(gen)\n",
        "print(len(gen[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fth-xKliSeK",
        "outputId": "86bcec92-0ddc-4afb-9bd3-f9b81948260a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<SOS>', 'low', 'scuffling', 'instrumental', 'live', 'low', 'piano', 'loud', 'symphonic', 'female', 'unrelated', 'shrutibox', 'tap', 'swing', 'jazzy', 'harp', 'indian', 'classical', 'low', 'diy', 'joyful', 'climax', 'snapping', 'opera', 'kids', 'acapella', 'bad', 'benign', 'hindu']\n",
            "['percussion', 'music', 'no', 'other', 'instruments', 'no', 'voices', 'instrumental', 'advertisement', 'music', 'promotional', 'music']\n"
          ]
        }
      ],
      "source": [
        "tokenizedInput = [  0,    4,  427,   28,   74,    4,   13,  270,  558,   10,   64,  199,\n",
        "         2215, 1158,   41,  269,  692,  229,    4, 2174,  233, 2084, 2095,  557,\n",
        "           95,  744,  520, 4229, 2037]\n",
        "outputSentence = createSentence(tokenizedInput)\n",
        "print(outputSentence)\n",
        "print(ds_test[0][\"aspect_list\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1VBOgdySxGb5bUNgN1kWfZFR050qmmec3",
      "authorship_tag": "ABX9TyOYdR9AYOCD/GO45xzP5+Qa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caf864f927bb4dfd9a920af784e6279a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c820ef37e37f46ae97f8f8c7835d6155",
              "IPY_MODEL_6ce05079f751444e858fdec3490c643d",
              "IPY_MODEL_f10c7b8c53434b149a738349e2db4f83"
            ],
            "layout": "IPY_MODEL_efbd27fbeb2743e5959f922766f7af1d"
          }
        },
        "c820ef37e37f46ae97f8f8c7835d6155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9afc25d4ce5947d5a6d9a18efb1867f5",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab758d6094b48f0bc16c97d0f51bdd1",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "6ce05079f751444e858fdec3490c643d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9796c68ea3b48f8ab531dd95da9248b",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8600763699148a7ba75cb5bf452760e",
            "value": 4000
          }
        },
        "f10c7b8c53434b149a738349e2db4f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a9eaedc8404c5ab058991e29755084",
            "placeholder": "​",
            "style": "IPY_MODEL_eebc759d45fc4ee0adb0c909a666256d",
            "value": " 4000/4000 [01:40&lt;00:00, 21.43 examples/s]"
          }
        },
        "efbd27fbeb2743e5959f922766f7af1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afc25d4ce5947d5a6d9a18efb1867f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab758d6094b48f0bc16c97d0f51bdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9796c68ea3b48f8ab531dd95da9248b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8600763699148a7ba75cb5bf452760e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15a9eaedc8404c5ab058991e29755084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebc759d45fc4ee0adb0c909a666256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe5e88f46814addb420127fba3e1a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98882b6be26d4adb984b780f18b42475",
              "IPY_MODEL_cbcdddb134184651878d4095e86f568a",
              "IPY_MODEL_0b3a52a94e964d3d88cd3f4af589ec32"
            ],
            "layout": "IPY_MODEL_8cb19431548240c6aef34ee2f7b727d9"
          }
        },
        "98882b6be26d4adb984b780f18b42475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51160fe4f0f4428a849ae2f45cdeb6f",
            "placeholder": "​",
            "style": "IPY_MODEL_4e50c217fc9a4593ad1a4b13d3cd6520",
            "value": "Filter: 100%"
          }
        },
        "cbcdddb134184651878d4095e86f568a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f7e377db9d402589c0b62459eeb6f8",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4e0be3a213144b28c49e5bf8bfb3cea",
            "value": 4000
          }
        },
        "0b3a52a94e964d3d88cd3f4af589ec32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0414bc80ce8843089e4cb2703c148d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_92f8854f16fa4aa589e5cca56519e17e",
            "value": " 4000/4000 [00:00&lt;00:00, 19839.85 examples/s]"
          }
        },
        "8cb19431548240c6aef34ee2f7b727d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51160fe4f0f4428a849ae2f45cdeb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e50c217fc9a4593ad1a4b13d3cd6520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39f7e377db9d402589c0b62459eeb6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e0be3a213144b28c49e5bf8bfb3cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0414bc80ce8843089e4cb2703c148d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f8854f16fa4aa589e5cca56519e17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfefceaa9a994572bc75f13848d17e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b182fdc6fb142e99a3e1c68e64a85c6",
              "IPY_MODEL_0a12a718706941388f4648d6f253aff2",
              "IPY_MODEL_dc91bd5090d146b1898283e57504f417"
            ],
            "layout": "IPY_MODEL_79e43e78edd44d659c596010bb8cd8cf"
          }
        },
        "1b182fdc6fb142e99a3e1c68e64a85c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa698a1c6114d4e838cead88aadd973",
            "placeholder": "​",
            "style": "IPY_MODEL_50f48d378d984300b20567188119f2a7",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "0a12a718706941388f4648d6f253aff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf2bf40e7b94e5788c62e90eb130811",
            "max": 3938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_408414e23a3f486f8f1ca8ddcd58571e",
            "value": 3938
          }
        },
        "dc91bd5090d146b1898283e57504f417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b83da868d64aacb2813ee62aa56592",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0b7242250542b3bd24fff37f9b8c0f",
            "value": " 3938/3938 [00:36&lt;00:00, 117.02 examples/s]"
          }
        },
        "79e43e78edd44d659c596010bb8cd8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa698a1c6114d4e838cead88aadd973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f48d378d984300b20567188119f2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bf2bf40e7b94e5788c62e90eb130811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408414e23a3f486f8f1ca8ddcd58571e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59b83da868d64aacb2813ee62aa56592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0b7242250542b3bd24fff37f9b8c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edc9bfb111894241b7743ade8368adc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cc7c21de84f42baa203e7a6cbfd4dcd",
              "IPY_MODEL_8c8ce7cf8338462e90432586090c2546",
              "IPY_MODEL_d95723b737444067bd108b9d98e93730"
            ],
            "layout": "IPY_MODEL_30ab350318e84c0a9946c2335e69c3c9"
          }
        },
        "8cc7c21de84f42baa203e7a6cbfd4dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3e65a266f34760804bc2251ff5f982",
            "placeholder": "​",
            "style": "IPY_MODEL_1e74f90df3724ac994b8b7fcb36ccae5",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "8c8ce7cf8338462e90432586090c2546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046c9b249add4637946e8737e51b8873",
            "max": 3938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34f82ef2f34b46459cc0fd66b2486ecf",
            "value": 3938
          }
        },
        "d95723b737444067bd108b9d98e93730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9c235094cd462980e3493da044942c",
            "placeholder": "​",
            "style": "IPY_MODEL_898aa92f313841f1a5a668a73b342a70",
            "value": " 3938/3938 [02:56&lt;00:00,  3.40s/ examples]"
          }
        },
        "30ab350318e84c0a9946c2335e69c3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3e65a266f34760804bc2251ff5f982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e74f90df3724ac994b8b7fcb36ccae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "046c9b249add4637946e8737e51b8873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34f82ef2f34b46459cc0fd66b2486ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9c235094cd462980e3493da044942c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898aa92f313841f1a5a668a73b342a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3ee0149e064d1a8c546e91aa99d8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04b0b6f18014987a1eb327448d52e00",
              "IPY_MODEL_e194bcae55cb48f680b425ca5dec78f9",
              "IPY_MODEL_19a5b8526e3647619c6394e6171d6061"
            ],
            "layout": "IPY_MODEL_054aeb09d15d4e56a05d24e2bb9bdebb"
          }
        },
        "a04b0b6f18014987a1eb327448d52e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf66265813542a088ec4c0802fba527",
            "placeholder": "​",
            "style": "IPY_MODEL_a3458938928b4a3a870d6adb8aa92982",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "e194bcae55cb48f680b425ca5dec78f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b3722deba44609867fe515213b6cce",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b26c31d96cca4b248fc5f687c3819115",
            "value": 800
          }
        },
        "19a5b8526e3647619c6394e6171d6061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9af07bdf9764d45bb758fd91b93b643",
            "placeholder": "​",
            "style": "IPY_MODEL_fab2854df7ba4574888d6f97b545171e",
            "value": " 800/800 [00:12&lt;00:00, 49.69 examples/s]"
          }
        },
        "054aeb09d15d4e56a05d24e2bb9bdebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf66265813542a088ec4c0802fba527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3458938928b4a3a870d6adb8aa92982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b3722deba44609867fe515213b6cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26c31d96cca4b248fc5f687c3819115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9af07bdf9764d45bb758fd91b93b643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab2854df7ba4574888d6f97b545171e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225c1f91cb1c405a84eb42282a1fed5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_652cfb71336c48ac83069d0126c2d98a",
              "IPY_MODEL_579d5da2cf524faa829462f30d8edc8f",
              "IPY_MODEL_49ea87b042404059a62a4b78de5fe987"
            ],
            "layout": "IPY_MODEL_8500fd266cca4dfdb71773360136fbf8"
          }
        },
        "652cfb71336c48ac83069d0126c2d98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52b0397f846448f88138aadf54245d4",
            "placeholder": "​",
            "style": "IPY_MODEL_f43b3ecb31d64e1cb8b3b7113fd5ff8d",
            "value": "Filter: 100%"
          }
        },
        "579d5da2cf524faa829462f30d8edc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218f39ee38134945b6ed0f237154475e",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bed47b85e2f1445a8f233f4d140ab006",
            "value": 800
          }
        },
        "49ea87b042404059a62a4b78de5fe987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba7c9753e16428d95c64cf451000ac2",
            "placeholder": "​",
            "style": "IPY_MODEL_933d03e0e2d34787ac431aaadcf34744",
            "value": " 800/800 [00:00&lt;00:00, 16478.62 examples/s]"
          }
        },
        "8500fd266cca4dfdb71773360136fbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52b0397f846448f88138aadf54245d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43b3ecb31d64e1cb8b3b7113fd5ff8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218f39ee38134945b6ed0f237154475e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed47b85e2f1445a8f233f4d140ab006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba7c9753e16428d95c64cf451000ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933d03e0e2d34787ac431aaadcf34744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3818e5a00b7f4d77b0a7e91a7cb6ba6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6574f3aa167e4b5fb791455ff8789429",
              "IPY_MODEL_9cba04b8c0734986a8ee9e1be3573da2",
              "IPY_MODEL_c6dad448169d470888ed1f37ec78be9a"
            ],
            "layout": "IPY_MODEL_c1ebebe46d35491a866e7a7a34b7f9ec"
          }
        },
        "6574f3aa167e4b5fb791455ff8789429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566b1fed17164827a967a19d62446262",
            "placeholder": "​",
            "style": "IPY_MODEL_102b1f901b3a4a8c8d4cb3483bc07cc1",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "9cba04b8c0734986a8ee9e1be3573da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a911bca4b4b40f5924db04dd7519d39",
            "max": 786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9a3996898c643c38c803a943decc4f6",
            "value": 786
          }
        },
        "c6dad448169d470888ed1f37ec78be9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d959a491d010482695ba8ac117d6e7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_77ba9fb0314c44ed91835b93a5577e11",
            "value": " 786/786 [00:08&lt;00:00, 140.50 examples/s]"
          }
        },
        "c1ebebe46d35491a866e7a7a34b7f9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566b1fed17164827a967a19d62446262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102b1f901b3a4a8c8d4cb3483bc07cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a911bca4b4b40f5924db04dd7519d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a3996898c643c38c803a943decc4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d959a491d010482695ba8ac117d6e7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ba9fb0314c44ed91835b93a5577e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80bf7c0d05b45b1b061a9e555d2d772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ff16ebcaeb4401aae8fd9fd10d807a0",
              "IPY_MODEL_9b9d18e620994db09fe389d3411d2820",
              "IPY_MODEL_b908ef8c300f496481de5127b838cfaf"
            ],
            "layout": "IPY_MODEL_64100adbcf824998b54afdc5db21c645"
          }
        },
        "4ff16ebcaeb4401aae8fd9fd10d807a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4931815f9a114a908023a22ed7134a07",
            "placeholder": "​",
            "style": "IPY_MODEL_52a2fc382b3845d9a7c82a858b8575a2",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "9b9d18e620994db09fe389d3411d2820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dd6b3080104ad595d4c408d57dae3c",
            "max": 786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8147f2c3087148e99e73d5f1f1965327",
            "value": 786
          }
        },
        "b908ef8c300f496481de5127b838cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf0a40211f4b7996ed41a163b82389",
            "placeholder": "​",
            "style": "IPY_MODEL_7679a1e2a97442568d66d62f3ee15a33",
            "value": " 786/786 [00:34&lt;00:00, 22.37 examples/s]"
          }
        },
        "64100adbcf824998b54afdc5db21c645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4931815f9a114a908023a22ed7134a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a2fc382b3845d9a7c82a858b8575a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dd6b3080104ad595d4c408d57dae3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8147f2c3087148e99e73d5f1f1965327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fdf0a40211f4b7996ed41a163b82389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7679a1e2a97442568d66d62f3ee15a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}